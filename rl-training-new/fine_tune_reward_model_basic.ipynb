{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tune reward model from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODOs:\n",
    "\n",
    "#TODO: double-check that labels are not somehow misaligned...\n",
    "\n",
    "#TODO: check if you need to plot \n",
    "\n",
    "1. LoRA learns the position of the low rank adaptation matrix that is needed to finetune a model of a much higher rank\n",
    "\n",
    "#TODO: double check model performance, generate output, maybe adjust training metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports, setup, and global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "CUDA is available. Using GPU: NVIDIA L40S\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Add the parent directory to the Python path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.dirname(os.getcwd()), '..')))\n",
    "\n",
    "from transformers import TrainingArguments, EarlyStoppingCallback\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from datasets import Dataset, DatasetDict, load_from_disk\n",
    "\n",
    "from peft import LoraConfig, get_peft_model, PeftModel\n",
    "\n",
    "from utils import parse_ratings, tokenize_fn_with_best_window, tokenize_fn_basic_batched, CustomRewardTrainer\n",
    "\n",
    "\n",
    "# from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# load the relevant devices available on the server\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = os.getenv(\"AVAILABLE_DEVICES\")\n",
    "\n",
    "# Enable expandable CUDA segments\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "# load cuda\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print(\"CUDA is available. Using GPU:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"CUDA is not available. Using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training variables\n",
    "FEEDBACK_TO_TRAIN_ON = os.getenv(\"FEEDBACK_TO_TRAIN_ON\")\n",
    "FEEDBACK_TO_REMOVE = os.getenv(\"FEEDBACK_TO_REMOVE\")\n",
    "MODEL = os.getenv(\"REWARD_MODEL\")\n",
    "DATASET = os.getenv(\"REWARD_DATASET\")\n",
    "TOKENIZE_FN = os.getenv(\"TOKENIZE_FN\")\n",
    "MAX_LENGTH = os.getenv(\"MAX_LENGTH\")\n",
    "STRIDE = os.getenv(\"STRIDE\")\n",
    "LORA_CHECKPOINTS_FOLDER = os.getenv(\"LORA_CHECKPOINTS_FOLDER\")\n",
    "FINAL_LORA_ADAPTERS = os.getenv(\"FINAL_LORA_ADAPTERS_FOLDER\") + f\"_{FEEDBACK_TO_TRAIN_ON}_{TOKENIZE_FN}_{DATASET}\"\n",
    "TOKENIZED_DATA = os.getenv(\"TOKENIZED_DATA\") + f\"_{FEEDBACK_TO_TRAIN_ON}_{TOKENIZE_FN}_{DATASET}\"\n",
    "\n",
    "# load training data\n",
    "FILE_1 = os.getenv(\"FILE_1\")\n",
    "FILE_5 = os.getenv(\"FILE_5\")\n",
    "FILE_7 = os.getenv(\"FILE_7\")\n",
    "FILE_9 = os.getenv(\"FILE_9\")\n",
    "FILE_10_1 = os.getenv(\"FILE_10_1\")\n",
    "FILE_10_2 = os.getenv(\"FILE_10_2\")\n",
    "FILE_SYNTH = os.getenv(\"FILE_SYNTH\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset loading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataframes\n",
    "df_1 = pd.read_csv(FILE_1, sep=\";\")\n",
    "df_5 = pd.read_csv(FILE_5, sep=\";\")\n",
    "df_7 = pd.read_csv(FILE_7, sep=\";\")\n",
    "df_9 = pd.read_csv(FILE_9, sep=\";\")\n",
    "df_10_1 = pd.read_csv(FILE_10_1, sep=\";\")\n",
    "df_10_2 = pd.read_csv(FILE_10_2, sep=\";\")\n",
    "df_synth = pd.read_csv(FILE_SYNTH, sep=\";\")\n",
    "\n",
    "df_human = pd.concat([df_1, df_5, df_7, df_9, df_10_1, df_10_2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(929, 13)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if DATASET == \"human\":\n",
    "    df_train = df_human\n",
    "elif DATASET == \"synthetic\":\n",
    "    df_train = df_synth\n",
    "    \n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. a) Parse ratings to numeric values for MSE Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed feedback for extraction: 0    2\n",
      "1    2\n",
      "2    2\n",
      "3    2\n",
      "4    3\n",
      "Name: feedback_extraction, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df_train[FEEDBACK_TO_TRAIN_ON] = [parse_ratings(feedback) for feedback in df_train[FEEDBACK_TO_TRAIN_ON]]\n",
    "print(\"Parsed feedback for extraction:\", df_train[FEEDBACK_TO_TRAIN_ON][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. b) look at biases in feedback to train on for weights in RL loop --> feedback_detection is very biased through way it was collected, so gets less weight overall..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feedback_extraction\n",
       "0    499\n",
       "3    231\n",
       "2    104\n",
       "1     95\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[FEEDBACK_TO_TRAIN_ON].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. c) keep only relevant feedback column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['file', 'frame_ID', 'frame_type', 'frame_text', 'precondition_id', 'precondition_text', 'precondition_position', 'response_text', 'prompt_config_examples', 'prompt_config_chain_of_thought', 'feedback_extraction', 'feedback_detection', 'additional_feedback'],\n",
      "    num_rows: 929\n",
      "})\n",
      "feedback_extraction\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset.from_pandas(df_train)\n",
    "\n",
    "print(dataset)\n",
    "print(FEEDBACK_TO_TRAIN_ON) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.remove_columns([FEEDBACK_TO_REMOVE])\n",
    "dataset = dataset.rename_column(FEEDBACK_TO_TRAIN_ON, \"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load model with LoRA layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nlpaueb/legal-bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertForSequenceClassification(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSdpaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (classifier): Linear(in_features=768, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Load the model and the tokenizer\n",
    "model_id = MODEL \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_id, num_labels=1) # num_labels = 1 since we want to prodict a single scalar (the rating)\n",
    "\n",
    "# Comment: Automodel for sequence classification with num_labels=1 already has a regression head\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "512\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.model_max_length)\n",
    "print(model.config.max_position_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 443,137 || all params: 109,926,146 || trainable%: 0.4031\n"
     ]
    }
   ],
   "source": [
    "# Define LoRA config\n",
    "lora_config = LoraConfig(\n",
    "    r=8,           # Rank of the LoRA matrices (smaller = less memory)\n",
    "    lora_alpha=16, # Scaling factor (higher = stronger adaptation)\n",
    "    target_modules=[\"query\", \"key\", \"value\"], # Apply LoRA to attention layers\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_CLS\"  # classify each answer \n",
    ")\n",
    "\n",
    "# Convert the model to a PEFT (LoRA) model\n",
    "model = get_peft_model(model, lora_config)\n",
    "# model.gradient_checkpointing_enable()\n",
    "model.print_trainable_parameters()  # Check trainable params (~0.1% of full model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 1067, 223, 207, 580, 210, 1335, 124, 102, 0, 0, 0], [101, 1067, 223, 207, 5601, 190, 580, 213, 207, 1727, 124, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test tokenizer\n",
    "sample_data = [\"What is the capital of France?\", \"What is the largest capital in the world?\"]\n",
    "tokenizer(sample_data, padding=True, truncation=True, max_length=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Encode dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['file', 'frame_ID', 'frame_type', 'frame_text', 'precondition_id', 'precondition_text', 'precondition_position', 'response_text', 'prompt_config_examples', 'prompt_config_chain_of_thought', 'label', 'additional_feedback']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 929/929 [00:00<00:00, 16730.97 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2, 2, 2, 3]\n",
      "['1. Subfact: Onze Minister\\n                2. Positie: Artikel 1, sectie 1 IN Vreemdelingenwet geldig vanaf 2024\\n                3. Subfact: Onze Minister\\n                4. Positie: Artikel 8, sectie 1 IN Vreemdelingenwet geldig vanaf 2024\\n                5. Subfact: Onze Minister\\n                6. Positie: Artikel 14, sectie 1 IN Vreemdelingenwet geldig vanaf 2024\\n                7. Subfact: Onze Minister\\n                8. Positie: Artikel 16, sectie 1 IN Vreemdelingenwet geldig vanaf 2024\\n                9. Subfact: Onze Minister\\n                10. Positie: Artikel 17, sectie 1 IN Vreemdelingenwet geldig vanaf 2024\\n                11. Subfact: Onze Minister\\n                12. Positie: Artikel 17a, sectie 1 IN Vreemdelingenwet geldig vanaf 2024\\n                13. Subfact: Onze Minister\\n                14. Positie: Artikel 26, sectie 1 IN Vreemdelingenwet geldig vanaf 2024\\n                15. Subfact: Onze Minister\\n                16. Positie: Artikel 27, sectie 1 IN Vreemdelingenwet geldig vanaf 2024\\n                17. Subfact: Onze Minister\\n                18. Positie: Artikel 66a, sectie 6 IN Vreemdelingenwet geldig vanaf 2024\\n                19. Subfact: Onze Minister\\n                20. Positie: Artikel 67, sectie 3 IN Vreemdelingenwet geldig vanaf 2024\\n', '1. Subfact: Onze Minister\\n                2. Positie: Artikel 1, sectie 1 IN Vreemdelingenwet geldig vanaf 2024\\n                3. Subfact: Onze Minister\\n                4. Positie: Artikel 8, sectie 1 IN Vreemdelingenwet geldig vanaf 2024\\n                5. Subfact: Onze Minister\\n                6. Positie: Artikel 14, sectie 1 IN Vreemdelingenwet geldig vanaf 2024\\n                7. Subfact: Onze Minister\\n                8. Positie: Artikel 16, sectie 1 IN Vreemdelingenwet geldig vanaf 2024\\n                9. Subfact: Onze Minister\\n                10. Positie: Artikel 17, sectie 1 IN Vreemdelingenwet geldig vanaf 2024\\n                11. Subfact: Onze Minister\\n                12. Positie: Artikel 17a, sectie 1 IN Vreemdelingenwet geldig vanaf 2024\\n                13. Subfact: Onze Minister\\n                14. Positie: Artikel 26, sectie 1 IN Vreemdelingenwet geldig vanaf 2024\\n                15. Subfact: Onze Minister\\n                16. Positie: Artikel 27, sectie 1 IN Vreemdelingenwet geldig vanaf 2024\\n                17. Subfact: Onze Minister\\n                18. Positie: Artikel 66a, sectie 6 IN Vreemdelingenwet geldig vanaf 2024\\n                19. Subfact: Onze Minister\\n                20. Positie: Artikel 67, sectie 3 IN Vreemdelingenwet geldig vanaf 2024\\n', '1. Subfact: Onze Minister\\n                2. Positie: Artikel 1, sectie 1 IN Vreemdelingenwet geldig vanaf 2024\\n                3. Subfact: Onze Minister\\n                4. Positie: Artikel 8, sectie 1 IN Vreemdelingenwet geldig vanaf 2024\\n                5. Subfact: Onze Minister\\n                6. Positie: Artikel 14, sectie 1 IN Vreemdelingenwet geldig vanaf 2024\\n                7. Subfact: Onze Minister\\n                8. Positie: Artikel 16, sectie 1 IN Vreemdelingenwet geldig vanaf 2024\\n                9. Subfact: Onze Minister\\n                10. Positie: Artikel 17, sectie 1 IN Vreemdelingenwet geldig vanaf 2024\\n                11. Subfact: Onze Minister\\n                12. Positie: Artikel 17a, sectie 1 IN Vreemdelingenwet geldig vanaf 2024\\n                13. Subfact: Onze Minister\\n                14. Positie: Artikel 26, sectie 1 IN Vreemdelingenwet geldig vanaf 2024\\n                15. Subfact: Onze Minister\\n                16. Positie: Artikel 27, sectie 1 IN Vreemdelingenwet geldig vanaf 2024\\n                17. Subfact: Onze Minister\\n                18. Positie: Artikel 66a, sectie 6 IN Vreemdelingenwet geldig vanaf 2024\\n                19. Subfact: Onze Minister\\n                20. Positie: Artikel 67, sectie 3 IN Vreemdelingenwet geldig vanaf 2024\\n', '1. Subfact: Onze Minister\\n\\n                2. Positie: Artikel 1, sectie 1 IN Algemene wet bestuursrecht\\n\\n                3. Positie: Artikel 1, sectie 1 IN Vreemdelingenwet geldig vanaf 2024\\n\\n                4. Positie: Artikel 14, 1 IN Vreemdelingenwet geldig vanaf 2024\\n\\n                5. Positie: Artikel 1, sub 2° IN Vreemdelingenwet geldig vanaf 2024\\n\\n                6. Positie: Artikel 1, sub 4° IN Vreemdelingenwet geldig vanaf 2024\\n\\n                7. Positie: Artikel 1, sub 6° IN Vreemdelingenwet geldig vanaf 2024\\n\\n                8. Positie: Artikel 1, sub 2° IN Vreemdelingenwet geldig vanaf 2024, Afdeling 3. De verblijfsvergunning regulier\\n\\n                9. Positie: Artikel 9, 1 IN Vreemdelingenwet geldig vanaf 2024\\n\\n                10. Positie: Artikel 14, 1a IN Vreemdelingenwet geldig vanaf 2024\\n\\n                11. Positie: Artikel 14, 1b IN Vreemdelingenwet geldig vanaf 2024\\n\\n                12. Positie: Artikel 14, 1c IN Vreemdelingenwet geldig vanaf 2024\\n\\n                13. Positie: Artikel 14, 1d IN Vreemdelingenwet geldig vanaf 2024\\n\\n                14. Positie: Artikel 14, 1e IN Vreemdel', '1. Subfact: Onze Minister\\n\\n                2. Positie: Artikel 1, sectie 1 IN Algemene wet bestuursrecht\\n\\n                3. Positie: Artikel 1, sectie 1 IN Vreemdelingenwet geldig vanaf 2024\\n\\n                4. Positie: Artikel 14, 1 IN Vreemdelingenwet geldig vanaf 2024\\n\\n                5. Positie: Artikel 1, sub 2° IN Vreemdelingenwet geldig vanaf 2024\\n\\n                6. Positie: Artikel 1, sub 4° IN Vreemdelingenwet geldig vanaf 2024\\n\\n                7. Positie: Artikel 1, sub 6° IN Vreemdelingenwet geldig vanaf 2024\\n\\n                8. Positie: Artikel 1, sub 2° IN Vreemdelingenwet geldig vanaf 2024, Afdeling 3. De verblijfsvergunning regulier\\n\\n                9. Positie: Artikel 9, 1 IN Vreemdelingenwet geldig vanaf 2024\\n\\n                10. Positie: Artikel 14, 1a IN Vreemdelingenwet geldig vanaf 2024\\n\\n                11. Positie: Artikel 14, 1b IN Vreemdelingenwet geldig vanaf 2024\\n\\n                12. Positie: Artikel 14, 1c IN Vreemdelingenwet geldig vanaf 2024\\n\\n                13. Positie: Artikel 14, 1d IN Vreemdelingenwet geldig vanaf 2024\\n\\n                14. Positie: Artikel 14, 1e IN Vreemdel']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# if labels are not integers, convert them to integers\n",
    "def convert_label_to_int(data):\n",
    "    data[\"label\"] = int(data[\"label\"])\n",
    "    return data\n",
    "\n",
    "\n",
    "print(dataset.column_names)\n",
    "# mao string labels to integers\n",
    "dataset = dataset.map(convert_label_to_int)  # Assuming 'text' is the column with the text data\n",
    "\n",
    "print(dataset[\"label\"][:5])  # Check labels\n",
    "print(dataset[\"response_text\"][:5])  # Check labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comment\n",
    "\n",
    "1. Needed for feedback extraction: precondition_text, response_text, label(rating feedback extraction)\n",
    "2. Needed for feedback detection: precondition_text, precondition_position, response_text, label (rating feedback detection)\n",
    "3. For the precondition position to be found well, it is a crucial for the model to find the precondition text (at least to a recognizable degree) as well, otherwise the precondition is not found at all..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 929/929 [00:00<00:00, 3708.29 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 929/929 [00:00<00:00, 168381.16 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# sample = dataset.select(range(5))\n",
    "# tokenized_sample = tokenize_fn(sample)\n",
    "# print([len(ids) for ids in tokenized_sample[\"input_ids\"]])\n",
    "\n",
    "if not os.path.exists(TOKENIZED_DATA):\n",
    "    if TOKENIZE_FN == \"best_window\":\n",
    "        dataset = dataset.map(tokenize_fn_with_best_window, \n",
    "                              fn_kwargs={\"feedback_train\": FEEDBACK_TO_TRAIN_ON, \n",
    "                                         \"tokenizer\": tokenizer, \n",
    "                                         \"max_length\": int(MAX_LENGTH), \n",
    "                                         \"stride\": int(STRIDE),\n",
    "                                         \"device\": device\n",
    "                                         },\n",
    "                              batched=False)\n",
    "    else:\n",
    "        dataset = dataset.map(tokenize_fn_basic_batched, \n",
    "                              fn_kwargs={\"feedback_train\": FEEDBACK_TO_TRAIN_ON, \n",
    "                                         \"tokenizer\": tokenizer \n",
    "                                         },\n",
    "                              batched=True)\n",
    "    \n",
    "    dataset.save_to_disk(TOKENIZED_DATA)\n",
    "else:\n",
    "    dataset = load_from_disk(TOKENIZED_DATA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split dataset into train, test, eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test and eval sets\n",
    "train_test_split = dataset.train_test_split(test_size=0.3, seed=42)\n",
    "eval_test_split = train_test_split[\"test\"].train_test_split(test_size=0.5, seed=42)\n",
    "\n",
    "\n",
    "final_splits = DatasetDict({\n",
    "    'train': train_test_split['train'],\n",
    "    'validation': eval_test_split['train'],\n",
    "    'test': eval_test_split['test']\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train reward model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=LORA_CHECKPOINTS_FOLDER,\n",
    "    eval_strategy='steps',\n",
    "    save_strategy='steps',\n",
    "    save_steps=100,\n",
    "    eval_steps=100,\n",
    "    save_total_limit=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    learning_rate=3e-4,\n",
    "    num_train_epochs=20,\n",
    "    logging_steps=10,\n",
    "    label_names=[\"labels\"],\n",
    "    # report_to=\"none\",\n",
    "    logging_dir=\"./logs\",\n",
    "    fp16=True,  # Use mixed precision training\n",
    "    metric_for_best_model=\"eval_loss\", # or \"eval_loss\"\n",
    "    greater_is_better=False, # False if using loss\n",
    "    # gradient_accumulation_steps=4 # \n",
    ")\n",
    "\n",
    "# Initialize custom trainer\n",
    "trainer = CustomRewardTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=final_splits['train'],\n",
    "    eval_dataset=final_splits['validation'],\n",
    "    # compute_metrics=trainer.compute_metrics,  # Use the custom metrics function\n",
    "    processing_class=tokenizer,\n",
    "    loss_type=\"huber\",  # \"mse\" or \"huber\"\n",
    "    weight_strategy=\"linear\",  # \"linear\", \"inverse\", or None\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)] # use early stopping since we are sing high amount of epochs\n",
    "    # data_collator=RewardDataCollator()\n",
    ")\n",
    "\n",
    "# # add distributioncallback to trainer TODO: only integrate if relevant\n",
    "# trainer.add_callback(DistributionCallback())\n",
    "\n",
    "print(trainer.args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='820' max='820' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [820/820 00:59, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.047400</td>\n",
       "      <td>1.194752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.640400</td>\n",
       "      <td>0.794190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.601600</td>\n",
       "      <td>0.784183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.425600</td>\n",
       "      <td>0.604200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.417700</td>\n",
       "      <td>0.636476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.378400</td>\n",
       "      <td>0.612518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.402100</td>\n",
       "      <td>0.559864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.385300</td>\n",
       "      <td>0.616722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=820, training_loss=0.6142073491724526, metrics={'train_runtime': 59.3654, 'train_samples_per_second': 218.983, 'train_steps_per_second': 13.813, 'total_flos': 3438110128128000.0, 'train_loss': 0.6142073491724526, 'epoch': 20.0})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store final model parameters\n",
    "model.save_pretrained(FINAL_LORA_ADAPTERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reload saved LoRA adapter for inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nlpaueb/legal-bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "base_model = AutoModelForSequenceClassification.from_pretrained(MODEL, num_labels=1)\n",
    "model = PeftModel.from_pretrained(base_model, FINAL_LORA_ADAPTERS)\n",
    "model = model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results: {'eval_loss': 0.5376802086830139, 'eval_runtime': 0.2384, 'eval_samples_per_second': 587.255, 'eval_steps_per_second': 37.752, 'epoch': 20.0}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_results = trainer.evaluate(eval_dataset=final_splits['test'])\n",
    "print(\"Test Results:\", test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1: Predicted Rating: 2.8296525478363037, True Rating: 1\n",
      "Sample 2: Predicted Rating: 0.0598440058529377, True Rating: 0\n",
      "Sample 3: Predicted Rating: 2.578739881515503, True Rating: 3\n",
      "Sample 4: Predicted Rating: 0.08147154748439789, True Rating: 0\n",
      "Sample 5: Predicted Rating: 0.6681082844734192, True Rating: 3\n",
      "Sample 6: Predicted Rating: 0.173975870013237, True Rating: 0\n",
      "Sample 7: Predicted Rating: 2.470729112625122, True Rating: 1\n",
      "Sample 8: Predicted Rating: 0.2174949198961258, True Rating: 0\n",
      "Sample 9: Predicted Rating: -0.02062557265162468, True Rating: 0\n",
      "Sample 10: Predicted Rating: 0.08285029232501984, True Rating: 0\n",
      "Sample 11: Predicted Rating: 0.0437869168817997, True Rating: 0\n",
      "Sample 12: Predicted Rating: 1.4138603210449219, True Rating: 0\n",
      "Sample 13: Predicted Rating: 0.12305611371994019, True Rating: 0\n",
      "Sample 14: Predicted Rating: 3.0094668865203857, True Rating: 1\n",
      "Sample 15: Predicted Rating: 2.069288492202759, True Rating: 0\n",
      "Sample 16: Predicted Rating: 0.027122173458337784, True Rating: 0\n",
      "Sample 17: Predicted Rating: 2.470729112625122, True Rating: 3\n",
      "Sample 18: Predicted Rating: 2.8889946937561035, True Rating: 3\n",
      "Sample 19: Predicted Rating: 0.17913763225078583, True Rating: 1\n",
      "Sample 20: Predicted Rating: 2.8274126052856445, True Rating: 3\n"
     ]
    }
   ],
   "source": [
    "# evaluate model manually on some test cases\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(20):\n",
    "        sample = final_splits['test'][i]\n",
    "        inputs = tokenizer(sample['precondition_text'] + \" \" + sample['response_text'], return_tensors='pt', truncation=True, padding=\"max_length\").to(device)\n",
    "        outputs = model(**inputs)\n",
    "        prediction = outputs.logits.item()\n",
    "        print(f\"Sample {i+1}: Predicted Rating: {prediction}, True Rating: {sample['label']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
