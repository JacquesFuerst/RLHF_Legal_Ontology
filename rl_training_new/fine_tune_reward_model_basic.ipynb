{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tune reward model from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODOs:\n",
    "\n",
    "#TODO: double-check that labels are not somehow misaligned...\n",
    "\n",
    "#TODO: check if you need to plot \n",
    "\n",
    "1. LoRA learns the position of the low rank adaptation matrix that is needed to finetune a model of a much higher rank\n",
    "\n",
    "#TODO: double check model performance, generate output, maybe adjust training metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports, setup, and global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jacques.furst/miniconda3/envs/reward_model_training/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "CUDA is available. Using GPU: NVIDIA L40S\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Add the parent directory to the Python path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.dirname(os.getcwd()), '..')))\n",
    "\n",
    "from transformers import TrainingArguments, EarlyStoppingCallback\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from datasets import Dataset, DatasetDict, load_from_disk\n",
    "\n",
    "from peft import LoraConfig, get_peft_model, PeftModel, PeftConfig\n",
    "\n",
    "from utils import parse_ratings, tokenize_fn_with_best_window, tokenize_fn_basic_batched, CustomRewardTrainer, find_best_window, convert_label_to_int\n",
    "\n",
    "\n",
    "# from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# load the relevant devices available on the server\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = os.getenv(\"AVAILABLE_DEVICES\")\n",
    "\n",
    "# Enable expandable CUDA segments\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "# load cuda\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print(\"CUDA is available. Using GPU:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"CUDA is not available. Using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training variables\n",
    "FEEDBACK_TO_TRAIN_ON = os.getenv(\"FEEDBACK_TO_TRAIN_ON\")\n",
    "FEEDBACK_TO_REMOVE = os.getenv(\"FEEDBACK_TO_REMOVE\")\n",
    "MODEL = os.getenv(\"REWARD_MODEL\")\n",
    "DATASET = os.getenv(\"REWARD_DATASET\")\n",
    "TOKENIZE_FN = os.getenv(\"TOKENIZE_FN\")\n",
    "MAX_LENGTH = os.getenv(\"MAX_LENGTH\")\n",
    "STRIDE = os.getenv(\"STRIDE\")\n",
    "LORA_CHECKPOINTS_FOLDER = os.getenv(\"LORA_CHECKPOINTS_FOLDER\")\n",
    "\n",
    "#TODO: change this to not store model since contains /!!!\n",
    "FINAL_LORA_ADAPTERS = os.getenv(\"FINAL_LORA_ADAPTERS_FOLDER\") + f\"_{FEEDBACK_TO_TRAIN_ON}_{TOKENIZE_FN}_{DATASET}\"\n",
    "TOKENIZED_DATA_TRAIN = os.getenv(\"TOKENIZED_DATA\") + f\"_{FEEDBACK_TO_TRAIN_ON}_{TOKENIZE_FN}_{DATASET}_train\"\n",
    "TOKENIZED_DATA_EVAL = os.getenv(\"TOKENIZED_DATA\") + f\"_{FEEDBACK_TO_TRAIN_ON}_{TOKENIZE_FN}_{DATASET}_eval\"\n",
    "TOKENIZED_DATA_TEST = os.getenv(\"TOKENIZED_DATA\") + f\"_{FEEDBACK_TO_TRAIN_ON}_{TOKENIZE_FN}_{DATASET}_test\"\n",
    "DATASET_STRUCTURE = os.getenv(\"DATASET_STRUCTURE\")\n",
    "\n",
    "REWARD_DATA_PATH = os.getenv(\"REWARD_DATA_PATH\")\n",
    "\n",
    "if DATASET_STRUCTURE == \"determined\":\n",
    "    REWARD_MODEL_TRAIN_DATA_HUMAN = REWARD_DATA_PATH + \"/train_human_determined.csv\"\n",
    "    REWARD_MODEL_EVAL_DATA_HUMAN = REWARD_DATA_PATH + \"/validation_human_determined.csv\"\n",
    "    REWARD_MODEL_TEST_DATA_HUMAN = REWARD_DATA_PATH + \"/test_human_determined.csv\"\n",
    "\n",
    "    REWARD_MODEL_TRAIN_DATA_SYNTH = REWARD_DATA_PATH + \"/train_synth_determined.csv\"\n",
    "    REWARD_MODEL_EVAL_DATA_SYNTH = REWARD_DATA_PATH + \"/validation_synth_determined.csv\"\n",
    "    REWARD_MODEL_TEST_DATA_SYNTH = REWARD_DATA_PATH + \"/test_synth_determined.csv\"\n",
    "\n",
    "elif DATASET_STRUCTURE == \"random\":\n",
    "    REWARD_MODEL_TRAIN_DATA_HUMAN = REWARD_DATA_PATH + \"/train_human_random.csv\"\n",
    "    REWARD_MODEL_EVAL_DATA_HUMAN = REWARD_DATA_PATH + \"/validation_human_random.csv\"\n",
    "    REWARD_MODEL_TEST_DATA_HUMAN = REWARD_DATA_PATH + \"/test_human_random.csv\"\n",
    "\n",
    "    REWARD_MODEL_TRAIN_DATA_SYNTH = REWARD_DATA_PATH + \"/train_synth_random.csv\"\n",
    "    REWARD_MODEL_EVAL_DATA_SYNTH = REWARD_DATA_PATH + \"/validation_synth_random.csv\"\n",
    "    REWARD_MODEL_TEST_DATA_SYNTH = REWARD_DATA_PATH + \"/test_synth_random.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset loading and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Re-structure df synthetic to fit in training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['file', 'frame_ID', 'frame_type', 'frame_text', 'precondition_id',\n",
       "       'precondition_text', 'precondition_position', 'response_text',\n",
       "       'prompt_config_examples', 'prompt_config_chain_of_thought',\n",
       "       'feedback_extraction', 'feedback_detection', 'additional_feedback',\n",
       "       'synthetic_feedback'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if DATASET == \"human\":\n",
    "    df_train = pd.read_csv(REWARD_MODEL_TRAIN_DATA_HUMAN, sep=\";\")\n",
    "    df_eval = pd.read_csv(REWARD_MODEL_EVAL_DATA_HUMAN, sep=\";\")\n",
    "    df_test = pd.read_csv(REWARD_MODEL_TEST_DATA_HUMAN, sep=\";\")\n",
    "elif DATASET == \"synthetic\":\n",
    "    df_train = pd.read_csv(REWARD_MODEL_TRAIN_DATA_SYNTH, sep=\";\")\n",
    "    df_eval = pd.read_csv(REWARD_MODEL_EVAL_DATA_SYNTH, sep=\";\")\n",
    "    df_test = pd.read_csv(REWARD_MODEL_TEST_DATA_SYNTH, sep=\";\")\n",
    "    \n",
    "    \n",
    "df_train.shape\n",
    "df_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. a) Parse ratings to numeric values for MSE Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed feedback for extraction: 0    0\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    0\n",
      "Name: feedback_extraction, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df_train[FEEDBACK_TO_TRAIN_ON] = [parse_ratings(feedback) for feedback in df_train[FEEDBACK_TO_TRAIN_ON]]\n",
    "df_eval[FEEDBACK_TO_TRAIN_ON] = [parse_ratings(feedback) for feedback in df_eval[FEEDBACK_TO_TRAIN_ON]]\n",
    "df_test[FEEDBACK_TO_TRAIN_ON] = [parse_ratings(feedback) for feedback in df_test[FEEDBACK_TO_TRAIN_ON]]\n",
    "print(\"Parsed feedback for extraction:\", df_train[FEEDBACK_TO_TRAIN_ON][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. b) look at biases in feedback to train on for weights in RL loop --> feedback_detection is very biased through way it was collected, so gets less weight overall..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feedback_extraction\n",
       "0    265\n",
       "2     63\n",
       "1     35\n",
       "3     31\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[FEEDBACK_TO_TRAIN_ON].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. c) keep only relevant feedback column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['file', 'frame_ID', 'frame_type', 'frame_text', 'precondition_id', 'precondition_text', 'precondition_position', 'response_text', 'prompt_config_examples', 'prompt_config_chain_of_thought', 'feedback_extraction', 'feedback_detection', 'additional_feedback', 'synthetic_feedback'],\n",
      "    num_rows: 394\n",
      "})\n",
      "feedback_extraction\n"
     ]
    }
   ],
   "source": [
    "dataset_train = Dataset.from_pandas(df_train)\n",
    "dataset_eval = Dataset.from_pandas(df_eval)\n",
    "dataset_test = Dataset.from_pandas(df_test)\n",
    "\n",
    "print(dataset_train)\n",
    "print(FEEDBACK_TO_TRAIN_ON) \n",
    "\n",
    "datasets = [dataset_train, dataset_eval, dataset_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '1', '1', '0', '0', '0', '0', '3', '0', '0', '1', '0', '1', '1', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '3', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '2', '2', '0', '0', '2', '0', '0', '2', '2', '0', '0', '0', '0', '3', '0', '2', '2', '0', '0', '0', '0', '1', '1', '0', '0', '0', '1', '0', '0', '0', '3', '0', '0', '2', '0', '0', '0', '0', '0', '0', '0', '0', '0', '2', '0', '0', '0', '0', '2', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '1', '0', '2', '2', '0', '0', '3', '0', '3', '2', '2', '0', '0', '0', '0', '0', '0', '3', '2', '0', '0', '1', '0', '0', '2', '0', '2', '3', '0', '3', '0', '2', '0', '0', '2', '0', '0', '0', '0', '1', '2', '0', '2', '0', '2', '0', '0', '2', '2', '0', '0', '0', '1', '1', '0', '0', '0', '2', '1', '0', '2', '0', '1', '2', '0', '1', '0', '0', '3', '0', '0', '2', '2', '0', '0', '0', '3', '0', '3', '0', '0', '0', '3', '0', '0', '3', '0', '0', '2', '0', '0', '0', '0', '1', '3', '0', '0', '2', '0', '2', '0', '0', '0', '0', '2', '0', '0', '0', '0', '0', '0', '0', '2', '0', '0', '2', '0', '0', '0', '0', '0', '0', '0', '3', '3', '1', '0', '0', '0', '2', '2', '2', '0', '3', '0', '0', '0', '2', '0', '0', '3', '0', '0', '0', '0', '0', '0', '0', '2', '0', '3', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '2', '0', '0', '0', '1', '0', '2', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '2', '2', '0', '1', '0', '0', '0', '0', '0', '0', '3', '3', '0', '0', '0', '2', '3', '2', '3', '2', '3', '0', '2', '2', '1', '1', '0', '2', '0', '0', '2', '0', '0', '0', '3', '0', '0', '0', '3', '0', '0', '0', '0', '2', '0', '0', '0', '0', '0', '0', '0', '1', '1', '1', '2', '1', '2', '2', '1', '0', '3', '0', '0', '0', '1', '0', '0', '2', '0', '0', '2', '1', '0', '2', '0', '0', '3', '2', '0', '0', '0', '1', '3', '0', '2', '3', '0', '0', '0', '2', '2', '2', '0', '1', '0', '0', '0', '0', '0', '0', '0']\n"
     ]
    }
   ],
   "source": [
    "datasets= [dataset.remove_columns([FEEDBACK_TO_REMOVE]) for dataset in datasets]\n",
    "datasets = [dataset.rename_column(FEEDBACK_TO_TRAIN_ON, \"label\") for dataset in datasets]\n",
    "\n",
    "print(datasets[0][\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load model with LoRA layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nlpaueb/legal-bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertForSequenceClassification(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSdpaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (classifier): Linear(in_features=768, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Load the model and the tokenizer\n",
    "model_id = MODEL \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_id, num_labels=1) # num_labels = 1 since we want to prodict a single scalar (the rating)\n",
    "\n",
    "# Comment: Automodel for sequence classification with num_labels=1 already has a regression head\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "512\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.model_max_length)\n",
    "print(model.config.max_position_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 443,137 || all params: 109,926,146 || trainable%: 0.4031\n"
     ]
    }
   ],
   "source": [
    "# Define LoRA config\n",
    "\n",
    "\n",
    "if MODEL == \"answerdotai/ModernBERT-base\":\n",
    "\n",
    "    lora_config = LoraConfig(\n",
    "    r=8,           # Rank of the LoRA matrices (smaller = less memory)\n",
    "    lora_alpha=16, # Scaling factor (higher = stronger adaptation)\n",
    "    target_modules=[\"Wqkv\", \"Wo\"], # Apply LoRA to attention layers\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_CLS\"  # classify each answer \n",
    "    )\n",
    "else:\n",
    "    lora_config = LoraConfig(\n",
    "    r=8,           # Rank of the LoRA matrices (smaller = less memory)\n",
    "    lora_alpha=16, # Scaling factor (higher = stronger adaptation)\n",
    "    target_modules=[\"query\", \"key\", \"value\"], # Apply LoRA to attention layers\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_CLS\"  # classify each answer \n",
    "    )\n",
    "    \n",
    "\n",
    "# Freeze base model\n",
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "\n",
    "\n",
    "# Convert the model to a PEFT (LoRA) model\n",
    "peft_model = get_peft_model(model, lora_config)\n",
    "# model.gradient_checkpointing_enable()\n",
    "peft_model.print_trainable_parameters()  # Check trainable params (~0.1% of full model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 1067, 223, 207, 580, 210, 1335, 124, 102, 0, 0, 0], [101, 1067, 223, 207, 5601, 190, 580, 213, 207, 1727, 124, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test tokenizer\n",
    "sample_data = [\"What is the capital of France?\", \"What is the largest capital in the world?\"]\n",
    "tokenizer(sample_data, padding=True, truncation=True, max_length=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Encode dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['file', 'frame_ID', 'frame_type', 'frame_text', 'precondition_id', 'precondition_text', 'precondition_position', 'response_text', 'prompt_config_examples', 'prompt_config_chain_of_thought', 'label', 'additional_feedback', 'synthetic_feedback']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 394/394 [00:00<00:00, 11158.53 examples/s]\n",
      "Map: 100%|██████████| 85/85 [00:00<00:00, 7656.30 examples/s]\n",
      "Map: 100%|██████████| 85/85 [00:00<00:00, 9308.99 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 1, 1, 0]\n",
      "['1. Het college stelt het recht op bijstand ambtshalve vast indien:\\n                   - het in aanmerking te nemen inkomen lager is dan de bijstandsnorm; en\\n                   - er geen in aanmerking te nemen vermogen is.\\n                   Positie: Artikel 19, sectie 1, IN Hoofdstuk 3, Algemene bijstand, § 3.1, Wet op de Bijstand aan de arbeidsongeschikte, de arbeidsongeschikte zieke en de arbeidsongeschikte verzorgende.\\n\\n                2. De belanghebbende heeft zich gemeld als zijn naam, adres en woonplaats bij het Uitvoeringsinstituut werknemersverzekeringen zijn geregistreerd, en:\\n                   - indien artikel 41, vierde lid, van toepassing is: hij door het Uitvoeringsinstituut werknemersverzekeringen op de hoogte is gesteld van de verplichting, bedoeld in artikel 9, eerste lid, onderdeel a, en de inhoud van artikel 41;\\n                   - indien artikel 41, vierde lid, niet van toepassing is: hij in staat is gesteld zijn aanvraag in te dienen bij het Uitvoeringsinstituut werknemersverzekeringen, als het een aanvraag betreft als bedoeld in artikel 41, eerste of derde lid, of bij het college, als het een aanvraag betreft als bedoeld in artikel 41, tweede lid.\\n                   Positie: Artikel 44, sectie 2, IN Hoofdstuk 5, Uitvoering, § 5.1, Wet op de Bijstand aan de arbeidsongeschikte, de arbeidsongeschikte zieke en de arbeidsongeschikte verzorgende.', '1. De vreemdeling beschikt niet over een geldige machtiging tot voorlopig verblijf die overeenkomt met het verblijfsdoel waarvoor de verblijfsvergunning is aangevraagd. \\n\\n                Positie: Artikel 16, sub-sectie 1a, Algemene wet bestuursrecht\\n\\n                2. De vreemdeling beschikt niet over een geldig document voor grensoverschrijding.\\n\\n                Positie: Artikel 16, sub-sectie 1b, Algemene wet bestuursrecht\\n\\n                3. De vreemdeling niet zelfstandig en duurzaam beschikt over voldoende middelen van bestaan dan wel, indien de persoon bij wie de vreemdeling wil verblijven, niet zelfstandig en duurzaam beschikt over voldoende middelen van bestaan.\\n\\n                Positie: Artikel 16, sub-sectie 1c, Algemene wet bestuursrecht\\n\\n                4. De vreemdeling een gevaar vormt voor de openbare orde of nationale veiligheid.\\n\\n                Positie: Artikel 16, sub-sectie 1d, Algemene wet bestuursrecht\\n\\n                5. De vreemdeling niet bereid is om medewerking te verlenen aan een medisch onderzoek naar een ziekte aangewezen bij of krachtens de Wet publieke gezondheid, ter bescherming van de volksgezondheid of een medische behandeling tegen een dergelijke ziekte te ondergaan.\\n\\n                Positie: Artikel 16, sub-sectie 1e, Algemene wet bestuursrecht', '1. Subfact: De niet-departementale begroting wordt opgesteld door de juiste minister. \\n\\n                   Positie: Geen van de vermelde artikelen bevat een expliciete vermelding dat de niet-departementale begroting wordt opgesteld door de juiste minister. Het wordt echter wel aangegeven dat de ministers verantwoordelijk zijn voor het beheer van de niet-departementale begrotingen (Artikel 4.3, 4.4 van de Comptabiliteitswet 2016).\\n\\n                2. Subfact: De juiste minister is verantwoordelijk voor de opstelling van de niet-departementale begroting.\\n\\n                   Positie: Geen van de vermelde artikelen bevat een expliciete vermelding dat de juiste minister is verantwoordelijk voor de opstelling van de niet-departementale begroting. Het wordt echter wel aangegeven dat de ministers verantwoordelijk zijn voor het beheer van de niet-departementale begrotingen (Artikel 4.3, 4.4 van de Comptabiliteitswet 2016).\\n\\n                3. Subfact: De juiste minister is verantwoordelijk voor het opstellen van de niet-departementale begroting.\\n\\n                   Positie: Geen van de vermelde artikelen bevat een expliciete vermelding dat de juiste minister is verantwoordelijk voor het opstellen van de niet-departementale begroting. Het wordt echter wel aangegeven dat de ministers verantwoordelijk zijn voor het beheer van de niet-departementale begrotingen (Artikel 4.3, 4.4 van de Comptabiliteitswet 2016).\\n\\n                4. Subfact: De juiste minister stelt de niet-departementale begroting op.\\n\\n                   Positie: Geen van de vermelde artikelen bevat een expliciete vermelding dat de juiste minister stelt de niet-departementale begroting op. Het wordt echter wel aangegeven dat de ministers voor elk ministerie stellen voor de aanvang van een begrotingsjaar een begroting op (Artikel 2.1 van de Comptabiliteitswet 2016).\\n\\n                5. Subfact: De juiste minister maakt de niet-departementale begroting.\\n\\n                   Positie: Geen van de vermelde artikelen bevat een expliciete vermelding dat de juiste minister maakt de niet-departementale begroting. Het wordt echter wel aangegeven dat de ministers verantwoordelijk zijn voor het beheer van de niet-departementale begrotingen (Artikel 4.3, 4.4 van de Comptabiliteitswet 2016).\\n\\n                6. Subfact: De juiste minister is de maker van de niet-departementale begroting.\\n\\n                   Positie: Geen van de vermelde artikelen bevat een expliciete vermelding dat de juiste minister is de maker van de niet-departementale begroting. Het wordt echter wel aangegeven dat de ministers voor elk ministerie stellen voor de aanvang van een begrotingsjaar een begroting op (Artikel 2.1 van de Comptabiliteitswet 2016).', '1. Vreemdeling: ieder die de Nederlandse nationaliteit niet bezit en niet op grond van een wettelijke bepaling als Nederlander moet worden behandeld \\n \\n                Positie: Artikel 1, Algemene wet bestuursrecht\\n \\n                2. Vreemdeling: ieder die de Nederlandse nationaliteit niet bezit en niet op grond van een wettelijke bepaling als Nederlander moet worden behandeld; ieder die rechtmatig verblijf heeft op grond van artikel 8 \\n \\n                Positie: Artikel 8, Vreemdelingenwet\\n \\n                3. Vreemdeling: ieder die de Nederlandse nationaliteit niet bezit en niet op grond van een wettelijke bepaling als Nederlander moet worden behandeld; ieder die rechtmatig verblijf heeft op grond van artikel 8, onder a tot en met d, f tot en met h en j tot en met m, en aan de vreemdeling die rechtmatig verblijf heeft op grond van artikel 8, onder e, en gemeenschapsonderdaan is als bedoeld in artikel 1, sub 2°, 4° en 6° \\n \\n                Positie: Artikel 9, Vreemdelingenwet', '   Inhoud: <tekstfragment waarin de preconditie staat>\\n\\n\\n                Voorbeeld:\\n\\n\\n                Preconditie: De persoon heeft zich onttrekt aan de tenuitvoerlegging van een vrijheidsstraf of vrijheidsbenemende maatregel.\\n\\n                Positie: Artikel 13, sectie 1, letter b IN Hoofdstuk 3, Wet op de algemene bijstand\\n\\n                Inhoud: De persoon die zich onttrekt aan de tenuitvoerlegging van een vrijheidsstraf of vrijheidsbenemende maatregel heeft geen recht op bijstand.\\n\\n\\n                Preconditie: De persoon is jonger dan 18 jaar.\\n\\n                Positie: Artikel 13, sectie 1, letter f IN Hoofdstuk 3, Wet op de algemene bijstand\\n\\n                Inhoud: De persoon die jonger is dan 18 jaar heeft geen recht op bijstand.\\n\\n\\n                Preconditie: De persoon is een uitreiziger.\\n\\n                Positie: Artikel 13, sectie 1, letter h IN Hoofdstuk 3, Wet op de algemene bijstand\\n\\n                Inhoud: De persoon die een uitreiziger is heeft geen recht op bijstand.\\n\\n\\n                Preconditie: De persoon heeft een schuldenlast en beschikte over de middelen om in de noodzakelijke kosten van het bestaan te voorzien.\\n\\n                Positie: Artikel 12, sectie 1, letter g IN Hoofdstuk 2, Wet op de algemene bijstand\\n\\n                Inhoud: De persoon die een schuldenlast heeft en bij het ontstaan van de schuldenlast beschikte over de middelen om in de noodzakelijke kosten van het bestaan te voorzien heeft geen recht op bijstand.\\n\\n\\n                Preconditie: De persoon heeft rechtens zijn vrijheid ontnomen.\\n\\n                Positie: Artikel 13, sectie 1, letter a IN Hoofdstuk 3, Wet op de algemene bijstand\\n\\n                Inhoud: Geen recht op bijstand heeft degene aan wie rechtens zijn vrijheid is ontnomen.\\n\\n\\n                Preconditie: De persoon is jonger dan 27 jaar en uitwijkt van het onderwijs.\\n\\n                Positie: Artikel 2, sectie 2, letter d, onderdeel 2 IN Hoofdstuk 3, Wet op de algemene bijstand\\n\\n                Inhoud: De persoon die jonger is dan 27 jaar en uit ’s Rijks kas bekostigd onderwijs kan volgen en: in verband daarmee aanspraak heeft op studiefinanciering op grond van de Wet studiefinanciering 2000, dan wel in verband daarmee geen aanspraak heeft op studiefinanciering en dit onderwijs niet volgt; heeft geen recht op algemene bijstand.\\n\\n\\n                Preconditie: De persoon heeft geen recht op bijstand vanwege het feit dat hij zich onttrekt aan de arbeid.\\n\\n                Positie: Artikel 13, sectie 1, letter d IN Hoofdstuk 3, Wet op de algemene bijstand\\n\\n                Inhoud: De persoon die wegens werkstaking of uitsluiting niet deelneemt aan de arbeid, voorzover diens gebrek aan middelen daarvan het gevolg is, heeft geen recht op bijstand.\\n\\n\\n                Preconditie: De persoon heeft een uitreiziger geweest.\\n\\n                Positie: Artikel 13, sectie 1, letter h IN Hoofdstuk 3, Wet op de algemene bijstand\\n\\n                Inhoud: De persoon die een uitreiziger is heeft geen recht op bijstand.\\n\\n\\n                Preconditie: De persoon heeft zich in Nederland voor langer dan 4 weken buiten het land bevonden.\\n\\n                Positie: Artikel 13, sectie 1, letter e IN Hoofdstuk 3, Wet op de algemene bijstand\\n\\n                Inhoud: De persoon die per kalenderjaar langer dan vier weken verblijf houdt buiten Nederland dan wel een aaneengesloten periode van langer dan vier weken verblijf houdt buiten Nederland heeft geen recht op bijstand.\\n\\n\\n                Preconditie: De persoon heeft een onderhoudsrecht jegens zijn ouders en kan niet deze recht maken.\\n\\n                Positie: Artikel 12, sectie 1, letter b IN Hoofdstuk 2, Wet op de algemene bijstand\\n\\n                Inhoud: De persoon die redelijkerwijs zijn onderhoudsrecht jegens zijn ouders niet te gelde kan maken heeft recht op bijzondere bijstand voorzover zijn noodzakelijke kosten van het bestaan uitgaan boven de bijstandsnorm.\\n\\n\\n                Preconditie: De persoon heeft geen in aanmerking te nemen vermogen.\\n\\n                Positie: Artikel 19, sectie 1, onderdeel b IN Hoofdstuk 3, Wet op de algemene bijstand\\n\\n                Inhoud: De alleenstaande of het gezin heeft recht op algemene bijstand indien er geen in aanmerking te nemen vermogen is.\\n\\n\\n                Preconditie: De persoon heeft een in aanmerking te nemen inkomen dat lager is dan de bijstandsnorm.\\n\\n                Positie: Artikel 19, sectie 1, onderdeel a IN Hoofdstuk 3, Wet op de algemene bijstand\\n\\n                Inhoud: De alleenstaande of het gezin heeft recht op algemene bijstand indien het in aanmerking te nemen inkomen lager is dan de bijstandsnorm.\\n\\n\\n                Preconditie: De persoon heeft een kostendelende medebewoner.\\n\\n                Positie: Artikel 19a, sectie 1, onderdeel a IN Hoofdstuk 3, Wet op de algemene bijstand\\n\\n                Inhoud: In deze paragraaf wordt onder kostendelende medebewoner verstaan de persoon van 27 jaar of ouder die in dezelfde woning als de belanghebbende zijn hoofdverblijf heeft en niet: a. de echtgenoot van belanghebbende is; b. op basis van een schriftelijke overeenkomst met de belanghebbende, waarbij een commerciële prijs is overeengekomen, als verhuurder, huurder, onderverhuurder, kostgever of kostganger, niet zijnde een bloed- of aanverwant in de eerste of tweede graad van de belanghebbende, in dezelfde woning als de belanghebbende zijn hoofdverblijf heeft; c. op basis van een schriftelijke overeenkomst met een derde, waarbij een commerciële prijs is overeengekomen, als huurder, onderhuurder of kostganger in dezelfde woning als de belanghebbende zijn hoofdverblijf heeft, mits hij de overeenkomst heeft met dezelfde persoon als met wie de belanghebbende een schriftelijke overeenkomst heeft, waarbij een commerciële prijs is overeengekomen, als huurder, onderhuurder of kostganger; of d. een persoon is die: 1°. onderwijs volgt waarvoor aanspraak op studiefinanciering als bedoeld in artikel 3.1, eerste of tweede lid, van de Wet studiefinanciering 2000 kan bestaan en op enig moment tijdens dat onderwijs gelet op zijn leeftijd in aanmerking kan komen voor die studiefinanciering; 2°. onderwijs volgt waarvoor aanspraak kan bestaan op een tegemoetkoming op grond van hoofdstuk 4 van de Wet tegemoetkoming onderwijsbijdrage en schoolkosten en op enig moment tijdens dat onderwijs gelet op zijn leeftijd in aanmerking kan komen voor die tegemoetkoming; 3°. een beroepsopleiding als bedoeld in artikel 7.2.2, eerste lid, onderdelen a tot en met e, van de Wet educatie en beroepsonderwijs in de beroepsbegeleidende leerweg volgt; 4°. een vergelijkbaar soort onderwijs of beroepsopleiding als bedoeld onder 1° tot en met 3° volgt buiten Nederland, waarbij voor onder 1° en 2° geldt dat hij op enig moment tijdens dat onderwijs jonger dan 30 jaar is of in de maand van aanvang de leeftijd van 30 jaren heeft bereikt.\\n\\n\\n                Preconditie: De persoon is gehuwd en heeft geen recht op bijstand.\\n\\n                Positie: Artikel 4, sectie 4 IN Hoofdstuk 2, Wet op de algemene bijstand\\n\\n                Inhoud: Het recht op bijstand komt de echtgenoten gezamenlijk toe, tenzij een van de echtgenoten geen recht op bijstand heeft.\\n\\n\\n                Preconditie: De persoon is niet jonger dan 18 jaar.\\n\\n                Positie: Artikel 12, sectie 1 IN Hoofdstuk 2, Wet op de algemene bijstand\\n\\n                Inhoud: Een persoon van 18, 19 of 20 jaar heeft recht op bijzondere bijstand voorzover zijn noodzakelijke kosten van het bestaan uitgaan boven de bijstandsnorm en hij voor deze kosten geen beroep kan doen op zijn ouders, omdat: a. de middelen van de ouders daartoe niet toereikend zijn; of b. hij redelijkerwijs zijn onderhoudsrecht jegens zijn ouders niet te gelde kan maken.\\n\\n\\n                Preconditie: De persoon heeft een vakantietoeslag.\\n\\n                Positie: Artikel 19, sectie 3 IN Hoofdstuk 3, Wet op de algemene bijstand\\n\\n                Inhoud: In de algemene bijstand is een vakantietoeslag begrepen ter hoogte van 4,8 procent [Red: per 1 januari 2009: 5 procent] van die bijstand.\\n\\n\\n                Preconditie: De persoon is een echtgenoot en heeft een gezamenlijk inkomen dat hoger is dan de bijstandsnorm.\\n\\n                Positie: Artikel 19, sectie 1 IN Hoofdstuk 3, Wet op de algemene bijstand\\n\\n                Inhoud: De alleenstaande of het gezin heeft recht op algemene bijstand indien: a. het in aanmerking te nemen inkomen lager is dan de bijstandsnorm; en b. er geen in aanmerking te nemen vermogen is.\\n\\n\\n                Preconditie: De persoon heeft een onderhoudsplicht.\\n\\n                Positie: Artikel 12, sectie 1 IN Hoofdstuk 2, Wet op de algemene bijstand\\n\\n                Inhoud: Een persoon van 18, 19 of 20 jaar heeft recht op bijzondere bijstand voorzover zijn noodzakelijke kosten van het bestaan uitgaan boven de bijstandsnorm en hij voor deze kosten geen beroep kan doen']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(datasets[0].column_names)\n",
    "# mao string labels to integers\n",
    "datasets = [dataset.map(convert_label_to_int) for dataset in datasets]\n",
    "\n",
    "print(datasets[0][\"label\"][:5])  # Check labels\n",
    "print(datasets[0][\"response_text\"][:5])  # Check labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comment\n",
    "\n",
    "1. Needed for feedback extraction: precondition_text, response_text, label(rating feedback extraction)\n",
    "2. Needed for feedback detection: precondition_text, precondition_position, response_text, label (rating feedback detection)\n",
    "3. For the precondition position to be found well, it is a crucial for the model to find the precondition text (at least to a recognizable degree) as well, otherwise the precondition is not found at all..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1127 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "de juiste keuzes hebben gemaakt, of ze trouw zijn gebleven aan zichzelf. anderen proberen simpelweg de dag door te komen, met hoop op iets beters. in die momenten van stilte komt vaak het besef dat, hoewel we allemaal verschillende paden bewandelen, we een waarheid delen : dat het leven, ondanks al onze inspanningen en verlangens, nooit gemakkelijk is. of, zoals mijn grootmoeder het ooit zei terwijl ze haar handen vouwde na een lange dag werken op het land : [UNK] je moet weten, kind, het leven is nooit gemakkelijk, maar het is wel de moeite waard. [UNK] we worden gevormd door onze ervaringen, door de mensen die we ontmoeten en de obstakels die we overwinnen. elke fout, elk succes, elke traan en elke glimlach draagt bij aan wie we zijn. en toch, ondanks al die ervaringen, blijven we zoeken. naar betekenis. naar verbinding. naar rust. soms lijkt het alsof de wereld te snel draait. technologie verandert ons leven in een razend tempo, verwachtingen worden hoger, en de druk om te presteren neemt toe. in die chaos vergeten we soms stil te staan. te ademen. te voelen. maar juist in die momenten van rust vinden we vaak de antwoorden die we zo hard nodig hebben. de liefde, bijvoorbeeld, is een van de krachtigste krachten die ons voortdrijft. liefde voor een partner, een kind, een vriend, of zelfs voor een passie. het is die liefde die ons helpt vol te houden wanneer alles tegen\n"
     ]
    }
   ],
   "source": [
    "# Code to test bestw indow function\n",
    "\n",
    "test_text = \"\"\"\n",
    "        Titel: De Weg Door Het Leven\n",
    "\n",
    "Het leven is een reis vol onverwachte wendingen, een pad dat zich zelden rechtlijnig ontvouwt. Vanaf het moment dat we onze eerste ademhaling nemen, worden we ondergedompeld in een wereld die we nog moeten leren begrijpen. Als kind lijkt alles eenvoudig: lachen, spelen, ontdekken. Maar naarmate we ouder worden, beginnen de lagen van complexiteit zich op te stapelen. We leren dat mensen niet altijd zeggen wat ze bedoelen, dat keuzes consequenties hebben, en dat geluk soms vluchtiger is dan we zouden willen.\n",
    "\n",
    "In de vroege ochtenden, wanneer de zon net boven de horizon verschijnt en de wereld nog stil is, denken velen na over hun plaats in het grotere geheel. Sommigen vragen zich af of ze de juiste keuzes hebben gemaakt, of ze trouw zijn gebleven aan zichzelf. Anderen proberen simpelweg de dag door te komen, met hoop op iets beters. In die momenten van stilte komt vaak het besef dat, hoewel we allemaal verschillende paden bewandelen, we één waarheid delen: dat het leven, ondanks al onze inspanningen en verlangens, nooit gemakkelijk is. Of, zoals mijn grootmoeder het ooit zei terwijl ze haar handen vouwde na een lange dag werken op het land: “Je moet weten, kind, het leven is nooit gemakkelijk, maar het is wel de moeite waard.”\n",
    "\n",
    "We worden gevormd door onze ervaringen, door de mensen die we ontmoeten en de obstakels die we overwinnen. Elke fout, elk succes, elke traan en elke glimlach draagt bij aan wie we zijn. En toch, ondanks al die ervaringen, blijven we zoeken. Naar betekenis. Naar verbinding. Naar rust.\n",
    "\n",
    "Soms lijkt het alsof de wereld te snel draait. Technologie verandert ons leven in een razend tempo, verwachtingen worden hoger, en de druk om te presteren neemt toe. In die chaos vergeten we soms stil te staan. Te ademen. Te voelen. Maar juist in die momenten van rust vinden we vaak de antwoorden die we zo hard nodig hebben.\n",
    "\n",
    "De liefde, bijvoorbeeld, is een van de krachtigste krachten die ons voortdrijft. Liefde voor een partner, een kind, een vriend, of zelfs voor een passie. Het is die liefde die ons helpt vol te houden wanneer alles tegenzit. Die ons eraan herinnert waarom we begonnen zijn, waarom we blijven proberen.\n",
    "\n",
    "En dan is er verlies. Een onvermijdelijk onderdeel van het leven. We verliezen mensen, kansen, dromen. Maar in dat verlies schuilt ook groei. We leren loslaten, opnieuw beginnen, sterker worden. Het is pijnlijk, ja, maar ook noodzakelijk.\n",
    "\n",
    "Wanneer we terugkijken op ons leven, zijn het zelden de materiële zaken die we herinneren. Het zijn de momenten. De gesprekken bij kaarslicht. De wandelingen in de regen. De onverwachte lachbuien. De stilte van een gedeeld verdriet. Die momenten vormen de essentie van ons bestaan.\n",
    "\n",
    "Dus ja, het leven is vol uitdagingen. Het is rommelig, verwarrend, soms oneerlijk. Maar het is ook prachtig, rijk aan betekenis, en gevuld met kansen om te groeien, te leren en lief te hebben. En misschien is dat wel de grootste les van allemaal: dat we, ondanks alles, blijven kiezen voor hoop. Voor verbinding. Voor het leven zelf.\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "test_ground_truth = \"Het leven is nooit gemakkelijk.\"\n",
    "\n",
    "print(find_best_window(test_text, test_ground_truth, device, tokenizer))\n",
    "\n",
    "# Works as expectd, I am impressed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/394 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 394/394 [05:43<00:00,  1.15 examples/s]\n",
      "Map: 100%|██████████| 85/85 [01:09<00:00,  1.21 examples/s]\n",
      "Map: 100%|██████████| 85/85 [01:18<00:00,  1.08 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 394/394 [00:00<00:00, 55647.23 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 85/85 [00:00<00:00, 19809.74 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 85/85 [00:00<00:00, 22312.92 examples/s]\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(TOKENIZED_DATA_TRAIN) or True:\n",
    "    if TOKENIZE_FN == \"best_window\":\n",
    "        datasets = [dataset.map(tokenize_fn_with_best_window, \n",
    "                            fn_kwargs={\"feedback_train\": FEEDBACK_TO_TRAIN_ON, \n",
    "                                        \"tokenizer\": tokenizer, \n",
    "                                        \"max_length\": int(MAX_LENGTH), \n",
    "                                        \"stride\": int(STRIDE),\n",
    "                                        \"device\": device\n",
    "                                        },\n",
    "                            batched=False) for dataset in datasets]\n",
    "    else:\n",
    "        datasets = [dataset.map(tokenize_fn_basic_batched, \n",
    "                            fn_kwargs={\"feedback_train\": FEEDBACK_TO_TRAIN_ON, \n",
    "                                        \"tokenizer\": tokenizer \n",
    "                                        },\n",
    "                            batched=True) for dataset in datasets]\n",
    "\n",
    "\n",
    "    datasets[0].save_to_disk(TOKENIZED_DATA_TRAIN)\n",
    "    datasets[1].save_to_disk(TOKENIZED_DATA_EVAL)\n",
    "    datasets[2].save_to_disk(TOKENIZED_DATA_TEST)\n",
    "else:\n",
    "    datasets[0] = load_from_disk(TOKENIZED_DATA_TRAIN)\n",
    "    datasets[1] = load_from_disk(TOKENIZED_DATA_TEST)\n",
    "    datasets[2] = load_from_disk(TOKENIZED_DATA_EVAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Participatiewet_most_recent_public.json': 140, 'Interpretatie_Vw_over_besluiten_op_aanvragen_voor_een_verblijfsvergunning_regulier_bepaalde_tijd.json': 134, 'rijksbegrotingscyclus.json': 120})\n"
     ]
    }
   ],
   "source": [
    "print(Counter(datasets[0]['file']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train reward model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Training arguments\n",
    "\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "\n",
    "#TODO: switch to cross entropy loss...\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=LORA_CHECKPOINTS_FOLDER,\n",
    "    eval_strategy='steps',\n",
    "    save_strategy='steps',\n",
    "    save_steps=40,\n",
    "    eval_steps=40,\n",
    "    save_total_limit=3,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    learning_rate=3e-4,\n",
    "    num_train_epochs=10,\n",
    "    logging_steps=10,\n",
    "    label_names=[\"labels\"],\n",
    "    # report_to=\"none\",\n",
    "    logging_dir=\"./logs\",\n",
    "    # fp16=True,  # Use mixed precision training\n",
    "    metric_for_best_model=\"eval_loss\", # or \"eval_loss\"\n",
    "    greater_is_better=False, # False if using loss\n",
    "    # gradient_accumulation_steps=4, # \n",
    "    # torch_compile=False\n",
    "    # weight_decay=0.01\n",
    "    warmup_steps=82, \n",
    ")\n",
    "\n",
    "# Initialize custom trainer\n",
    "trainer = CustomRewardTrainer(\n",
    "    model=peft_model,\n",
    "    args=training_args,\n",
    "    train_dataset=datasets[0],\n",
    "    eval_dataset=datasets[1],\n",
    "    # compute_metrics=trainer.compute_metrics,  # Use the custom metrics function\n",
    "    processing_class=tokenizer,\n",
    "    loss_type=\"huber\",  # \"mse\" or \"huber\"\n",
    "    weight_strategy=\"linear\",  # \"linear\", \"inverse\", or None\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "print(trainer.args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjacques-furst123\u001b[0m (\u001b[33mjacques-furst123-none\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.20.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jacques.furst/development/RAG/flintfiller-precondition-rl/rl_training_new/wandb/run-20250624_104446-v5mwh1g9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jacques-furst123-none/huggingface/runs/v5mwh1g9' target=\"_blank\">/home/jacques.furst/development/RAG/flintfiller-precondition-rl/reward_training_files/lora_checkpoints</a></strong> to <a href='https://wandb.ai/jacques-furst123-none/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jacques-furst123-none/huggingface' target=\"_blank\">https://wandb.ai/jacques-furst123-none/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jacques-furst123-none/huggingface/runs/v5mwh1g9' target=\"_blank\">https://wandb.ai/jacques-furst123-none/huggingface/runs/v5mwh1g9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='990' max='990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [990/990 01:04, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.683200</td>\n",
       "      <td>0.988718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.106800</td>\n",
       "      <td>0.682266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.662900</td>\n",
       "      <td>0.324600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.430400</td>\n",
       "      <td>0.350311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.305700</td>\n",
       "      <td>0.282960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.366400</td>\n",
       "      <td>0.231883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.286400</td>\n",
       "      <td>0.148038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.218200</td>\n",
       "      <td>0.160490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.323400</td>\n",
       "      <td>0.139623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.196000</td>\n",
       "      <td>0.120666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.083200</td>\n",
       "      <td>0.128449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.171100</td>\n",
       "      <td>0.164564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.103600</td>\n",
       "      <td>0.128142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.123400</td>\n",
       "      <td>0.157984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.161000</td>\n",
       "      <td>0.175876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>0.103400</td>\n",
       "      <td>0.124859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>0.116800</td>\n",
       "      <td>0.108517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.109400</td>\n",
       "      <td>0.129742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>0.076800</td>\n",
       "      <td>0.141835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.161455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.151800</td>\n",
       "      <td>0.124056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>0.033600</td>\n",
       "      <td>0.129390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>0.214000</td>\n",
       "      <td>0.110667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.090500</td>\n",
       "      <td>0.112347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jacques.furst/development/RAG/flintfiller-precondition-rl/rl_training_new/utils.py:289: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.huber_loss(logits, labels, reduction=\"none\", delta=1.0) #--> balances between MSE and MAE for data that has outliers/ noise\n",
      "/home/jacques.furst/development/RAG/flintfiller-precondition-rl/rl_training_new/utils.py:289: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.huber_loss(logits, labels, reduction=\"none\", delta=1.0) #--> balances between MSE and MAE for data that has outliers/ noise\n",
      "/home/jacques.furst/development/RAG/flintfiller-precondition-rl/rl_training_new/utils.py:289: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.huber_loss(logits, labels, reduction=\"none\", delta=1.0) #--> balances between MSE and MAE for data that has outliers/ noise\n",
      "/home/jacques.furst/development/RAG/flintfiller-precondition-rl/rl_training_new/utils.py:289: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.huber_loss(logits, labels, reduction=\"none\", delta=1.0) #--> balances between MSE and MAE for data that has outliers/ noise\n",
      "/home/jacques.furst/development/RAG/flintfiller-precondition-rl/rl_training_new/utils.py:289: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.huber_loss(logits, labels, reduction=\"none\", delta=1.0) #--> balances between MSE and MAE for data that has outliers/ noise\n",
      "/home/jacques.furst/development/RAG/flintfiller-precondition-rl/rl_training_new/utils.py:289: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.huber_loss(logits, labels, reduction=\"none\", delta=1.0) #--> balances between MSE and MAE for data that has outliers/ noise\n",
      "/home/jacques.furst/development/RAG/flintfiller-precondition-rl/rl_training_new/utils.py:289: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.huber_loss(logits, labels, reduction=\"none\", delta=1.0) #--> balances between MSE and MAE for data that has outliers/ noise\n",
      "/home/jacques.furst/development/RAG/flintfiller-precondition-rl/rl_training_new/utils.py:289: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.huber_loss(logits, labels, reduction=\"none\", delta=1.0) #--> balances between MSE and MAE for data that has outliers/ noise\n",
      "/home/jacques.furst/development/RAG/flintfiller-precondition-rl/rl_training_new/utils.py:289: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.huber_loss(logits, labels, reduction=\"none\", delta=1.0) #--> balances between MSE and MAE for data that has outliers/ noise\n",
      "/home/jacques.furst/development/RAG/flintfiller-precondition-rl/rl_training_new/utils.py:289: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.huber_loss(logits, labels, reduction=\"none\", delta=1.0) #--> balances between MSE and MAE for data that has outliers/ noise\n",
      "/home/jacques.furst/development/RAG/flintfiller-precondition-rl/rl_training_new/utils.py:289: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.huber_loss(logits, labels, reduction=\"none\", delta=1.0) #--> balances between MSE and MAE for data that has outliers/ noise\n",
      "/home/jacques.furst/development/RAG/flintfiller-precondition-rl/rl_training_new/utils.py:289: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.huber_loss(logits, labels, reduction=\"none\", delta=1.0) #--> balances between MSE and MAE for data that has outliers/ noise\n",
      "/home/jacques.furst/development/RAG/flintfiller-precondition-rl/rl_training_new/utils.py:289: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.huber_loss(logits, labels, reduction=\"none\", delta=1.0) #--> balances between MSE and MAE for data that has outliers/ noise\n",
      "/home/jacques.furst/development/RAG/flintfiller-precondition-rl/rl_training_new/utils.py:289: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.huber_loss(logits, labels, reduction=\"none\", delta=1.0) #--> balances between MSE and MAE for data that has outliers/ noise\n",
      "/home/jacques.furst/development/RAG/flintfiller-precondition-rl/rl_training_new/utils.py:289: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.huber_loss(logits, labels, reduction=\"none\", delta=1.0) #--> balances between MSE and MAE for data that has outliers/ noise\n",
      "/home/jacques.furst/development/RAG/flintfiller-precondition-rl/rl_training_new/utils.py:289: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.huber_loss(logits, labels, reduction=\"none\", delta=1.0) #--> balances between MSE and MAE for data that has outliers/ noise\n",
      "/home/jacques.furst/development/RAG/flintfiller-precondition-rl/rl_training_new/utils.py:289: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.huber_loss(logits, labels, reduction=\"none\", delta=1.0) #--> balances between MSE and MAE for data that has outliers/ noise\n",
      "/home/jacques.furst/development/RAG/flintfiller-precondition-rl/rl_training_new/utils.py:289: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.huber_loss(logits, labels, reduction=\"none\", delta=1.0) #--> balances between MSE and MAE for data that has outliers/ noise\n",
      "/home/jacques.furst/development/RAG/flintfiller-precondition-rl/rl_training_new/utils.py:289: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.huber_loss(logits, labels, reduction=\"none\", delta=1.0) #--> balances between MSE and MAE for data that has outliers/ noise\n",
      "/home/jacques.furst/development/RAG/flintfiller-precondition-rl/rl_training_new/utils.py:289: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.huber_loss(logits, labels, reduction=\"none\", delta=1.0) #--> balances between MSE and MAE for data that has outliers/ noise\n",
      "/home/jacques.furst/development/RAG/flintfiller-precondition-rl/rl_training_new/utils.py:289: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.huber_loss(logits, labels, reduction=\"none\", delta=1.0) #--> balances between MSE and MAE for data that has outliers/ noise\n",
      "/home/jacques.furst/development/RAG/flintfiller-precondition-rl/rl_training_new/utils.py:289: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.huber_loss(logits, labels, reduction=\"none\", delta=1.0) #--> balances between MSE and MAE for data that has outliers/ noise\n",
      "/home/jacques.furst/development/RAG/flintfiller-precondition-rl/rl_training_new/utils.py:289: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.huber_loss(logits, labels, reduction=\"none\", delta=1.0) #--> balances between MSE and MAE for data that has outliers/ noise\n",
      "/home/jacques.furst/development/RAG/flintfiller-precondition-rl/rl_training_new/utils.py:289: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.huber_loss(logits, labels, reduction=\"none\", delta=1.0) #--> balances between MSE and MAE for data that has outliers/ noise\n"
     ]
    }
   ],
   "source": [
    "# if not os.path.exists(FINAL_LORA_ADAPTERS):\n",
    "# train model\n",
    "trainer.train()\n",
    "# # store final model parameters\n",
    "peft_model.save_pretrained(FINAL_LORA_ADAPTERS)\n",
    "\n",
    "# #TODO: not storing this properly I suppose, need to change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reload saved LoRA adapter for inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nlpaueb/legal-bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "base_model_test = AutoModelForSequenceClassification.from_pretrained(MODEL, num_labels=1)\n",
    "\n",
    "\n",
    "# config = PeftConfig.from_pretrained(FINAL_LORA_ADAPTERS)\n",
    "# base_model_test = AutoModelForSequenceClassification.from_pretrained(config.base_model_name_or_path, num_labels=1)\n",
    "\n",
    "new_model = PeftModel.from_pretrained(base_model_test, FINAL_LORA_ADAPTERS)\n",
    "# new_model = new_model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jacques.furst/development/RAG/flintfiller-precondition-rl/reward_training_files/final_lora_adapters_feedback_extraction_best_window_synthetic\n"
     ]
    }
   ],
   "source": [
    "print(FINAL_LORA_ADAPTERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize trainer with new model\n",
    "trainer = CustomRewardTrainer(\n",
    "    model=new_model,\n",
    "    args=training_args,\n",
    "    train_dataset=datasets[0],\n",
    "    eval_dataset=datasets[1],\n",
    "    # compute_metrics=trainer.compute_metrics,  # Use the custom metrics function\n",
    "    processing_class=tokenizer,\n",
    "    loss_type=\"huber\",  # \"mse\" or \"huber\"\n",
    "    weight_strategy=\"linear\",  # \"linear\", \"inverse\", or None\n",
    "    # callbacks=[EarlyStoppingCallback(early_stopping_patience=50)] # use early stopping since we are sing high amount of epochs\n",
    "    # data_collator=RewardDataCollator()\n",
    "    # torch_compile=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 1/22 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jacques.furst/development/RAG/flintfiller-precondition-rl/rl_training_new/utils.py:289: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.huber_loss(logits, labels, reduction=\"none\", delta=1.0) #--> balances between MSE and MAE for data that has outliers/ noise\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results: {'eval_loss': 0.352273166179657, 'eval_model_preparation_time': 0.0064, 'eval_runtime': 0.4502, 'eval_samples_per_second': 188.808, 'eval_steps_per_second': 48.868}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_results = trainer.evaluate(eval_dataset=datasets[2])\n",
    "print(\"Test Results:\", test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1: Predicted Rating: -0.06262409687042236, True Rating: 0\n",
      "Sample 2: Predicted Rating: 0.002692139707505703, True Rating: 0\n",
      "Sample 3: Predicted Rating: 0.17508560419082642, True Rating: 0\n",
      "Sample 4: Predicted Rating: 0.06614108383655548, True Rating: 0\n",
      "Sample 5: Predicted Rating: 0.44440513849258423, True Rating: 0\n",
      "Sample 6: Predicted Rating: -0.013227694667875767, True Rating: 0\n",
      "Sample 7: Predicted Rating: 0.2783017158508301, True Rating: 2\n",
      "Sample 8: Predicted Rating: -0.04929590970277786, True Rating: 0\n",
      "Sample 9: Predicted Rating: -0.12832462787628174, True Rating: 0\n",
      "Sample 10: Predicted Rating: -0.06848514825105667, True Rating: 0\n",
      "Sample 11: Predicted Rating: -0.049879059195518494, True Rating: 0\n",
      "Sample 12: Predicted Rating: 0.06139906495809555, True Rating: 0\n",
      "Sample 13: Predicted Rating: -0.24118205904960632, True Rating: 0\n",
      "Sample 14: Predicted Rating: -0.08462418615818024, True Rating: 0\n",
      "Sample 15: Predicted Rating: 2.085700750350952, True Rating: 2\n",
      "Sample 16: Predicted Rating: 0.10471564531326294, True Rating: 0\n",
      "Sample 17: Predicted Rating: 1.1507039070129395, True Rating: 1\n",
      "Sample 18: Predicted Rating: 0.10437417030334473, True Rating: 1\n",
      "Sample 19: Predicted Rating: -0.06663914769887924, True Rating: 0\n",
      "Sample 20: Predicted Rating: -0.02816673368215561, True Rating: 0\n"
     ]
    }
   ],
   "source": [
    "# evaluate model manually on some test cases\n",
    "new_model.to(device)\n",
    "new_model.eval()\n",
    "\n",
    "#TODO: change tokenization function here!\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(20):\n",
    "        sample = datasets[2][i]\n",
    "        inputs = tokenizer(sample['precondition_text'] + \" \" + sample['response_text'], return_tensors='pt', truncation=True, padding=\"max_length\").to(device)\n",
    "        outputs = new_model(**inputs)\n",
    "        prediction = outputs.logits.item()\n",
    "        print(f\"Sample {i+1}: Predicted Rating: {prediction}, True Rating: {sample['label']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test reward model on prompt structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1: Predicted Rating: 1.946418046951294\n"
     ]
    }
   ],
   "source": [
    "response_text = \"\"\"\n",
    "                Inhoud: <inhoud>\n",
    "                 <details>\n",
    "                 <summary>parsering</summary>\n",
    "                 <pre>\n",
    "                 <code>\n",
    "        subfact\n",
    "                 </code>\n",
    "                 </pre>\n",
    "                 </details>\n",
    " \n",
    "                 Resultaat:\n",
    "\n",
    "\n",
    "                Subfact: vreemdeling \n",
    " \n",
    "                Positie: Artikel 8 IN Verordening vreemdelingenattributen\n",
    " \n",
    "                Inhoud: de vreemdeling heeft in Nederland uitsluitend rechtmatig verblijf:\n",
    "                <details>\n",
    "                <summary>parsering</summary>\n",
    "                <pre>\n",
    "                <code>\n",
    "        de vreemdeling\n",
    "                </code>\n",
    "                </pre>\n",
    "                </details>\n",
    " \n",
    "                Subfact: vreemdeling \n",
    " \n",
    "                Positie: Artikel 8 IN Verordening vreemdelingenattributen\n",
    " \n",
    "                Inhoud: het verblijf van een vreemdeling in Nederland op grond van deze wet anders dan op de \n",
    "                gronden bedoeld in de artikelen 29 en 34\n",
    "                <details>\n",
    "                <summary>parsering</summary>\n",
    "                <pre>\n",
    "                <code>\n",
    "        het verblijf van een vreemdeling\n",
    "                </code>\n",
    "                </pre>\n",
    "                </details>\n",
    " \n",
    "                Subfact: vreemdeling \n",
    " \n",
    "                Positie: Artikel 8, onder a IN Verordening vreemdelingenattributen\n",
    " \n",
    "                Inhoud: op grond van een verblijfsvergunning voor bepaalde tijd als bedoeld in artikel 14;\n",
    "                <details>\n",
    "                <summary>parsering</summary>\n",
    "                <pre>\n",
    "                <code>\n",
    "        op grond van een verblijfsvergunning voor bepaalde tijd\n",
    "                </code>\n",
    "                </pre>\n",
    "                </details>\n",
    "                \"\"\"\n",
    "\n",
    "precon_text = \"NOT ieder die op grond van een wettelijke bepaling als Nederlander moet worden behandeld\"\n",
    "\n",
    "with torch.no_grad():\n",
    "    inputs = tokenizer(precon_text + \" \" + response_text, return_tensors='pt', truncation=True, padding=\"max_length\").to(device)\n",
    "    outputs = new_model(**inputs)\n",
    "    prediction = outputs.logits.item()\n",
    "    print(f\"Sample {1}: Predicted Rating: {prediction}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reward_model_training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
