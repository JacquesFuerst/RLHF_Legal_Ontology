{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tune reward model from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODOs:\n",
    "\n",
    "#TODO: double-check that labels are not somehow misaligned...\n",
    "\n",
    "#TODO: check if you need to plot \n",
    "\n",
    "1. LoRA learns the position of the low rank adaptation matrix that is needed to finetune a model of a much higher rank\n",
    "\n",
    "#TODO: double check model performance, generate output, maybe adjust training metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports, setup, and global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jacques.furst/miniconda3/envs/RL/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "CUDA is available. Using GPU: NVIDIA L40S\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Add the parent directory to the Python path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.dirname(os.getcwd()), '..')))\n",
    "\n",
    "from transformers import TrainingArguments, EarlyStoppingCallback\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from datasets import Dataset, DatasetDict, load_from_disk\n",
    "\n",
    "from peft import LoraConfig, get_peft_model, PeftModel\n",
    "\n",
    "from utils import parse_ratings, tokenize_fn_with_best_window, tokenize_fn_basic_batched, CustomRewardTrainer, find_best_window, convert_label_to_int\n",
    "\n",
    "\n",
    "# from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# load the relevant devices available on the server\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = os.getenv(\"AVAILABLE_DEVICES\")\n",
    "\n",
    "# Enable expandable CUDA segments\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "# load cuda\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print(\"CUDA is available. Using GPU:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"CUDA is not available. Using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training variables\n",
    "FEEDBACK_TO_TRAIN_ON = os.getenv(\"FEEDBACK_TO_TRAIN_ON\")\n",
    "FEEDBACK_TO_REMOVE = os.getenv(\"FEEDBACK_TO_REMOVE\")\n",
    "MODEL = os.getenv(\"REWARD_MODEL\")\n",
    "DATASET = os.getenv(\"REWARD_DATASET\")\n",
    "TOKENIZE_FN = os.getenv(\"TOKENIZE_FN\")\n",
    "MAX_LENGTH = os.getenv(\"MAX_LENGTH\")\n",
    "STRIDE = os.getenv(\"STRIDE\")\n",
    "LORA_CHECKPOINTS_FOLDER = os.getenv(\"LORA_CHECKPOINTS_FOLDER\")\n",
    "\n",
    "#TODO: change this to not store model since contains /!!!\n",
    "FINAL_LORA_ADAPTERS = os.getenv(\"FINAL_LORA_ADAPTERS_FOLDER\") + f\"_{FEEDBACK_TO_TRAIN_ON}_{TOKENIZE_FN}_{DATASET}\"\n",
    "TOKENIZED_DATA_TRAIN = os.getenv(\"TOKENIZED_DATA\") + f\"_{FEEDBACK_TO_TRAIN_ON}_{TOKENIZE_FN}_{DATASET}_train\"\n",
    "TOKENIZED_DATA_EVAL = os.getenv(\"TOKENIZED_DATA\") + f\"_{FEEDBACK_TO_TRAIN_ON}_{TOKENIZE_FN}_{DATASET}_eval\"\n",
    "TOKENIZED_DATA_TEST = os.getenv(\"TOKENIZED_DATA\") + f\"_{FEEDBACK_TO_TRAIN_ON}_{TOKENIZE_FN}_{DATASET}_test\"\n",
    "DATASET_STRUCTURE = os.getenv(\"DATASET_STRUCTURE\")\n",
    "\n",
    "REWARD_DATA_PATH = os.getenv(\"REWARD_DATA_PATH\")\n",
    "\n",
    "if DATASET_STRUCTURE == \"determined\":\n",
    "    REWARD_MODEL_TRAIN_DATA_HUMAN = REWARD_DATA_PATH + \"/train_human_determined.csv\"\n",
    "    REWARD_MODEL_EVAL_DATA_HUMAN = REWARD_DATA_PATH + \"/validation_human_determined.csv\"\n",
    "    REWARD_MODEL_TEST_DATA_HUMAN = REWARD_DATA_PATH + \"/test_human_determined.csv\"\n",
    "\n",
    "    REWARD_MODEL_TRAIN_DATA_SYNTH = REWARD_DATA_PATH + \"/train_synth_determined.csv\"\n",
    "    REWARD_MODEL_EVAL_DATA_SYNTH = REWARD_DATA_PATH + \"/validation_synth_determined.csv\"\n",
    "    REWARD_MODEL_TEST_DATA_SYNTH = REWARD_DATA_PATH + \"/test_synth_determined.csv\"\n",
    "\n",
    "elif DATASET_STRUCTURE == \"random\":\n",
    "    REWARD_MODEL_TRAIN_DATA_HUMAN = REWARD_DATA_PATH + \"/train_human_random.csv\"\n",
    "    REWARD_MODEL_EVAL_DATA_HUMAN = REWARD_DATA_PATH + \"/validation_human_random.csv\"\n",
    "    REWARD_MODEL_TEST_DATA_HUMAN = REWARD_DATA_PATH + \"/test_human_random.csv\"\n",
    "\n",
    "    REWARD_MODEL_TRAIN_DATA_SYNTH = REWARD_DATA_PATH + \"/train_synth_random.csv\"\n",
    "    REWARD_MODEL_EVAL_DATA_SYNTH = REWARD_DATA_PATH + \"/validation_synth_random.csv\"\n",
    "    REWARD_MODEL_TEST_DATA_SYNTH = REWARD_DATA_PATH + \"/test_synth_random.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset loading and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Re-structure df synthetic to fit in training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['file', 'frame_ID', 'frame_type', 'frame_text', 'precondition_id',\n",
       "       'precondition_text', 'precondition_position', 'response_text',\n",
       "       'prompt_config_examples', 'prompt_config_chain_of_thought',\n",
       "       'feedback_extraction', 'feedback_detection', 'additional_feedback'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if DATASET == \"human\":\n",
    "    df_train = pd.read_csv(REWARD_MODEL_TRAIN_DATA_HUMAN, sep=\";\")\n",
    "    df_eval = pd.read_csv(REWARD_MODEL_EVAL_DATA_HUMAN, sep=\";\")\n",
    "    df_test = pd.read_csv(REWARD_MODEL_TEST_DATA_HUMAN, sep=\";\")\n",
    "elif DATASET == \"synthetic\":\n",
    "    df_train = pd.read_csv(REWARD_MODEL_TRAIN_DATA_SYNTH, sep=\";\")\n",
    "    df_eval = pd.read_csv(REWARD_MODEL_EVAL_DATA_SYNTH, sep=\";\")\n",
    "    df_test = pd.read_csv(REWARD_MODEL_TEST_DATA_SYNTH, sep=\";\")\n",
    "    \n",
    "    \n",
    "df_train.shape\n",
    "df_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. a) Parse ratings to numeric values for MSE Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed feedback for extraction: 0    3\n",
      "1    0\n",
      "2    2\n",
      "3    0\n",
      "4    3\n",
      "Name: feedback_extraction, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df_train[FEEDBACK_TO_TRAIN_ON] = [parse_ratings(feedback) for feedback in df_train[FEEDBACK_TO_TRAIN_ON]]\n",
    "df_eval[FEEDBACK_TO_TRAIN_ON] = [parse_ratings(feedback) for feedback in df_eval[FEEDBACK_TO_TRAIN_ON]]\n",
    "df_test[FEEDBACK_TO_TRAIN_ON] = [parse_ratings(feedback) for feedback in df_test[FEEDBACK_TO_TRAIN_ON]]\n",
    "print(\"Parsed feedback for extraction:\", df_train[FEEDBACK_TO_TRAIN_ON][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. b) look at biases in feedback to train on for weights in RL loop --> feedback_detection is very biased through way it was collected, so gets less weight overall..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feedback_extraction\n",
       "0    347\n",
       "3    168\n",
       "2     72\n",
       "1     63\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[FEEDBACK_TO_TRAIN_ON].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. c) keep only relevant feedback column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['file', 'frame_ID', 'frame_type', 'frame_text', 'precondition_id', 'precondition_text', 'precondition_position', 'response_text', 'prompt_config_examples', 'prompt_config_chain_of_thought', 'feedback_extraction', 'feedback_detection', 'additional_feedback'],\n",
      "    num_rows: 650\n",
      "})\n",
      "feedback_extraction\n"
     ]
    }
   ],
   "source": [
    "dataset_train = Dataset.from_pandas(df_train)\n",
    "dataset_eval = Dataset.from_pandas(df_eval)\n",
    "dataset_test = Dataset.from_pandas(df_test)\n",
    "\n",
    "print(dataset_train)\n",
    "print(FEEDBACK_TO_TRAIN_ON) \n",
    "\n",
    "datasets = [dataset_train, dataset_eval, dataset_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3', '0', '2', '0', '3', '0', '0', '2', '2', '0', '0', '0', '0', '0', '3', '0', '0', '2', '3', '3', '3', '0', '3', '0', '0', '1', '0', '0', '0', '1', '0', '0', '0', '1', '0', '0', '0', '2', '0', '0', '3', '3', '3', '0', '3', '0', '0', '0', '0', '3', '0', '0', '0', '3', '2', '0', '3', '0', '1', '3', '3', '0', '2', '0', '3', '0', '0', '1', '3', '2', '0', '3', '0', '0', '0', '0', '3', '0', '0', '0', '3', '1', '0', '0', '0', '3', '0', '2', '3', '0', '0', '0', '2', '0', '1', '0', '0', '3', '3', '0', '0', '2', '3', '0', '1', '2', '0', '3', '3', '0', '0', '1', '0', '3', '3', '0', '0', '3', '0', '2', '2', '3', '0', '0', '3', '0', '0', '0', '2', '0', '3', '3', '0', '2', '2', '0', '0', '3', '0', '0', '1', '0', '3', '0', '1', '3', '0', '0', '0', '0', '3', '2', '0', '0', '2', '1', '0', '3', '3', '0', '3', '2', '0', '0', '0', '0', '3', '3', '1', '0', '0', '3', '0', '0', '3', '2', '0', '0', '0', '0', '2', '3', '2', '0', '0', '0', '3', '3', '0', '0', '1', '3', '2', '3', '2', '3', '0', '0', '0', '1', '3', '3', '2', '0', '1', '0', '0', '0', '0', '0', '0', '3', '1', '1', '0', '2', '3', '0', '1', '3', '3', '3', '1', '3', '0', '3', '0', '2', '0', '0', '0', '1', '3', '0', '3', '1', '2', '0', '2', '0', '0', '3', '0', '1', '3', '3', '0', '0', '3', '1', '3', '3', '0', '0', '0', '3', '0', '0', '2', '0', '0', '3', '0', '3', '0', '1', '2', '0', '1', '1', '3', '0', '0', '2', '1', '1', '3', '0', '3', '0', '0', '3', '0', '0', '3', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '3', '0', '3', '0', '0', '0', '0', '0', '0', '0', '0', '3', '0', '3', '0', '3', '3', '0', '0', '0', '0', '0', '3', '2', '3', '0', '0', '3', '0', '0', '0', '0', '3', '0', '3', '0', '0', '2', '0', '0', '3', '3', '0', '0', '0', '3', '0', '0', '2', '0', '0', '0', '3', '0', '0', '3', '0', '2', '3', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '3', '0', '1', '3', '0', '1', '3', '2', '0', '0', '0', '0', '2', '0', '0', '0', '0', '3', '0', '1', '1', '0', '0', '1', '0', '0', '2', '3', '1', '2', '0', '1', '0', '3', '3', '3', '1', '1', '0', '3', '3', '1', '1', '3', '0', '3', '0', '1', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '3', '0', '0', '0', '2', '0', '2', '0', '2', '3', '2', '0', '3', '0', '1', '3', '1', '0', '2', '0', '0', '3', '3', '0', '0', '2', '0', '3', '1', '0', '0', '3', '3', '2', '3', '0', '2', '0', '0', '0', '0', '0', '0', '3', '0', '3', '0', '2', '0', '0', '0', '0', '0', '0', '3', '2', '2', '0', '3', '1', '3', '3', '2', '0', '0', '2', '3', '0', '0', '3', '3', '0', '3', '3', '0', '0', '3', '2', '0', '0', '0', '0', '3', '0', '0', '3', '1', '0', '0', '2', '3', '1', '0', '3', '3', '3', '1', '0', '3', '3', '2', '3', '0', '3', '3', '0', '0', '3', '2', '0', '0', '0', '3', '0', '0', '0', '3', '3', '3', '0', '0', '0', '2', '3', '0', '3', '0', '2', '2', '0', '3', '3', '2', '0', '3', '3', '2', '3', '0', '0', '2', '0', '3', '3', '1', '0', '3', '1', '0', '3', '0', '0', '0', '0', '0', '1', '0', '2', '0', '1', '0', '3', '0', '0', '3', '3', '2', '2', '0', '1', '3', '0', '0', '0', '0', '0', '0', '2', '0', '3', '0', '0', '0', '1', '3', '0', '3', '0', '0', '3', '0', '0', '1', '0', '1', '1', '0', '0', '0', '2', '1', '0', '3', '0', '0', '0', '3', '0', '0', '0', '2', '2', '3', '3', '0', '0', '0', '2', '1', '3', '0', '0']\n"
     ]
    }
   ],
   "source": [
    "datasets= [dataset.remove_columns([FEEDBACK_TO_REMOVE]) for dataset in datasets]\n",
    "datasets = [dataset.rename_column(FEEDBACK_TO_TRAIN_ON, \"label\") for dataset in datasets]\n",
    "\n",
    "print(datasets[0][\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load model with LoRA layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModernBertForSequenceClassification(\n",
      "  (model): ModernBertModel(\n",
      "    (embeddings): ModernBertEmbeddings(\n",
      "      (tok_embeddings): Embedding(50368, 768, padding_idx=50283)\n",
      "      (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (layers): ModuleList(\n",
      "      (0): ModernBertEncoderLayer(\n",
      "        (attn_norm): Identity()\n",
      "        (attn): ModernBertAttention(\n",
      "          (Wqkv): Linear(in_features=768, out_features=2304, bias=False)\n",
      "          (rotary_emb): ModernBertRotaryEmbedding()\n",
      "          (Wo): Linear(in_features=768, out_features=768, bias=False)\n",
      "          (out_drop): Identity()\n",
      "        )\n",
      "        (mlp_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): ModernBertMLP(\n",
      "          (Wi): Linear(in_features=768, out_features=2304, bias=False)\n",
      "          (act): GELUActivation()\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "          (Wo): Linear(in_features=1152, out_features=768, bias=False)\n",
      "        )\n",
      "      )\n",
      "      (1-21): 21 x ModernBertEncoderLayer(\n",
      "        (attn_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): ModernBertAttention(\n",
      "          (Wqkv): Linear(in_features=768, out_features=2304, bias=False)\n",
      "          (rotary_emb): ModernBertRotaryEmbedding()\n",
      "          (Wo): Linear(in_features=768, out_features=768, bias=False)\n",
      "          (out_drop): Identity()\n",
      "        )\n",
      "        (mlp_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): ModernBertMLP(\n",
      "          (Wi): Linear(in_features=768, out_features=2304, bias=False)\n",
      "          (act): GELUActivation()\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "          (Wo): Linear(in_features=1152, out_features=768, bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (head): ModernBertPredictionHead(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=False)\n",
      "    (act): GELUActivation()\n",
      "    (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (drop): Dropout(p=0.0, inplace=False)\n",
      "  (classifier): Linear(in_features=768, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Load the model and the tokenizer\n",
    "model_id = MODEL \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_id, num_labels=1) # num_labels = 1 since we want to prodict a single scalar (the rating)\n",
    "\n",
    "# Comment: Automodel for sequence classification with num_labels=1 already has a regression head\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8192\n",
      "8192\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.model_max_length)\n",
    "print(model.config.max_position_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,149,697 || all params: 150,755,330 || trainable%: 0.7626\n"
     ]
    }
   ],
   "source": [
    "# Define LoRA config\n",
    "\n",
    "\n",
    "if MODEL == \"answerdotai/ModernBERT-base\":\n",
    "\n",
    "    lora_config = LoraConfig(\n",
    "    r=8,           # Rank of the LoRA matrices (smaller = less memory)\n",
    "    lora_alpha=16, # Scaling factor (higher = stronger adaptation)\n",
    "    target_modules=[\"Wqkv\", \"Wo\"], # Apply LoRA to attention layers\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_CLS\"  # classify each answer \n",
    "    )\n",
    "else:\n",
    "    lora_config = LoraConfig(\n",
    "    r=8,           # Rank of the LoRA matrices (smaller = less memory)\n",
    "    lora_alpha=16, # Scaling factor (higher = stronger adaptation)\n",
    "    target_modules=[\"query\", \"key\", \"value\"], # Apply LoRA to attention layers\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_CLS\"  # classify each answer \n",
    "    )\n",
    "    \n",
    "\n",
    "# Freeze base model\n",
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "\n",
    "\n",
    "# Convert the model to a PEFT (LoRA) model\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.gradient_checkpointing_enable()\n",
    "model.print_trainable_parameters()  # Check trainable params (~0.1% of full model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[50281, 1276, 310, 253, 5347, 273, 6181, 32, 50282, 50283, 50283], [50281, 1276, 310, 253, 6253, 5347, 275, 253, 1533, 32, 50282]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test tokenizer\n",
    "sample_data = [\"What is the capital of France?\", \"What is the largest capital in the world?\"]\n",
    "tokenizer(sample_data, padding=True, truncation=True, max_length=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Encode dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['file', 'frame_ID', 'frame_type', 'frame_text', 'precondition_id', 'precondition_text', 'precondition_position', 'response_text', 'prompt_config_examples', 'prompt_config_chain_of_thought', 'label', 'additional_feedback']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 650/650 [00:00<00:00, 8645.99 examples/s]\n",
      "Map: 100%|██████████| 139/139 [00:00<00:00, 9504.38 examples/s]\n",
      "Map: 100%|██████████| 140/140 [00:00<00:00, 12209.48 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 0, 2, 0, 3]\n",
      "['Inhoud: <inhoud van subfact>\\n\\n\\n                 1. Subfact: Budgettaire totaalbeeld\\n                  Positie: Artikel 4.2.4.a IN Rijksbegrotingswet 2016\\n                  Inhoud: het budgettaire totaalbeeld voor het betrokken begrotingsjaar en de vier daaropvolgende jaren van de rijksbegroting en de niet tot de rijksbegroting behorende budgetdisciplinesectoren\\n\\n                 2. Subfact: Budgettaire beschouwingen\\n                  Positie: Artikel 4.2.4.b IN Rijksbegrotingswet 2016\\n                  Inhoud: de budgettaire beschouwingen over het voorgenomen beleid voor de collectieve sector\\n\\n                 3. Subfact: Overzicht van de uitgaven en ontvangsten\\n                  Positie: Artikel 4.2.4.c IN Rijksbegrotingswet 2016\\n                  Inhoud: een overzicht van de uitgaven en de ontvangsten in de begrotingen voor het begrotingsjaar en de vier daarop aansluitende jaren.', '1. Subfact: Begroting bevat begrotingsstaat\\n\\n                Positie: Artikel 2.1, eerste lid, IN Comptabiliteitswet 2016\\n\\n            2. Subfact: De departementale begroting bevat begrotingsstaat\\n\\n               Positie: Artikel 2.1, eerste lid, IN Comptabiliteitswet 2016\\n\\n            3. Subfact: De niet-departementale begroting bevat begrotingsstaat\\n\\n              Positie: Artikel 2.5, IN Comptabiliteitswet 2016\\n\\n            4. Subfact: De begroting van een begrotingsfonds bevat begrotingsstaat\\n\\n              Positie: Artikel 2.11, eerste lid, IN Comptabiliteitswet 2016', '1. Vreemdeling: ieder die de Nederlandse nationaliteit niet bezit en niet op grond van een wettelijke bepaling als Nederlander moet worden behandeld \\n \\n                Positie: Artikel 1, Algemene wet bestuursrecht\\n \\n                2. Vreemdeling: ieder die de Nederlandse nationaliteit niet bezit en niet op grond van een wettelijke bepaling als Nederlander moet worden behandeld; ieder die rechtmatig verblijf heeft op grond van artikel 8 \\n \\n                Positie: Artikel 8, Vreemdelingenwet\\n \\n                3. Vreemdeling: ieder die de Nederlandse nationaliteit niet bezit en niet op grond van een wettelijke bepaling als Nederlander moet worden behandeld; ieder die rechtmatig verblijf heeft op grond van artikel 8, onder a tot en met d, f tot en met h en j tot en met m, en aan de vreemdeling die rechtmatig verblijf heeft op grond van artikel 8, onder e, en gemeenschapsonderdaan is als bedoeld in artikel 1, sub 2°, 4° en 6° \\n \\n                Positie: Artikel 9, Vreemdelingenwet', '1. De aanvraag is ontvangen \\n                Positie: Artikel 27, 1, 1 IN Vreemdelingenwet geldig vanaf 2024\\n \\n                2. De vreemdeling aangetoond dat hij aan alle voorwaarden voldoet \\n                Positie: Niet in de Vreemdelingenwet geldig vanaf 2024, maar wel in het algemene wet bestuursrecht\\n                Artikel 1:3, 3 IN Algemene wet bestuursrecht\\n \\n                3. De verblijfsvergunning wordt verleend met ingang van de dag waarop de aanvraag is ontvangen \\n                Positie: Artikel 27, 1, 1 IN Vreemdelingenwet geldig vanaf 2024\\n \\n                4. De verblijfsvergunning wordt verleend niet eerder dan met ingang van de dag waarop de aanvraag is ontvangen \\n                Positie: Artikel 27, 1, 1 IN Vreemdelingenwet geldig vanaf 2024', ' Inhoud: <inhoud>\\n\\n\\n\\n                Subfact: De minister van Binnenlandse Zaken en Koninkrijksrelaties is verantwoordelijk voor het beheer van de begrotingen van de Staten-Generaal, de Raad van State, de Algemene Rekenkamer, de Nationale ombudsman, de Kanselarij der Nederlandse Orden, het Kabinet van de Gouverneur van Aruba, het Kabinet van de Gouverneur van Curaçao, het Kabinet van de Gouverneur van Sint Maarten en de Kiesraad.\\n\\n                Positie: Artikel 4.4, sectie 2 IN Rijksbegrotingswet 2016\\n\\n                Inhoud: Onze Minister van Binnenlandse Zaken en Koninkrijksrelaties is verantwoordelijk voor het beheer van de begrotingen van de Staten-Generaal, de Raad van State, de Algemene Rekenkamer, de Nationale ombudsman, de Kanselarij der Nederlandse Orden, het Kabinet van de Gouverneur van Aruba, het Kabinet van de Gouverneur van Curaçao, het Kabinet van de Gouverneur van Sint Maarten en de Kiesraad.\\n\\n                Subfact: De minister van Binnenlandse Zaken en Koninkrijksrelaties is verantwoordelijk voor het beheer van de begroting van koninkrijksrelaties.\\n\\n                Positie: Artikel 4.3, sectie 2 IN Rijksbegrotingswet 2016\\n\\n                Inhoud: Onze Minister van Binnenlandse Zaken en Koninkrijksrelaties is verantwoordelijk voor het beheer van de begroting van koninkrijksrelaties.\\n\\n                Subfact: De minister van Binnenlandse Zaken en Koninkrijksrelaties is verantwoordelijk voor het beheer van de begrotingen van de Staten-Generaal.\\n\\n                Positie: Artikel 4.4, sectie 2 IN Rijksbegrotingswet 2016\\n\\n                Inhoud: De minister van Binnenlandse Zaken en Koninkrijksrelaties is verantwoordelijk voor het beheer van de begrotingen van de Staten-Generaal.\\n\\n                Subfact: De minister van Binnenlandse Zaken en Koninkrijksrelaties is verantwoordelijk voor het beheer van de begroting van de Raad van State.\\n\\n                Positie: Artikel 4.4, sectie 2 IN Rijksbegrotingswet 2016\\n\\n                Inhoud: De minister van Binnenlandse Zaken en Koninkrijksrelaties is verantwoordelijk voor het beheer van de begroting van de Raad van State.\\n\\n                Subfact: De minister van Binnenlandse Zaken en Koninkrijksrelaties is verantwoordelijk voor het beheer van de begroting van de Algemene Rekenkamer.\\n\\n                Positie: Artikel 4.4, sectie 2 IN Rijksbegrotingswet 2016\\n\\n                Inhoud: De minister van Binnenlandse Zaken en Koninkrijksrelaties is verantwoordelijk voor het beheer van de begroting van de Algemene Rekenkamer.\\n\\n                Subfact: De minister van Binnenlandse Zaken en Koninkrijksrelaties is verantwoordelijk voor het beheer van de begroting van de Nationale ombudsman.\\n\\n                Positie: Artikel 4.4, sectie 2 IN Rijksbegrotingswet 2016\\n\\n                Inhoud: De minister van Binnenlandse Zaken en Koninkrijksrelaties is verantwoordelijk voor het beheer van de begroting van de Nationale ombudsman.\\n\\n                Subfact: De minister van Binnenlandse Zaken en Koninkrijksrelaties is verantwoordelijk voor het beheer van de Kanselarij der Nederlandse Orden.\\n\\n                Positie: Artikel 4.4, sectie 2 IN Rijksbegrotingswet 2016\\n\\n                Inhoud: De minister van Binnenlandse Zaken en Koninkrijksrelaties is verantwoordelijk voor het beheer van de Kanselarij der Nederlandse Orden.\\n\\n                Subfact: De minister van Binnenlandse Zaken en Koninkrijksrelaties is verantwoordelijk voor het beheer van het Kabinet van de Gouverneur van Aruba.\\n\\n                Positie: Artikel 4.4, sectie 2 IN Rijksbegrotingswet 2016\\n\\n                Inhoud: De minister van Binnenlandse Zaken en Koninkrijksrelaties is verantwoordelijk voor het beheer van het Kabinet van de Gouverneur van Aruba.\\n\\n                Subfact: De minister van Binnenlandse Zaken en Koninkrijksrelaties is verantwoordelijk voor het beheer van het Kabinet van de Gouverneur van Curaçao.\\n\\n                Positie: Artikel 4.4, sectie 2 IN Rijksbegrotingswet 2016\\n\\n                Inhoud: De minister van Binnenlandse Zaken en Koninkrijksrelaties is verant']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(datasets[0].column_names)\n",
    "# mao string labels to integers\n",
    "datasets = [dataset.map(convert_label_to_int) for dataset in datasets]\n",
    "\n",
    "print(datasets[0][\"label\"][:5])  # Check labels\n",
    "print(datasets[0][\"response_text\"][:5])  # Check labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comment\n",
    "\n",
    "1. Needed for feedback extraction: precondition_text, response_text, label(rating feedback extraction)\n",
    "2. Needed for feedback detection: precondition_text, precondition_position, response_text, label (rating feedback detection)\n",
    "3. For the precondition position to be found well, it is a crucial for the model to find the precondition text (at least to a recognizable degree) as well, otherwise the precondition is not found at all..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Titel: De Weg Door Het Leven\n",
      "\n",
      "Het leven is een reis vol onverwachte wendingen, een pad dat zich zelden rechtlijnig ontvouwt. Vanaf het moment dat we onze eerste ademhaling nemen, worden we ondergedompeld in een wereld die we nog moeten leren begrijpen. Als kind lijkt alles eenvoudig: lachen, spelen, ontdekken. Maar naarmate we ouder worden, beginnen de lagen van complexiteit zich op te stapelen. We leren dat mensen niet altijd zeggen wat ze bedoelen, dat keuzes consequenties hebben, en dat geluk soms vluchtiger is dan we zouden willen.\n",
      "\n",
      "In de vroege ochtenden, wanneer de zon net boven de horizon verschijnt en de wereld nog stil is, denken velen na over hun plaats in het grotere geheel. Sommigen vragen zich af of ze de juiste keuzes hebben gemaakt, of ze trouw zijn gebleven aan zichzelf. Anderen proberen simpelweg de dag door te komen, met hoop op iets beters. In die momenten van stilte komt vaak het besef dat, hoewel we allemaal verschillende paden bewandelen, we één waarheid delen: dat het leven, ondanks al onze inspanningen en verlangens, nooit gemakkelijk is. Of, zoals mijn grootmoeder het ooit zei terwijl ze haar handen vouwde na een lange dag werken op het land: “Je moet weten, kind, het leven is nooit gemakkelijk, maar het is wel de moeite waard.”\n",
      "\n",
      "We worden gevormd door onze ervaringen, door de mensen die we ontmoeten en de obstakels die we overwinnen. Elke fout, elk succes, elke traan en elke glimlach draagt bij aan wie we zijn. En toch, ondanks al die ervaringen, blijven we zoek\n"
     ]
    }
   ],
   "source": [
    "# Code to test bestw indow function\n",
    "\n",
    "test_text = \"\"\"\n",
    "        Titel: De Weg Door Het Leven\n",
    "\n",
    "Het leven is een reis vol onverwachte wendingen, een pad dat zich zelden rechtlijnig ontvouwt. Vanaf het moment dat we onze eerste ademhaling nemen, worden we ondergedompeld in een wereld die we nog moeten leren begrijpen. Als kind lijkt alles eenvoudig: lachen, spelen, ontdekken. Maar naarmate we ouder worden, beginnen de lagen van complexiteit zich op te stapelen. We leren dat mensen niet altijd zeggen wat ze bedoelen, dat keuzes consequenties hebben, en dat geluk soms vluchtiger is dan we zouden willen.\n",
    "\n",
    "In de vroege ochtenden, wanneer de zon net boven de horizon verschijnt en de wereld nog stil is, denken velen na over hun plaats in het grotere geheel. Sommigen vragen zich af of ze de juiste keuzes hebben gemaakt, of ze trouw zijn gebleven aan zichzelf. Anderen proberen simpelweg de dag door te komen, met hoop op iets beters. In die momenten van stilte komt vaak het besef dat, hoewel we allemaal verschillende paden bewandelen, we één waarheid delen: dat het leven, ondanks al onze inspanningen en verlangens, nooit gemakkelijk is. Of, zoals mijn grootmoeder het ooit zei terwijl ze haar handen vouwde na een lange dag werken op het land: “Je moet weten, kind, het leven is nooit gemakkelijk, maar het is wel de moeite waard.”\n",
    "\n",
    "We worden gevormd door onze ervaringen, door de mensen die we ontmoeten en de obstakels die we overwinnen. Elke fout, elk succes, elke traan en elke glimlach draagt bij aan wie we zijn. En toch, ondanks al die ervaringen, blijven we zoeken. Naar betekenis. Naar verbinding. Naar rust.\n",
    "\n",
    "Soms lijkt het alsof de wereld te snel draait. Technologie verandert ons leven in een razend tempo, verwachtingen worden hoger, en de druk om te presteren neemt toe. In die chaos vergeten we soms stil te staan. Te ademen. Te voelen. Maar juist in die momenten van rust vinden we vaak de antwoorden die we zo hard nodig hebben.\n",
    "\n",
    "De liefde, bijvoorbeeld, is een van de krachtigste krachten die ons voortdrijft. Liefde voor een partner, een kind, een vriend, of zelfs voor een passie. Het is die liefde die ons helpt vol te houden wanneer alles tegenzit. Die ons eraan herinnert waarom we begonnen zijn, waarom we blijven proberen.\n",
    "\n",
    "En dan is er verlies. Een onvermijdelijk onderdeel van het leven. We verliezen mensen, kansen, dromen. Maar in dat verlies schuilt ook groei. We leren loslaten, opnieuw beginnen, sterker worden. Het is pijnlijk, ja, maar ook noodzakelijk.\n",
    "\n",
    "Wanneer we terugkijken op ons leven, zijn het zelden de materiële zaken die we herinneren. Het zijn de momenten. De gesprekken bij kaarslicht. De wandelingen in de regen. De onverwachte lachbuien. De stilte van een gedeeld verdriet. Die momenten vormen de essentie van ons bestaan.\n",
    "\n",
    "Dus ja, het leven is vol uitdagingen. Het is rommelig, verwarrend, soms oneerlijk. Maar het is ook prachtig, rijk aan betekenis, en gevuld met kansen om te groeien, te leren en lief te hebben. En misschien is dat wel de grootste les van allemaal: dat we, ondanks alles, blijven kiezen voor hoop. Voor verbinding. Voor het leven zelf.\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "test_ground_truth = \"Het leven is nooit gemakkelijk.\"\n",
    "\n",
    "print(find_best_window(test_text, test_ground_truth, device, tokenizer))\n",
    "\n",
    "# Works as expectd, I am impressed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(TOKENIZED_DATA_TRAIN):\n",
    "    if TOKENIZE_FN == \"best_window\":\n",
    "        datasets = [dataset.map(tokenize_fn_with_best_window, \n",
    "                                fn_kwargs={\"feedback_train\": FEEDBACK_TO_TRAIN_ON, \n",
    "                                            \"tokenizer\": tokenizer, \n",
    "                                            \"max_length\": int(MAX_LENGTH), \n",
    "                                            \"stride\": int(STRIDE),\n",
    "                                            \"device\": device\n",
    "                                            },\n",
    "                                batched=False) for dataset in datasets]\n",
    "    else:\n",
    "        datasets = [dataset.map(tokenize_fn_basic_batched, \n",
    "                                fn_kwargs={\"feedback_train\": FEEDBACK_TO_TRAIN_ON, \n",
    "                                            \"tokenizer\": tokenizer \n",
    "                                            },\n",
    "                                batched=True) for dataset in datasets]\n",
    "    \n",
    "    \n",
    "    datasets[0].save_to_disk(TOKENIZED_DATA_TRAIN)\n",
    "    datasets[1].save_to_disk(TOKENIZED_DATA_EVAL)\n",
    "    datasets[2].save_to_disk(TOKENIZED_DATA_TEST)\n",
    "else:\n",
    "    datasets[0] = load_from_disk(TOKENIZED_DATA_TRAIN)\n",
    "    datasets[1] = load_from_disk(TOKENIZED_DATA_TEST)\n",
    "    datasets[2] = load_from_disk(TOKENIZED_DATA_EVAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Interpretatie_Vw_over_besluiten_op_aanvragen_voor_een_verblijfsvergunning_regulier_bepaalde_tijd.json': 298, 'Participatiewet_most_recent_public.json': 181, 'rijksbegrotingscyclus.json': 171})\n"
     ]
    }
   ],
   "source": [
    "print(Counter(datasets[0]['file']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train reward model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-18 17:01:34,495] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jacques.furst/miniconda3/envs/RL/compiler_compat/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "/home/jacques.furst/miniconda3/envs/RL/compiler_compat/ld: cannot find -lcufile: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-18 17:01:34,856] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Training arguments\n",
    "#TODO: switch to cross entropy loss...\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=LORA_CHECKPOINTS_FOLDER,\n",
    "    eval_strategy='steps',\n",
    "    save_strategy='steps',\n",
    "    save_steps=10,\n",
    "    eval_steps=10,\n",
    "    save_total_limit=3,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    learning_rate=3e-5,\n",
    "    num_train_epochs=30,\n",
    "    logging_steps=10,\n",
    "    label_names=[\"labels\"],\n",
    "    # report_to=\"none\",\n",
    "    logging_dir=\"./logs\",\n",
    "    fp16=True,  # Use mixed precision training\n",
    "    metric_for_best_model=\"eval_loss\", # or \"eval_loss\"\n",
    "    greater_is_better=False, # False if using loss\n",
    "    gradient_accumulation_steps=4, # \n",
    "    torch_compile=False\n",
    "    # weight_decay=0.01\n",
    ")\n",
    "\n",
    "# Initialize custom trainer\n",
    "trainer = CustomRewardTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=datasets[0],\n",
    "    eval_dataset=datasets[1],\n",
    "    # compute_metrics=trainer.compute_metrics,  # Use the custom metrics function\n",
    "    processing_class=tokenizer,\n",
    "    loss_type=\"mse\",  # \"mse\" or \"huber\"\n",
    "    weight_strategy=\"linear\",  # \"linear\", \"inverse\", or None\n",
    ")\n",
    "\n",
    "print(trainer.args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjacques-furst123\u001b[0m (\u001b[33mjacques-furst123-none\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.20.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jacques.furst/development/RAG/flintfiller-precondition-rl/rl_training_new/wandb/run-20250618_170136-vjtxltmm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jacques-furst123-none/huggingface/runs/vjtxltmm' target=\"_blank\">/home/jacques.furst/development/RAG/flintfiller-precondition-rl/reward_training_files/lora_checkpoints</a></strong> to <a href='https://wandb.ai/jacques-furst123-none/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jacques-furst123-none/huggingface' target=\"_blank\">https://wandb.ai/jacques-furst123-none/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jacques-furst123-none/huggingface/runs/vjtxltmm' target=\"_blank\">https://wandb.ai/jacques-furst123-none/huggingface/runs/vjtxltmm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jacques.furst/miniconda3/envs/RL/lib/python3.10/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/jacques.furst/miniconda3/envs/RL/lib/python3.10/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Boolean value of Tensor with more than one value is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# if not os.path.exists(FINAL_LORA_ADAPTERS):\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# train model\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# # store final model parameters\u001b[39;00m\n\u001b[1;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39msave_pretrained(FINAL_LORA_ADAPTERS)\n",
      "File \u001b[0;32m~/miniconda3/envs/RL/lib/python3.10/site-packages/transformers/trainer.py:2240\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2238\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2239\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2241\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2245\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/RL/lib/python3.10/site-packages/transformers/trainer.py:2555\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2548\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2549\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m   2550\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2551\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[1;32m   2552\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[1;32m   2553\u001b[0m )\n\u001b[1;32m   2554\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m-> 2555\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2557\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2558\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2559\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2560\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2561\u001b[0m ):\n\u001b[1;32m   2562\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2563\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/miniconda3/envs/RL/lib/python3.10/site-packages/transformers/trainer.py:3745\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3742\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   3744\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3745\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3747\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[1;32m   3748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   3749\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3750\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   3751\u001b[0m ):\n",
      "File \u001b[0;32m~/development/RAG/flintfiller-precondition-rl/rl_training_new/utils.py:274\u001b[0m, in \u001b[0;36mCustomRewardTrainer.compute_loss\u001b[0;34m(self, model, inputs, num_items_in_batch, return_outputs)\u001b[0m\n\u001b[1;32m    269\u001b[0m logits \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlogits\u001b[38;5;241m.\u001b[39msqueeze()  \u001b[38;5;66;03m# Shape: (batch_size) --> logits are the predicted rewards in this case\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;66;03m# Custom loss calculation\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;66;03m#TODO: take cross entropy loss here\u001b[39;00m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;66;03m# loss = self._compute_custom_loss(logits, labels, weights)\u001b[39;00m\n\u001b[0;32m--> 274\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCrossEntropyLoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (loss, outputs) \u001b[38;5;28;01mif\u001b[39;00m return_outputs \u001b[38;5;28;01melse\u001b[39;00m loss\n",
      "File \u001b[0;32m~/miniconda3/envs/RL/lib/python3.10/site-packages/torch/nn/modules/loss.py:1292\u001b[0m, in \u001b[0;36mCrossEntropyLoss.__init__\u001b[0;34m(self, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   1283\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m   1284\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1285\u001b[0m     weight: Optional[Tensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1290\u001b[0m     label_smoothing: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m,\n\u001b[1;32m   1291\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1292\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize_average\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1293\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mignore_index \u001b[38;5;241m=\u001b[39m ignore_index\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_smoothing \u001b[38;5;241m=\u001b[39m label_smoothing\n",
      "File \u001b[0;32m~/miniconda3/envs/RL/lib/python3.10/site-packages/torch/nn/modules/loss.py:57\u001b[0m, in \u001b[0;36m_WeightedLoss.__init__\u001b[0;34m(self, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     52\u001b[0m     weight: Optional[Tensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     55\u001b[0m     reduction: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     56\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 57\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msize_average\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregister_buffer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m\"\u001b[39m, weight)\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight: Optional[Tensor]\n",
      "File \u001b[0;32m~/miniconda3/envs/RL/lib/python3.10/site-packages/torch/nn/modules/loss.py:44\u001b[0m, in \u001b[0;36m_Loss.__init__\u001b[0;34m(self, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduction: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlegacy_get_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize_average\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduction \u001b[38;5;241m=\u001b[39m reduction\n",
      "File \u001b[0;32m~/miniconda3/envs/RL/lib/python3.10/site-packages/torch/nn/_reduction.py:44\u001b[0m, in \u001b[0;36mlegacy_get_string\u001b[0;34m(size_average, reduce, emit_warning)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m     reduce \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mand\u001b[39;00m reduce:\n\u001b[1;32m     45\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m reduce:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Boolean value of Tensor with more than one value is ambiguous"
     ]
    }
   ],
   "source": [
    "# if not os.path.exists(FINAL_LORA_ADAPTERS):\n",
    "# train model\n",
    "trainer.train()\n",
    "# # store final model parameters\n",
    "model.save_pretrained(FINAL_LORA_ADAPTERS)\n",
    "\n",
    "# #TODO: not storing this properly I suppose, need to change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reload saved LoRA adapter for inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "base_model_test = AutoModelForSequenceClassification.from_pretrained(MODEL, num_labels=1)\n",
    "new_model = PeftModel.from_pretrained(base_model_test, FINAL_LORA_ADAPTERS)\n",
    "# new_model = new_model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Trainer.__init__() got an unexpected keyword argument 'torch_compile'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Initialize trainer with new model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mCustomRewardTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatasets\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatasets\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# compute_metrics=trainer.compute_metrics,  # Use the custom metrics function\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprocessing_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhuber\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# \"mse\" or \"huber\"\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlinear\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# \"linear\", \"inverse\", or None\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# callbacks=[EarlyStoppingCallback(early_stopping_patience=50)] # use early stopping since we are sing high amount of epochs\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# data_collator=RewardDataCollator()\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch_compile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m     14\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/development/RAG/flintfiller-precondition-rl/rl_training_new/utils.py:256\u001b[0m, in \u001b[0;36mCustomRewardTrainer.__init__\u001b[0;34m(self, loss_type, weight_strategy, *args, **kwargs)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, loss_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m\"\u001b[39m, weight_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 256\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_type \u001b[38;5;241m=\u001b[39m loss_type  \u001b[38;5;66;03m# \"mse\", \"huber\", or custom\u001b[39;00m\n\u001b[1;32m    258\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight_strategy \u001b[38;5;241m=\u001b[39m weight_strategy\n",
      "File \u001b[0;32m~/miniconda3/envs/RL/lib/python3.10/site-packages/transformers/utils/deprecation.py:172\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: Trainer.__init__() got an unexpected keyword argument 'torch_compile'"
     ]
    }
   ],
   "source": [
    "# Initialize trainer with new model\n",
    "trainer = CustomRewardTrainer(\n",
    "    model=new_model,\n",
    "    args=training_args,\n",
    "    train_dataset=datasets[0],\n",
    "    eval_dataset=datasets[1],\n",
    "    # compute_metrics=trainer.compute_metrics,  # Use the custom metrics function\n",
    "    processing_class=tokenizer,\n",
    "    loss_type=\"huber\",  # \"mse\" or \"huber\"\n",
    "    weight_strategy=\"linear\",  # \"linear\", \"inverse\", or None\n",
    "    # callbacks=[EarlyStoppingCallback(early_stopping_patience=50)] # use early stopping since we are sing high amount of epochs\n",
    "    # data_collator=RewardDataCollator()\n",
    "    # torch_compile=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results: {'eval_loss': 0.5358006358146667, 'eval_model_preparation_time': 0.008, 'eval_runtime': 0.2558, 'eval_samples_per_second': 547.295, 'eval_steps_per_second': 35.183}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_results = trainer.evaluate(eval_dataset=datasets[2])\n",
    "print(\"Test Results:\", test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1: Predicted Rating: 2.779296875, True Rating: 1\n",
      "Sample 2: Predicted Rating: -0.07684326171875, True Rating: 0\n",
      "Sample 3: Predicted Rating: 2.345703125, True Rating: 3\n",
      "Sample 4: Predicted Rating: -0.010162353515625, True Rating: 0\n",
      "Sample 5: Predicted Rating: 2.9140625, True Rating: 3\n",
      "Sample 6: Predicted Rating: 0.10626220703125, True Rating: 0\n",
      "Sample 7: Predicted Rating: 2.4453125, True Rating: 1\n",
      "Sample 8: Predicted Rating: 0.07196044921875, True Rating: 0\n",
      "Sample 9: Predicted Rating: 0.056854248046875, True Rating: 0\n",
      "Sample 10: Predicted Rating: -0.040679931640625, True Rating: 0\n",
      "Sample 11: Predicted Rating: 0.053863525390625, True Rating: 0\n",
      "Sample 12: Predicted Rating: 0.17333984375, True Rating: 0\n",
      "Sample 13: Predicted Rating: -0.03515625, True Rating: 0\n",
      "Sample 14: Predicted Rating: 1.3251953125, True Rating: 1\n",
      "Sample 15: Predicted Rating: 1.2685546875, True Rating: 0\n",
      "Sample 16: Predicted Rating: 0.18017578125, True Rating: 0\n",
      "Sample 17: Predicted Rating: 2.4453125, True Rating: 3\n",
      "Sample 18: Predicted Rating: 2.87109375, True Rating: 3\n",
      "Sample 19: Predicted Rating: 0.0848388671875, True Rating: 1\n",
      "Sample 20: Predicted Rating: 2.955078125, True Rating: 3\n"
     ]
    }
   ],
   "source": [
    "# evaluate model manually on some test cases\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "#TODO: change tokenization function here!\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(20):\n",
    "        sample = datasets[2][i]\n",
    "        inputs = tokenizer(sample['precondition_text'] + \" \" + sample['response_text'], return_tensors='pt', truncation=True, padding=\"max_length\").to(device)\n",
    "        outputs = model(**inputs)\n",
    "        prediction = outputs.logits.item()\n",
    "        print(f\"Sample {i+1}: Predicted Rating: {prediction}, True Rating: {sample['label']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
