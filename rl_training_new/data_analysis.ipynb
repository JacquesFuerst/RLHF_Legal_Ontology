{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd01ea27",
   "metadata": {},
   "source": [
    "# Data cleanup notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae5f442",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab85d869",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jacques.furst/miniconda3/envs/Evaluation/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torchmetrics.nominal import FleissKappa\n",
    "import pandas as pd\n",
    "from utils import parse_ratings, count_categories\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4514bf",
   "metadata": {},
   "source": [
    "## 2. Clean up messed up files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bac294e",
   "metadata": {},
   "source": [
    "### Load files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc34f4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Participant 2\n",
    "\n",
    "first_file_2 = \"/home/jacques.furst/development/RAG/flintfiller-precondition-rl/data/human_feedback/human_feedback_7a185ca4-3d37-4487-8aa7-ad9e8f6fe884.csv\" # 13:10\n",
    "second_file_2 = \"/home/jacques.furst/development/RAG/flintfiller-precondition-rl/data/human_feedback/human_feedback_861cdaee-9f2e-4454-8252-d8ff397eb14e.csv\" # 15:48\n",
    "third_file_2 = \"/home/jacques.furst/development/RAG/flintfiller-precondition-rl/data/human_feedback/human_feedback_f60e0e84-2638-44da-871b-4847b751fabb.csv\" # 16:23\n",
    "\n",
    "\n",
    "# Participant 6\n",
    "\n",
    "first_file_6 = \"/home/jacques.furst/development/RAG/flintfiller-precondition-rl/data/human_feedback/human_feedback_48d1eb99-5d33-476a-a1a4-75917aa92e92.csv\" # 12:21\n",
    "second_file_6 = \"/home/jacques.furst/development/RAG/flintfiller-precondition-rl/data/human_feedback/human_feedback_b3d2cab5-ffca-467d-bddb-b9e188e5a85a.csv\" # 11:09\n",
    "third_file_6 = \"/home/jacques.furst/development/RAG/flintfiller-precondition-rl/data/human_feedback/human_feedback_c2e282a4-f8e7-4542-95ab-a9a74b6f57e0.csv\" # 13:39\n",
    "\n",
    "\n",
    "# Participant 10\n",
    "\n",
    "first_file_10 =  \"/home/jacques.furst/development/RAG/flintfiller-precondition-rl/data/human_feedback/human_feedback_e274815b-f334-4f2c-8cda-3788070d4bee.csv\" # 13:20\n",
    "second_file_10 = \"/home/jacques.furst/development/RAG/flintfiller-precondition-rl/data/human_feedback/human_feedback_5a066984-b053-4ae4-97ad-675900d79540.csv\" # 14:39\n",
    "\n",
    "\n",
    "# Synthetic feedback\n",
    "\n",
    "synthetic_file = \"/home/jacques.furst/development/RAG/flintfiller-precondition-rl/data/synthetic_feedback/synthetic_feedback.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da94d9db",
   "metadata": {},
   "source": [
    "### Sort out files participant 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c67f99ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281\n"
     ]
    }
   ],
   "source": [
    "df_2_1 = pd.read_csv(first_file_2, sep=\";\")\n",
    "df_2_2 = pd.read_csv(second_file_2, sep=\";\")\n",
    "df_2_3 = pd.read_csv(third_file_2, sep=\";\")\n",
    "\n",
    "df_2_1 = df_2_1[:186]\n",
    "df_2_2 = df_2_2[186:]\n",
    "df_2_3 = df_2_3[30:]\n",
    "\n",
    "df_2 = pd.concat([df_2_1, df_2_2, df_2_3], ignore_index=True)\n",
    "print(len(df_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e13ec52",
   "metadata": {},
   "source": [
    "### Sort out files participant 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b247c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\n",
      "168\n",
      "114\n",
      "282\n"
     ]
    }
   ],
   "source": [
    "df_6_1 = pd.read_csv(second_file_6, sep=\";\")\n",
    "df_6_2 = pd.read_csv(first_file_6, sep=\";\")\n",
    "df_6_3 = pd.read_csv(third_file_6, sep=\";\")\n",
    "\n",
    "print(len(df_6_1))\n",
    "print(len(df_6_2))\n",
    "print(len(df_6_3))\n",
    "\n",
    "df_6_1 = df_6_1[:]\n",
    "df_6_2 = df_6_2[84:]\n",
    "df_6_3 = df_6_3[:]\n",
    "\n",
    "df_6 = pd.concat([df_6_1, df_6_2, df_6_3], ignore_index=True)\n",
    "print(len(df_6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3c11af",
   "metadata": {},
   "source": [
    "### Sort out files participant 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8103e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282\n"
     ]
    }
   ],
   "source": [
    "df_10_1 = pd.read_csv(first_file_10, sep=\";\")\n",
    "df_10_2 = pd.read_csv(second_file_10, sep=\";\")\n",
    "\n",
    "df_10 = pd.concat([df_10_1, df_10_2], ignore_index=True)\n",
    "print(len(df_10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e037d8",
   "metadata": {},
   "source": [
    "### Check if there are duplicate rows in the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4f67265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "duplicates_6 = df_6.iloc[:, :-2].duplicated()\n",
    "duplicates_2 = df_2.iloc[:, :-2].duplicated()\n",
    "print(duplicates_6.sum())\n",
    "print(duplicates_2.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda76578",
   "metadata": {},
   "source": [
    "### Sort out synthetic feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81ce01fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic feedback shape: (563, 14)\n",
      "Index(['file', 'frame_ID', 'frame_type', 'frame_text', 'precondition_id',\n",
      "       'precondition_text', 'precondition_position', 'response_text',\n",
      "       'prompt_config_examples', 'prompt_config_chain_of_thought',\n",
      "       'feedback_extraction', 'feedback_detection', 'additional_feedback',\n",
      "       'synthetic_feedback'],\n",
      "      dtype='object')\n",
      "Synthetic feedback shape: (564, 14)\n",
      "Synthetic feedback 1 shape: (282, 14)\n",
      "Synthetic feedback 2 shape: (282, 14)\n",
      "Number of common rows in df_synth_1 and df_synth_2: 282\n"
     ]
    }
   ],
   "source": [
    "df_synthetic_both = pd.read_csv(synthetic_file, sep=\";\")\n",
    "\n",
    "print(\"Synthetic feedback shape:\", df_synthetic_both.shape)\n",
    "\n",
    "\n",
    "# Save the current headers since forgot to store headers in csv file\n",
    "old_headers = df_synthetic_both.columns.tolist()\n",
    "\n",
    "# print(\"Old headers:\", old_headers)\n",
    "\n",
    "# Step 2: Insert the headers as the first row\n",
    "df_synthetic_both.loc[-1] = old_headers # Add headers as a new row\n",
    "df_synthetic_both.index = df_synthetic_both.index + 1 # Shift index\n",
    "df_synthetic_both = df_synthetic_both.sort_index() # Sort index to place the new row at the top\n",
    "\n",
    "\n",
    "# Step 3: Assign new headers (optional)\n",
    "df_synthetic_both.columns = ['file', \n",
    "                            'frame_ID', \n",
    "                            'frame_type', \n",
    "                            'frame_text', \n",
    "                            'precondition_id', \n",
    "                            'precondition_text', \n",
    "                            'precondition_position', \n",
    "                            'response_text', \n",
    "                            'prompt_config_examples', \n",
    "                            'prompt_config_chain_of_thought', \n",
    "                            'feedback_extraction', \n",
    "                            'feedback_detection', \n",
    "                            'additional_feedback',\n",
    "                            'synthetic_feedback',\n",
    "                ]\n",
    "\n",
    "print(df_synthetic_both.columns)\n",
    "\n",
    "\n",
    "df_synthetic_both['prompt_config_examples'] = (df_synthetic_both['prompt_config_examples']                                              \n",
    "                                                .astype(str)\n",
    "                                                .str.strip()\n",
    "                                                .str.lower()\n",
    "                                                .map({'true': True, 'false': False})\n",
    ")\n",
    "\n",
    "df_synthetic_both['prompt_config_chain_of_thought'] = (df_synthetic_both['prompt_config_chain_of_thought']\n",
    "                                                .astype(str)\n",
    "                                                .str.strip()\n",
    "                                                .str.lower()\n",
    "                                                .map({'true': True, 'false': False})\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "print(\"Synthetic feedback shape:\", df_synthetic_both.shape)\n",
    "\n",
    "\n",
    "\n",
    "# Odd rows (index 0, 2, 4, ...)\n",
    "df_synthetic_1 = df_synthetic_both.iloc[::2]\n",
    "\n",
    "# Even rows (index 1, 3, 5, ...)\n",
    "df_synthetic_2 = df_synthetic_both.iloc[1::2]\n",
    "\n",
    "print(\"Synthetic feedback 1 shape:\", df_synthetic_1.shape)\n",
    "print(\"Synthetic feedback 2 shape:\", df_synthetic_2.shape)\n",
    "\n",
    "# print(\"Odd rows:\\n\", df_synthetic_1.head())\n",
    "\n",
    "df_synth_test_1 = df_synthetic_1.iloc[:, :-4]\n",
    "df_synth_test_2 = df_synthetic_2.iloc[:, :-4]\n",
    "\n",
    "\n",
    "common = pd.merge(df_synth_test_1, df_synth_test_2, how='inner')\n",
    "print(\"Number of common rows in df_synth_1 and df_synth_2:\", len(common))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18eba8f6",
   "metadata": {},
   "source": [
    "## 3. Load all proper files (except for the ones that were already created)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5517e4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_1 = \"/home/jacques.furst/development/RAG/flintfiller-precondition-rl/data/human_feedback/human_feedback_b2339fe6-2896-43ab-a9c8-24c8aacfbbd1.csv\"\n",
    "FILE_2 = None\n",
    "FILE_3 = \"/home/jacques.furst/development/RAG/flintfiller-precondition-rl/data/human_feedback/human_feedback_6430b6fd-0ddd-4cc6-a4a0-216d5603143e.csv\"\n",
    "FILE_4 = \"/home/jacques.furst/development/RAG/flintfiller-precondition-rl/data/human_feedback/human_feedback_5fa87112-3702-4263-ba81-1779b3b24d16.csv\"\n",
    "FILE_5 = \"/home/jacques.furst/development/RAG/flintfiller-precondition-rl/data/human_feedback/human_feedback_7b177fba-3ddb-465b-9a25-6f4481eeb492.csv\"\n",
    "FILE_6 = None\n",
    "FILE_7 = \"/home/jacques.furst/development/RAG/flintfiller-precondition-rl/data/human_feedback/human_feedback_ab53866b-7831-4f33-a628-3b6dbf01ead1.csv\"\n",
    "FILE_8 = \"/home/jacques.furst/development/RAG/flintfiller-precondition-rl/data/human_feedback/human_feedback_b1ed9f35-7d6a-439c-8a46-089311e8e340.csv\"\n",
    "FILE_9 = \"/home/jacques.furst/development/RAG/flintfiller-precondition-rl/data/human_feedback/human_feedback_a8ec999a-935f-476d-ac5c-f328a1288c7c.csv\"\n",
    "FILE_10 = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b127917",
   "metadata": {},
   "source": [
    "### Load all dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1da622b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                               Duidelijk\n",
      "1                               Duidelijk\n",
      "2                               Duidelijk\n",
      "3                               Duidelijk\n",
      "4                               Duidelijk\n",
      "                      ...                \n",
      "136    Onbestemde positie in ground truth\n",
      "137    Onbestemde positie in ground truth\n",
      "138               Helemaal niet duidelijk\n",
      "139               Helemaal niet duidelijk\n",
      "140               Helemaal niet duidelijk\n",
      "Name: feedback_detection, Length: 141, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df_1 = pd.read_csv(FILE_1, sep=\";\")\n",
    "df_3 = pd.read_csv(FILE_3, sep=\";\")\n",
    "df_4 = pd.read_csv(FILE_4, sep=\";\")\n",
    "df_5 = pd.read_csv(FILE_5, sep=\";\")\n",
    "df_7 = pd.read_csv(FILE_7, sep=\";\")\n",
    "df_8 = pd.read_csv(FILE_8, sep=\";\")\n",
    "df_9 = pd.read_csv(FILE_9, sep=\";\")\n",
    "\n",
    "print(df_1['feedback_detection'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b785cc",
   "metadata": {},
   "source": [
    "### Check number of common rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c77d888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of common rows in df1 and df5: 56\n",
      "                                                 file  \\\n",
      "0   Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
      "1   Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
      "2   Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
      "3   Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
      "4   Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
      "5   Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
      "6   Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
      "7   Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
      "8   Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
      "9   Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
      "10  Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
      "11  Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
      "12  Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
      "13  Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
      "14  Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
      "15  Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
      "16  Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
      "17  Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
      "18  Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
      "19  Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
      "20  Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
      "21  Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
      "22  Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
      "23  Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
      "24  Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
      "25  Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
      "26  Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
      "27  Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
      "28  Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
      "29  Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
      "30  Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
      "31  Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
      "32  Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
      "33  Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
      "34  Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
      "35  Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
      "36  Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
      "37  Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
      "38  Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
      "39  Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
      "40  Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
      "41  Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
      "42  Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
      "43  Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
      "44  Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
      "45  Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
      "46  Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
      "47  Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
      "48  Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
      "49  Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
      "50  Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
      "51  Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
      "52  Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
      "53  Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
      "54  Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
      "55  Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
      "\n",
      "                                frame_ID frame_type  \\\n",
      "0   7e8d151e-a6ad-4877-85db-5eda2990ac67       fact   \n",
      "1   7e8d151e-a6ad-4877-85db-5eda2990ac67       fact   \n",
      "2   7e8d151e-a6ad-4877-85db-5eda2990ac67       fact   \n",
      "3   7e8d151e-a6ad-4877-85db-5eda2990ac67       fact   \n",
      "4   7e8d151e-a6ad-4877-85db-5eda2990ac67       fact   \n",
      "5   7e8d151e-a6ad-4877-85db-5eda2990ac67       fact   \n",
      "6   87433709-4703-47ec-a236-3e064973e4c3       fact   \n",
      "7   87433709-4703-47ec-a236-3e064973e4c3       fact   \n",
      "8   87433709-4703-47ec-a236-3e064973e4c3       fact   \n",
      "9   87433709-4703-47ec-a236-3e064973e4c3       fact   \n",
      "10  87433709-4703-47ec-a236-3e064973e4c3       fact   \n",
      "11  87433709-4703-47ec-a236-3e064973e4c3       fact   \n",
      "12  4cf6080d-b56f-4f5d-8386-3be18add6b63       fact   \n",
      "13  4cf6080d-b56f-4f5d-8386-3be18add6b63       fact   \n",
      "14  4cf6080d-b56f-4f5d-8386-3be18add6b63       fact   \n",
      "15  4cf6080d-b56f-4f5d-8386-3be18add6b63       fact   \n",
      "16  4cf6080d-b56f-4f5d-8386-3be18add6b63       fact   \n",
      "17  4cf6080d-b56f-4f5d-8386-3be18add6b63       fact   \n",
      "18  4cf6080d-b56f-4f5d-8386-3be18add6b63       fact   \n",
      "19  4cf6080d-b56f-4f5d-8386-3be18add6b63       fact   \n",
      "20  4cf6080d-b56f-4f5d-8386-3be18add6b63       fact   \n",
      "21  4cf6080d-b56f-4f5d-8386-3be18add6b63       fact   \n",
      "22  4cf6080d-b56f-4f5d-8386-3be18add6b63       fact   \n",
      "23  4cf6080d-b56f-4f5d-8386-3be18add6b63       fact   \n",
      "24  4cf6080d-b56f-4f5d-8386-3be18add6b63       fact   \n",
      "25  4cf6080d-b56f-4f5d-8386-3be18add6b63       fact   \n",
      "26  4cf6080d-b56f-4f5d-8386-3be18add6b63       fact   \n",
      "27  4cf6080d-b56f-4f5d-8386-3be18add6b63       fact   \n",
      "28  4cf6080d-b56f-4f5d-8386-3be18add6b63       fact   \n",
      "29  4cf6080d-b56f-4f5d-8386-3be18add6b63       fact   \n",
      "30  4cf6080d-b56f-4f5d-8386-3be18add6b63       fact   \n",
      "31  4cf6080d-b56f-4f5d-8386-3be18add6b63       fact   \n",
      "32  4cf6080d-b56f-4f5d-8386-3be18add6b63       fact   \n",
      "33  4cf6080d-b56f-4f5d-8386-3be18add6b63       fact   \n",
      "34  4cf6080d-b56f-4f5d-8386-3be18add6b63       fact   \n",
      "35  4cf6080d-b56f-4f5d-8386-3be18add6b63       fact   \n",
      "36  4cf6080d-b56f-4f5d-8386-3be18add6b63       fact   \n",
      "37  4cf6080d-b56f-4f5d-8386-3be18add6b63       fact   \n",
      "38  4cf6080d-b56f-4f5d-8386-3be18add6b63       fact   \n",
      "39  4cf6080d-b56f-4f5d-8386-3be18add6b63       fact   \n",
      "40  43fe2671-232c-4cc1-aac2-dc2855fdb796       fact   \n",
      "41  43fe2671-232c-4cc1-aac2-dc2855fdb796       fact   \n",
      "42  43fe2671-232c-4cc1-aac2-dc2855fdb796       fact   \n",
      "43  43fe2671-232c-4cc1-aac2-dc2855fdb796       fact   \n",
      "44  aa969044-267c-4b75-913a-46743f44eea3       fact   \n",
      "45  aa969044-267c-4b75-913a-46743f44eea3       fact   \n",
      "46  aa969044-267c-4b75-913a-46743f44eea3       fact   \n",
      "47  aa969044-267c-4b75-913a-46743f44eea3       fact   \n",
      "48  aa969044-267c-4b75-913a-46743f44eea3       fact   \n",
      "49  aa969044-267c-4b75-913a-46743f44eea3       fact   \n",
      "50  aa969044-267c-4b75-913a-46743f44eea3       fact   \n",
      "51  aa969044-267c-4b75-913a-46743f44eea3       fact   \n",
      "52  aa969044-267c-4b75-913a-46743f44eea3       fact   \n",
      "53  aa969044-267c-4b75-913a-46743f44eea3       fact   \n",
      "54  aa969044-267c-4b75-913a-46743f44eea3       fact   \n",
      "55  aa969044-267c-4b75-913a-46743f44eea3       fact   \n",
      "\n",
      "                                           frame_text  \\\n",
      "0                                       Onze Minister   \n",
      "1                                       Onze Minister   \n",
      "2                                       Onze Minister   \n",
      "3                                       Onze Minister   \n",
      "4                                       Onze Minister   \n",
      "5                                       Onze Minister   \n",
      "6                                         vreemdeling   \n",
      "7                                         vreemdeling   \n",
      "8                                         vreemdeling   \n",
      "9                                         vreemdeling   \n",
      "10                                        vreemdeling   \n",
      "11                                        vreemdeling   \n",
      "12  de reguliere verblijfsvergunning voor bepaalde...   \n",
      "13  de reguliere verblijfsvergunning voor bepaalde...   \n",
      "14  de reguliere verblijfsvergunning voor bepaalde...   \n",
      "15  de reguliere verblijfsvergunning voor bepaalde...   \n",
      "16  de reguliere verblijfsvergunning voor bepaalde...   \n",
      "17  de reguliere verblijfsvergunning voor bepaalde...   \n",
      "18  de reguliere verblijfsvergunning voor bepaalde...   \n",
      "19  de reguliere verblijfsvergunning voor bepaalde...   \n",
      "20  de reguliere verblijfsvergunning voor bepaalde...   \n",
      "21  de reguliere verblijfsvergunning voor bepaalde...   \n",
      "22  de reguliere verblijfsvergunning voor bepaalde...   \n",
      "23  de reguliere verblijfsvergunning voor bepaalde...   \n",
      "24  de reguliere verblijfsvergunning voor bepaalde...   \n",
      "25  de reguliere verblijfsvergunning voor bepaalde...   \n",
      "26  de reguliere verblijfsvergunning voor bepaalde...   \n",
      "27  de reguliere verblijfsvergunning voor bepaalde...   \n",
      "28  de reguliere verblijfsvergunning voor bepaalde...   \n",
      "29  de reguliere verblijfsvergunning voor bepaalde...   \n",
      "30  de reguliere verblijfsvergunning voor bepaalde...   \n",
      "31  de reguliere verblijfsvergunning voor bepaalde...   \n",
      "32  de reguliere verblijfsvergunning voor bepaalde...   \n",
      "33  de reguliere verblijfsvergunning voor bepaalde...   \n",
      "34  de reguliere verblijfsvergunning voor bepaalde...   \n",
      "35  de reguliere verblijfsvergunning voor bepaalde...   \n",
      "36  de reguliere verblijfsvergunning voor bepaalde...   \n",
      "37  de reguliere verblijfsvergunning voor bepaalde...   \n",
      "38  de reguliere verblijfsvergunning voor bepaalde...   \n",
      "39  de reguliere verblijfsvergunning voor bepaalde...   \n",
      "40  de vreemdeling dan wel de persoon bij wie de v...   \n",
      "41  de vreemdeling dan wel de persoon bij wie de v...   \n",
      "42  de vreemdeling dan wel de persoon bij wie de v...   \n",
      "43  de vreemdeling dan wel de persoon bij wie de v...   \n",
      "44  de aanvrager heeft voldaan aan alle wettelijk ...   \n",
      "45  de aanvrager heeft voldaan aan alle wettelijk ...   \n",
      "46  de aanvrager heeft voldaan aan alle wettelijk ...   \n",
      "47  de aanvrager heeft voldaan aan alle wettelijk ...   \n",
      "48  de aanvrager heeft voldaan aan alle wettelijk ...   \n",
      "49  de aanvrager heeft voldaan aan alle wettelijk ...   \n",
      "50  de aanvrager heeft voldaan aan alle wettelijk ...   \n",
      "51  de aanvrager heeft voldaan aan alle wettelijk ...   \n",
      "52  de aanvrager heeft voldaan aan alle wettelijk ...   \n",
      "53  de aanvrager heeft voldaan aan alle wettelijk ...   \n",
      "54  de aanvrager heeft voldaan aan alle wettelijk ...   \n",
      "55  de aanvrager heeft voldaan aan alle wettelijk ...   \n",
      "\n",
      "                         precondition_id  \\\n",
      "0   341a8e52-ca51-42ec-b84e-f606887369e7   \n",
      "1   7e8d151e-a6ad-4877-85db-5eda2990ac67   \n",
      "2   dd1b844c-4239-4d34-97ef-aa7022f430db   \n",
      "3   341a8e52-ca51-42ec-b84e-f606887369e7   \n",
      "4   7e8d151e-a6ad-4877-85db-5eda2990ac67   \n",
      "5   dd1b844c-4239-4d34-97ef-aa7022f430db   \n",
      "6   87433709-4703-47ec-a236-3e064973e4c3   \n",
      "7   ed38a703-d325-4e29-a645-c9686c55c601   \n",
      "8   86d15d6e-b07d-417d-a031-4c5f5f2db813   \n",
      "9   87433709-4703-47ec-a236-3e064973e4c3   \n",
      "10  ed38a703-d325-4e29-a645-c9686c55c601   \n",
      "11  86d15d6e-b07d-417d-a031-4c5f5f2db813   \n",
      "12  4bc1a4da-3948-46aa-a8a5-392f9ab86522   \n",
      "13  f4cd5c2a-3e67-4a47-8b83-786f7d214add   \n",
      "14  9f6f899f-b9b0-46e2-88ff-3d083b3aa5a0   \n",
      "15  0723cc33-751e-4088-ba1a-7fae6b5a3006   \n",
      "16  43fe2671-232c-4cc1-aac2-dc2855fdb796   \n",
      "17  bb462009-f320-45c8-bebf-bf2e57fb4920   \n",
      "18  4714e879-ad2c-4037-986a-9c1bb9388856   \n",
      "19  a593aa87-d104-4fb7-8aab-3d9fc0ae7197   \n",
      "20  e116e23f-16a6-46a5-873e-2ef818170e7b   \n",
      "21  5f370c30-0085-4094-a386-ce39e897d6c4   \n",
      "22  10d0a3cf-ed2b-4af2-833e-5d2daa301a1f   \n",
      "23  5cb97c0b-d778-4923-be16-128176485abd   \n",
      "24  c9c15103-2bb6-417c-8fae-16309254d47c   \n",
      "25  82bf3f57-919a-4f58-b57f-a495d9b60a7a   \n",
      "26  4bc1a4da-3948-46aa-a8a5-392f9ab86522   \n",
      "27  f4cd5c2a-3e67-4a47-8b83-786f7d214add   \n",
      "28  9f6f899f-b9b0-46e2-88ff-3d083b3aa5a0   \n",
      "29  0723cc33-751e-4088-ba1a-7fae6b5a3006   \n",
      "30  43fe2671-232c-4cc1-aac2-dc2855fdb796   \n",
      "31  bb462009-f320-45c8-bebf-bf2e57fb4920   \n",
      "32  4714e879-ad2c-4037-986a-9c1bb9388856   \n",
      "33  a593aa87-d104-4fb7-8aab-3d9fc0ae7197   \n",
      "34  e116e23f-16a6-46a5-873e-2ef818170e7b   \n",
      "35  5f370c30-0085-4094-a386-ce39e897d6c4   \n",
      "36  10d0a3cf-ed2b-4af2-833e-5d2daa301a1f   \n",
      "37  5cb97c0b-d778-4923-be16-128176485abd   \n",
      "38  c9c15103-2bb6-417c-8fae-16309254d47c   \n",
      "39  82bf3f57-919a-4f58-b57f-a495d9b60a7a   \n",
      "40  0f78bdf4-bf24-4a96-8fd0-93a3c66e0f8f   \n",
      "41  af92160c-df34-4894-999e-5aca49a0e47e   \n",
      "42  0f78bdf4-bf24-4a96-8fd0-93a3c66e0f8f   \n",
      "43  af92160c-df34-4894-999e-5aca49a0e47e   \n",
      "44  5c9df1e1-b210-4850-b0c8-d1edcd39f957   \n",
      "45  e532243b-096a-4a66-931b-c44b84a93b05   \n",
      "46  71c02a7e-5f77-40b4-84aa-085a0a12b7a9   \n",
      "47  cedaf3d2-b672-4b79-8f7e-486ef236bd9a   \n",
      "48  f3399faf-bca5-4b27-97ca-0cff9f4d6dd2   \n",
      "49  1b0195ba-b2d8-4913-8a86-608f4c5ece94   \n",
      "50  5c9df1e1-b210-4850-b0c8-d1edcd39f957   \n",
      "51  e532243b-096a-4a66-931b-c44b84a93b05   \n",
      "52  71c02a7e-5f77-40b4-84aa-085a0a12b7a9   \n",
      "53  cedaf3d2-b672-4b79-8f7e-486ef236bd9a   \n",
      "54  f3399faf-bca5-4b27-97ca-0cff9f4d6dd2   \n",
      "55  1b0195ba-b2d8-4913-8a86-608f4c5ece94   \n",
      "\n",
      "                                    precondition_text  \\\n",
      "0   Onze Minister in de Vreemdelingenwet en de daa...   \n",
      "1                                       Onze Minister   \n",
      "2            Onze Minister van Veiligheid en Justitie   \n",
      "3   Onze Minister in de Vreemdelingenwet en de daa...   \n",
      "4                                       Onze Minister   \n",
      "5            Onze Minister van Veiligheid en Justitie   \n",
      "6                                         vreemdeling   \n",
      "7    NOT ieder die de Nederlandse nationaliteit bezit   \n",
      "8   NOT ieder die op grond van een wettelijke bepa...   \n",
      "9                                         vreemdeling   \n",
      "10   NOT ieder die de Nederlandse nationaliteit bezit   \n",
      "11  NOT ieder die op grond van een wettelijke bepa...   \n",
      "12  de verblijfsvergunning wordt verleend met inga...   \n",
      "13  NOT de verblijfsvergunning wordt verleend met ...   \n",
      "14  de vreemdeling beschikt over een geldige macht...   \n",
      "15  de vreemdeling beschikt over een geldig docume...   \n",
      "16  de vreemdeling dan wel de persoon bij wie de v...   \n",
      "17  NOT de vreemdeling een gevaar vormt voor de op...   \n",
      "18  de vreemdeling is bereid om medewerking te ver...   \n",
      "19  NOT de vreemdeling verricht arbeid voor een we...   \n",
      "20  de vreemdeling voldoet aan de beperking, verba...   \n",
      "21  de vreemdeling beschikt over kennis op basisni...   \n",
      "22  NOT de vreemdeling onjuiste gegevens heeft ver...   \n",
      "23  NOT de vreemdeling in Nederland verblijf heeft...   \n",
      "24  ten behoeve van de vreemdeling een verklaring ...   \n",
      "25  de nadelige gevolgen van een besluit zijn, voo...   \n",
      "26  de verblijfsvergunning wordt verleend met inga...   \n",
      "27  NOT de verblijfsvergunning wordt verleend met ...   \n",
      "28  de vreemdeling beschikt over een geldige macht...   \n",
      "29  de vreemdeling beschikt over een geldig docume...   \n",
      "30  de vreemdeling dan wel de persoon bij wie de v...   \n",
      "31  NOT de vreemdeling een gevaar vormt voor de op...   \n",
      "32  de vreemdeling is bereid om medewerking te ver...   \n",
      "33  NOT de vreemdeling verricht arbeid voor een we...   \n",
      "34  de vreemdeling voldoet aan de beperking, verba...   \n",
      "35  de vreemdeling beschikt over kennis op basisni...   \n",
      "36  NOT de vreemdeling onjuiste gegevens heeft ver...   \n",
      "37  NOT de vreemdeling in Nederland verblijf heeft...   \n",
      "38  ten behoeve van de vreemdeling een verklaring ...   \n",
      "39  de nadelige gevolgen van een besluit zijn, voo...   \n",
      "40  de vreemdeling beschikt zelfstandig en duurzaa...   \n",
      "41  de persoon bij wie de vreemdeling wil verblijv...   \n",
      "42  de vreemdeling beschikt zelfstandig en duurzaa...   \n",
      "43  de persoon bij wie de vreemdeling wil verblijv...   \n",
      "44  NOT de aanvraag of een van de daarbij behorend...   \n",
      "45  NOT de aanvraag of een van de daarbij behorend...   \n",
      "46  de aanvraag voor een verblijfsvergunning voor ...   \n",
      "47  NOT jegens de vreemdeling geldt een inreisverb...   \n",
      "48          NOT de vreemdeling is ongewenst verklaard   \n",
      "49  van de vreemdeling zijn een gezichtsopname en ...   \n",
      "50  NOT de aanvraag of een van de daarbij behorend...   \n",
      "51  NOT de aanvraag of een van de daarbij behorend...   \n",
      "52  de aanvraag voor een verblijfsvergunning voor ...   \n",
      "53  NOT jegens de vreemdeling geldt een inreisverb...   \n",
      "54          NOT de vreemdeling is ongewenst verklaard   \n",
      "55  van de vreemdeling zijn een gezichtsopname en ...   \n",
      "\n",
      "                                precondition_position  \\\n",
      "0                  Artikel 1 IN Vreemdelingenwet 2024   \n",
      "1                  Artikel 1 IN Vreemdelingenwet 2024   \n",
      "2                  Artikel 1 IN Vreemdelingenwet 2024   \n",
      "3                  Artikel 1 IN Vreemdelingenwet 2024   \n",
      "4                  Artikel 1 IN Vreemdelingenwet 2024   \n",
      "5                  Artikel 1 IN Vreemdelingenwet 2024   \n",
      "6                  Artikel 1 IN Vreemdelingenwet 2024   \n",
      "7                  Artikel 1 IN Vreemdelingenwet 2024   \n",
      "8                  Artikel 1 IN Vreemdelingenwet 2024   \n",
      "9                  Artikel 1 IN Vreemdelingenwet 2024   \n",
      "10                 Artikel 1 IN Vreemdelingenwet 2024   \n",
      "11                 Artikel 1 IN Vreemdelingenwet 2024   \n",
      "12       Artikel 26 sectie 1 IN Vreemdelingenwet 2024   \n",
      "13       Artikel 26 sectie 1 IN Vreemdelingenwet 2024   \n",
      "14    Artikel 16, sectie 1 a IN Vreemdelingenwet 2024   \n",
      "15    Artikel 16, sectie 1 b IN Vreemdelingenwet 2024   \n",
      "16    Artikel 16, sectie 1 c IN Vreemdelingenwet 2024   \n",
      "17    Artikel 16, sectie 1 d IN Vreemdelingenwet 2024   \n",
      "18    Artikel 16, sectie 1 e IN Vreemdelingenwet 2024   \n",
      "19    Artikel 16, sectie 1 f IN Vreemdelingenwet 2024   \n",
      "20    Artikel 16, sectie 1 g IN Vreemdelingenwet 2024   \n",
      "21    Artikel 16, sectie 1 h IN Vreemdelingenwet 2024   \n",
      "22    Artikel 16, sectie 1 i IN Vreemdelingenwet 2024   \n",
      "23    Artikel 16, sectie 1 j IN Vreemdelingenwet 2024   \n",
      "24    Artikel 16, sectie 1 k IN Vreemdelingenwet 2024   \n",
      "25  Artikel 3:4, sectie 2 IN Algemene wet bestuurs...   \n",
      "26       Artikel 26 sectie 1 IN Vreemdelingenwet 2024   \n",
      "27       Artikel 26 sectie 1 IN Vreemdelingenwet 2024   \n",
      "28    Artikel 16, sectie 1 a IN Vreemdelingenwet 2024   \n",
      "29    Artikel 16, sectie 1 b IN Vreemdelingenwet 2024   \n",
      "30    Artikel 16, sectie 1 c IN Vreemdelingenwet 2024   \n",
      "31    Artikel 16, sectie 1 d IN Vreemdelingenwet 2024   \n",
      "32    Artikel 16, sectie 1 e IN Vreemdelingenwet 2024   \n",
      "33    Artikel 16, sectie 1 f IN Vreemdelingenwet 2024   \n",
      "34    Artikel 16, sectie 1 g IN Vreemdelingenwet 2024   \n",
      "35    Artikel 16, sectie 1 h IN Vreemdelingenwet 2024   \n",
      "36    Artikel 16, sectie 1 i IN Vreemdelingenwet 2024   \n",
      "37    Artikel 16, sectie 1 j IN Vreemdelingenwet 2024   \n",
      "38    Artikel 16, sectie 1 k IN Vreemdelingenwet 2024   \n",
      "39  Artikel 3:4, sectie 2 IN Algemene wet bestuurs...   \n",
      "40     Artikel 16 sectie 1 c IN Vreemdelingenwet 2024   \n",
      "41     Artikel 16 sectie 1 c IN Vreemdelingenwet 2024   \n",
      "42     Artikel 16 sectie 1 c IN Vreemdelingenwet 2024   \n",
      "43     Artikel 16 sectie 1 c IN Vreemdelingenwet 2024   \n",
      "44  Artikel 4:5, sectie 2 IN Algemene wet bestuurs...   \n",
      "45  Artikel 4:5, sectie 3 IN Algemene wet bestuurs...   \n",
      "46     Artikel 14 sectie 1,3 IN Vreemdelingenwet 2024   \n",
      "47      Artikel 66a sectie 6 IN Vreemdelingenwet 2024   \n",
      "48       Artikel 67 sectie 3 IN Vreemdelingenwet 2024   \n",
      "49     Artikel 106a sectie 1 IN Vreemdelingenwet 2024   \n",
      "50  Artikel 4:5, sectie 2 IN Algemene wet bestuurs...   \n",
      "51  Artikel 4:5, sectie 3 IN Algemene wet bestuurs...   \n",
      "52     Artikel 14 sectie 1,3 IN Vreemdelingenwet 2024   \n",
      "53      Artikel 66a sectie 6 IN Vreemdelingenwet 2024   \n",
      "54       Artikel 67 sectie 3 IN Vreemdelingenwet 2024   \n",
      "55     Artikel 106a sectie 1 IN Vreemdelingenwet 2024   \n",
      "\n",
      "                                        response_text  prompt_config_examples  \\\n",
      "0   1. Subfact: Onze Minister\\n                2. ...                   False   \n",
      "1   1. Subfact: Onze Minister\\n                2. ...                   False   \n",
      "2   1. Subfact: Onze Minister\\n                2. ...                   False   \n",
      "3   1. Subfact: Onze Minister\\n\\n                2...                   False   \n",
      "4   1. Subfact: Onze Minister\\n\\n                2...                   False   \n",
      "5   1. Subfact: Onze Minister\\n\\n                2...                   False   \n",
      "6   1. Vreemdeling: ieder die de Nederlandse natio...                   False   \n",
      "7   1. Vreemdeling: ieder die de Nederlandse natio...                   False   \n",
      "8   1. Vreemdeling: ieder die de Nederlandse natio...                   False   \n",
      "9   1. Vreemdeling: Vreemdeling\\n\\n               ...                   False   \n",
      "10  1. Vreemdeling: Vreemdeling\\n\\n               ...                   False   \n",
      "11  1. Vreemdeling: Vreemdeling\\n\\n               ...                   False   \n",
      "12  1. De aanvraag is ontvangen \\n                ...                   False   \n",
      "13  1. De aanvraag is ontvangen \\n                ...                   False   \n",
      "14  1. De aanvraag is ontvangen \\n                ...                   False   \n",
      "15  1. De aanvraag is ontvangen \\n                ...                   False   \n",
      "16  1. De aanvraag is ontvangen \\n                ...                   False   \n",
      "17  1. De aanvraag is ontvangen \\n                ...                   False   \n",
      "18  1. De aanvraag is ontvangen \\n                ...                   False   \n",
      "19  1. De aanvraag is ontvangen \\n                ...                   False   \n",
      "20  1. De aanvraag is ontvangen \\n                ...                   False   \n",
      "21  1. De aanvraag is ontvangen \\n                ...                   False   \n",
      "22  1. De aanvraag is ontvangen \\n                ...                   False   \n",
      "23  1. De aanvraag is ontvangen \\n                ...                   False   \n",
      "24  1. De aanvraag is ontvangen \\n                ...                   False   \n",
      "25  1. De aanvraag is ontvangen \\n                ...                   False   \n",
      "26  1. Subfact: De aanvraag is ontvangen\\n        ...                   False   \n",
      "27  1. Subfact: De aanvraag is ontvangen\\n        ...                   False   \n",
      "28  1. Subfact: De aanvraag is ontvangen\\n        ...                   False   \n",
      "29  1. Subfact: De aanvraag is ontvangen\\n        ...                   False   \n",
      "30  1. Subfact: De aanvraag is ontvangen\\n        ...                   False   \n",
      "31  1. Subfact: De aanvraag is ontvangen\\n        ...                   False   \n",
      "32  1. Subfact: De aanvraag is ontvangen\\n        ...                   False   \n",
      "33  1. Subfact: De aanvraag is ontvangen\\n        ...                   False   \n",
      "34  1. Subfact: De aanvraag is ontvangen\\n        ...                   False   \n",
      "35  1. Subfact: De aanvraag is ontvangen\\n        ...                   False   \n",
      "36  1. Subfact: De aanvraag is ontvangen\\n        ...                   False   \n",
      "37  1. Subfact: De aanvraag is ontvangen\\n        ...                   False   \n",
      "38  1. Subfact: De aanvraag is ontvangen\\n        ...                   False   \n",
      "39  1. Subfact: De aanvraag is ontvangen\\n        ...                   False   \n",
      "40  1. Subfact: De vreemdeling beschikt zelfstandi...                   False   \n",
      "41  1. Subfact: De vreemdeling beschikt zelfstandi...                   False   \n",
      "42  1. Subfact: De vreemdeling beschikt zelfstandi...                   False   \n",
      "43  1. Subfact: De vreemdeling beschikt zelfstandi...                   False   \n",
      "44  1. De aanvrager heeft voldaan aan enig wetteli...                   False   \n",
      "45  1. De aanvrager heeft voldaan aan enig wetteli...                   False   \n",
      "46  1. De aanvrager heeft voldaan aan enig wetteli...                   False   \n",
      "47  1. De aanvrager heeft voldaan aan enig wetteli...                   False   \n",
      "48  1. De aanvrager heeft voldaan aan enig wetteli...                   False   \n",
      "49  1. De aanvrager heeft voldaan aan enig wetteli...                   False   \n",
      "50  1. Subfact: de aanvrager heeft voldaan aan een...                   False   \n",
      "51  1. Subfact: de aanvrager heeft voldaan aan een...                   False   \n",
      "52  1. Subfact: de aanvrager heeft voldaan aan een...                   False   \n",
      "53  1. Subfact: de aanvrager heeft voldaan aan een...                   False   \n",
      "54  1. Subfact: de aanvrager heeft voldaan aan een...                   False   \n",
      "55  1. Subfact: de aanvrager heeft voldaan aan een...                   False   \n",
      "\n",
      "    prompt_config_chain_of_thought  \n",
      "0                             True  \n",
      "1                             True  \n",
      "2                             True  \n",
      "3                             True  \n",
      "4                             True  \n",
      "5                             True  \n",
      "6                             True  \n",
      "7                             True  \n",
      "8                             True  \n",
      "9                             True  \n",
      "10                            True  \n",
      "11                            True  \n",
      "12                            True  \n",
      "13                            True  \n",
      "14                            True  \n",
      "15                            True  \n",
      "16                            True  \n",
      "17                            True  \n",
      "18                            True  \n",
      "19                            True  \n",
      "20                            True  \n",
      "21                            True  \n",
      "22                            True  \n",
      "23                            True  \n",
      "24                            True  \n",
      "25                            True  \n",
      "26                            True  \n",
      "27                            True  \n",
      "28                            True  \n",
      "29                            True  \n",
      "30                            True  \n",
      "31                            True  \n",
      "32                            True  \n",
      "33                            True  \n",
      "34                            True  \n",
      "35                            True  \n",
      "36                            True  \n",
      "37                            True  \n",
      "38                            True  \n",
      "39                            True  \n",
      "40                            True  \n",
      "41                            True  \n",
      "42                            True  \n",
      "43                            True  \n",
      "44                            True  \n",
      "45                            True  \n",
      "46                            True  \n",
      "47                            True  \n",
      "48                            True  \n",
      "49                            True  \n",
      "50                            True  \n",
      "51                            True  \n",
      "52                            True  \n",
      "53                            True  \n",
      "54                            True  \n",
      "55                            True  \n",
      "common files: ['Interpretatie_Vw_over_besluiten_op_aanvragen_voor_een_verblijfsvergunning_regulier_bepaalde_tijd.json']\n",
      "common frames: ['fact']\n"
     ]
    }
   ],
   "source": [
    "df_test_1 = df_3.iloc[:, :-3]\n",
    "df_test_2 = df_8.iloc[:, :-3]\n",
    "\n",
    "\n",
    "common = pd.merge(df_test_1, df_test_2, how='inner')\n",
    "print(\"Number of common rows in df1 and df5:\", len(common))\n",
    "print(common)\n",
    "\n",
    "# TODO: print file and frame type for common rows\n",
    "print(f\"common files: {common['file'].unique()}\")\n",
    "print(f\"common frames: {common['frame_type'].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4e952f",
   "metadata": {},
   "source": [
    "### Cast ratings to numeric values to use fleiss kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c2a0026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array(['Niet goed'], dtype=object)\n"
     ]
    }
   ],
   "source": [
    "print(repr(df_2.loc[df_2['feedback_detection'].str.contains(\"Niet goed\", na=False), 'feedback_detection'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05ecf0ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2455587/3453023554.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['feedback_extraction'] = [parse_ratings(feedback) for feedback in df['feedback_extraction']]\n",
      "/tmp/ipykernel_2455587/3453023554.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['feedback_detection'] = [parse_ratings(feedback_detec) for feedback_detec in df['feedback_detection']]\n"
     ]
    }
   ],
   "source": [
    "# parse ratings in all dataframes to be able to calculate Fleiss kappa\n",
    "def apply_parse_ratings(df, number):\n",
    "    df['feedback_extraction'] = [parse_ratings(feedback) for feedback in df['feedback_extraction']]\n",
    "    # print(number)\n",
    "    # print(df['feedback_detection'])\n",
    "    df['feedback_detection'] = [parse_ratings(feedback_detec) for feedback_detec in df['feedback_detection']]\n",
    "    # print(df['feedback_detection'])\n",
    "    return df\n",
    "\n",
    "# Apply to each DataFrame\n",
    "df1 = apply_parse_ratings(df_1, 1)\n",
    "df2 = apply_parse_ratings(df_2, 2)\n",
    "df3 = apply_parse_ratings(df_3, 3)\n",
    "df4 = apply_parse_ratings(df_4, 4)\n",
    "df5 = apply_parse_ratings(df_5, 5)\n",
    "df6 = apply_parse_ratings(df_6, 6)\n",
    "df7 = apply_parse_ratings(df_7, 7)\n",
    "df8 = apply_parse_ratings(df_8, 8)\n",
    "df9 = apply_parse_ratings(df_9, 9)\n",
    "df10 = apply_parse_ratings(df_10, 10)\n",
    "\n",
    "df_synthetic1 = apply_parse_ratings(df_synthetic_1, \"synthetic1\")\n",
    "df_synthetic2 = apply_parse_ratings(df_synthetic_2, \"synthetic2\")\n",
    "\n",
    "# Check if any feedback column contains Nan values\n",
    "\n",
    "\n",
    "print(df1['feedback_detection'].isna().any())\n",
    "print(df2['feedback_detection'].isna().any())\n",
    "print(df3['feedback_detection'].isna().any())\n",
    "print(df4['feedback_detection'].isna().any())\n",
    "print(df5['feedback_detection'].isna().any())\n",
    "print(df6['feedback_detection'].isna().any())\n",
    "print(df7['feedback_detection'].isna().any())\n",
    "print(df8['feedback_detection'].isna().any())\n",
    "print(df9['feedback_detection'].isna().any())\n",
    "print(df10['feedback_detection'].isna().any())\n",
    "print(df_synthetic1['feedback_detection'].isna().any())\n",
    "print(df_synthetic2['feedback_detection'].isna().any())\n",
    "\n",
    "print(df1['feedback_extraction'].isna().any())\n",
    "print(df2['feedback_extraction'].isna().any())\n",
    "print(df3['feedback_extraction'].isna().any())\n",
    "print(df4['feedback_extraction'].isna().any())\n",
    "print(df5['feedback_extraction'].isna().any())\n",
    "print(df6['feedback_extraction'].isna().any())\n",
    "print(df7['feedback_extraction'].isna().any())\n",
    "print(df8['feedback_extraction'].isna().any())\n",
    "print(df9['feedback_extraction'].isna().any())\n",
    "print(df10['feedback_extraction'].isna().any())\n",
    "print(df_synthetic1['feedback_extraction'].isna().any())\n",
    "print(df_synthetic2['feedback_extraction'].isna().any())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d031f767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are the first 50 rows of df1 and df2 equal (excluding last 3 columns)? True\n",
      "Are the first 50 rows of df1 and df3 equal (excluding last 3 columns)? True\n",
      "Are the first 50 rows of df1 and df4 equal (excluding last 3 columns)? True\n",
      "Are the first 50 rows of df1 and df5 equal (excluding last 3 columns)? True\n",
      "Are the first 50 rows of df1 and df6 equal (excluding last 3 columns)? True\n",
      "Are the first 50 rows of df1 and df7 equal (excluding last 3 columns)? True\n",
      "Are the first 50 rows of df1 and df8 equal (excluding last 3 columns)? True\n",
      "Are the first 50 rows of df1 and df9 equal (excluding last 3 columns)? True\n",
      "Are the first 50 rows of df1 and df10 equal (excluding last 3 columns)? True\n"
     ]
    }
   ],
   "source": [
    "# Collect the first 50 entries from each DataFrame for each column\n",
    "dfs = [df1, df5, df7, df9, df10]\n",
    "# dfs = [df5, df8]\n",
    "\n",
    "\n",
    "# synthetic dataframes\n",
    "dfs_synthetic = [df_synthetic1, df_synthetic2]\n",
    "\n",
    "\n",
    "# Compare first 50 rows, excluding the last 3 columns\n",
    "subset1 = df1.iloc[:50, :-3]\n",
    "subset2 = df2.iloc[:50, :-3]\n",
    "subset3 = df3.iloc[:50, :-3]\n",
    "subset4 = df4.iloc[:50, :-3]\n",
    "subset5 = df5.iloc[:50, :-3]\n",
    "subset6 = df6.iloc[:50, :-3]\n",
    "subset7 = df7.iloc[:50, :-3]\n",
    "subset8 = df8.iloc[:50, :-3]\n",
    "subset9 = df9.iloc[:50, :-3]\n",
    "subset10 = df10.iloc[:50, :-3]\n",
    "\n",
    "# Check if they are equal\n",
    "are_equal_1_2 = subset1.equals(subset2)\n",
    "are_equal_1_3 = subset1.equals(subset3)\n",
    "are_equal_1_4 = subset1.equals(subset4)\n",
    "are_equal_1_5 = subset1.equals(subset5)\n",
    "are_equal_1_6 = subset1.equals(subset6)\n",
    "are_equal_1_7 = subset1.equals(subset7)\n",
    "are_equal_1_8 = subset1.equals(subset8)\n",
    "are_equal_1_9 = subset1.equals(subset9)\n",
    "are_equal_1_10 = subset1.equals(subset10)\n",
    "\n",
    "# Print results of how equal stuff is\n",
    "print(\"Are the first 50 rows of df1 and df2 equal (excluding last 3 columns)?\", are_equal_1_2)\n",
    "print(\"Are the first 50 rows of df1 and df3 equal (excluding last 3 columns)?\", are_equal_1_3)\n",
    "print(\"Are the first 50 rows of df1 and df4 equal (excluding last 3 columns)?\", are_equal_1_4)\n",
    "print(\"Are the first 50 rows of df1 and df5 equal (excluding last 3 columns)?\", are_equal_1_5)\n",
    "print(\"Are the first 50 rows of df1 and df6 equal (excluding last 3 columns)?\", are_equal_1_6)\n",
    "print(\"Are the first 50 rows of df1 and df7 equal (excluding last 3 columns)?\", are_equal_1_7)\n",
    "print(\"Are the first 50 rows of df1 and df8 equal (excluding last 3 columns)?\", are_equal_1_8)\n",
    "print(\"Are the first 50 rows of df1 and df9 equal (excluding last 3 columns)?\", are_equal_1_9)\n",
    "print(\"Are the first 50 rows of df1 and df10 equal (excluding last 3 columns)?\", are_equal_1_10)\n",
    "\n",
    "# Helper function to extract and stack ratings\n",
    "def prepare_data(dfs, column):\n",
    "    # print(column)\n",
    "    data = [df[column].iloc[:50].tolist() for df in dfs]\n",
    "\n",
    "    # print(data)\n",
    "    return torch.tensor(list(zip(*data))) # shape: (50 items, 8 raters)\n",
    "\n",
    "\n",
    "# # Convert feedback extraction column to int\n",
    "# for df in dfs:\n",
    "#     df['feedback_extraction'] = df['feedback_extraction'].astype(int)\n",
    "#     df['feedback_detection'] = df['feedback_detection'].astype(int)\n",
    "\n",
    "# Prepare data\n",
    "extraction_tensor = prepare_data(dfs, 'feedback_extraction')\n",
    "detection_tensor = prepare_data(dfs, 'feedback_detection')\n",
    "\n",
    "# couont categories to pass into fleiss kappa\n",
    "extraction_categories = [os.getenv(\"EXTRACTION_FEEDBACK_0\"), os.getenv(\"EXTRACTION_FEEDBACK_1\"), os.getenv(\"EXTRACTION_FEEDBACK_2\"), os.getenv(\"EXTRACTION_FEEDBACK_3\")]\n",
    "detection_categories = [os.getenv(\"DETECTION_FEEDBACK_0\"), os.getenv(\"DETECTION_FEEDBACK_1\"), os.getenv(\"DETECTION_FEEDBACK_NONEXISTENT\")]\n",
    "\n",
    "categories_count_extraction = count_categories(extraction_tensor, extraction_categories)\n",
    "categories_count_detection = count_categories(detection_tensor, detection_categories)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29a107a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fleiss' Kappa for feedback_extraction: tensor(0.4705)\n",
      "Fleiss' Kappa for feedback_detection: tensor(0.5817)\n"
     ]
    }
   ],
   "source": [
    "kappa = FleissKappa(mode='counts')\n",
    "\n",
    "print(\"Fleiss' Kappa for feedback_extraction:\", kappa(categories_count_extraction))\n",
    "print(\"Fleiss' Kappa for feedback_detection:\", kappa(categories_count_detection))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d5c986",
   "metadata": {},
   "source": [
    "# Check distribution of acts/facts in different groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b391bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of entries in the combined DataFrame: 929\n",
      "Number of fact entries in the combined DataFrame: 502\n",
      "Number of act entries in the combined DataFrame: 427\n"
     ]
    }
   ],
   "source": [
    "big_df = pd.concat(dfs, ignore_index=True)\n",
    "print(\"Total number of entries in the combined DataFrame:\", len(big_df))\n",
    "print(\"Number of fact entries in the combined DataFrame:\", (big_df['frame_type']=='fact').sum())\n",
    "print(\"Number of act entries in the combined DataFrame:\", (big_df['frame_type']=='act').sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81f7b228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of entries in the combined synthetic DataFrame: 564\n",
      "Number of fact entries in the combined synthetic DataFrame: 260\n",
      "Number of act entries in the combined synthetic DataFrame: 304\n"
     ]
    }
   ],
   "source": [
    "big_synthetic_df = pd.concat(dfs_synthetic, ignore_index=True)\n",
    "print(\"Total number of entries in the combined synthetic DataFrame:\", len(big_synthetic_df))\n",
    "print(\"Number of fact entries in the combined synthetic DataFrame:\", (big_synthetic_df['frame_type']=='fact').sum())\n",
    "print(\"Number of act entries in the combined synthetic DataFrame:\", (big_synthetic_df['frame_type']=='act').sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827da58c",
   "metadata": {},
   "source": [
    "# Check act and fact inter-annotator agreement for rest of data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b33ec71",
   "metadata": {},
   "source": [
    "### Df10 contains both datasets and thus needs to be split accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c14b805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract dataset 1 and 2 from df10 which contains both\n",
    "\n",
    "df10_group1 = pd.concat([df_10_1.head(56), df_10_2], ignore_index=True)\n",
    "df10_group1 = apply_parse_ratings(df10_group1, 11)\n",
    "\n",
    "df10_group2 = apply_parse_ratings(df_10_1, 12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141d24c6",
   "metadata": {},
   "source": [
    "### Df1 has a very different order to its data and thus needs to be restructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34b120cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of matching rows in group 1: 103\n",
      "Number of matching rows in group 2: 94\n"
     ]
    }
   ],
   "source": [
    "# Find matching rows\n",
    "df1_reduced = df1.iloc[:, :-3]  # Exclude the last 3 columns\n",
    "df5_reduced = df5.iloc[:, :-3]  # Exclude the last 3 columns --> group 2\n",
    "df7_reduced = df3.iloc[:, :-3]  # Exclude the last 3 columns --> group 1\n",
    "\n",
    "matching_indices1_group1 = df1_reduced[df1_reduced.isin(df7_reduced.to_dict(orient='list')).all(axis=1)].index\n",
    "matching_indices2_group2 = df1_reduced[df1_reduced.isin(df5_reduced.to_dict(orient='list')).all(axis=1)].index\n",
    "# Extract matching rows\n",
    "df1_group1 = df1.loc[matching_indices1_group1].reset_index(drop=True)\n",
    "df1_group2 = df1.loc[matching_indices2_group2].reset_index(drop=True)\n",
    "# Print the number of matching rows for each group\n",
    "print(\"Number of matching rows in group 1:\", len(df1_group1))\n",
    "print(\"Number of matching rows in group 2:\", len(df1_group2))\n",
    "\n",
    "#TODO: find specific order, re-order all dataframes according to it since otherwise Kappa will be wrong OR jut exclude this dataframe from the analysis? \n",
    "# NO, SINCE IT COUNTS INTO FLEISS KAPPA FOR EACH GROUP NO MATTER WHAT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e736f0",
   "metadata": {},
   "source": [
    "### Dfs synthetic need to be re-stuctured according to the two datasets sice they were just run on the whole dataset at once --> need to plit them into the two datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5078c213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of matching rows in synthetic group 1: 170\n",
      "Number of matching rows in synthetic group 2: 168\n",
      "Number of matching rows in synthetic group 1: 170\n",
      "Number of matching rows in synthetic group 2: 168\n",
      "170\n",
      "168\n"
     ]
    }
   ],
   "source": [
    "# get two data rows for first and second dataset\n",
    "\n",
    "rows_group1 = df7.iloc[:, :-3]\n",
    "rows_group2 = df5.iloc[:, :-3]\n",
    "\n",
    "# get the important columns from the synthetic dataframe\n",
    "matching_columns1 = df_synthetic1.columns[:-4] \n",
    "\n",
    "# Merge with df1 to find matching rows\n",
    "df_synthetic1_group1 = df_synthetic1.merge(rows_group1, on=list(matching_columns1), how='inner')\n",
    "df_synthetic1_group2 = df_synthetic1.merge(rows_group2, on=list(matching_columns1), how='inner')\n",
    "\n",
    "# get the important columns from the synthetic dataframe\n",
    "matching_columns2 = df_synthetic2.columns[:-4] \n",
    "\n",
    "# Merge with df1 to find matching rows\n",
    "df_synthetic2_group1 = df_synthetic2.merge(rows_group1, on=list(matching_columns2), how='inner')\n",
    "df_synthetic2_group2 = df_synthetic2.merge(rows_group2, on=list(matching_columns2), how='inner')\n",
    "\n",
    "\n",
    "print(\"Number of matching rows in synthetic group 1:\", len(df_synthetic1_group1))\n",
    "print(\"Number of matching rows in synthetic group 2:\", len(df_synthetic1_group2))\n",
    "print(\"Number of matching rows in synthetic group 1:\", len(df_synthetic2_group1))\n",
    "print(\"Number of matching rows in synthetic group 2:\", len(df_synthetic2_group2))\n",
    "print(len(df7))\n",
    "print(len(df5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54df978",
   "metadata": {},
   "source": [
    "## Sort dfs by unique key (combination of act and precondition)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ec95e7",
   "metadata": {},
   "source": [
    "### For dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "471a7843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a composite key\n",
    "df7['key'] = list(zip(df7['frame_ID'], df7['precondition_id'],df7['response_text']))\n",
    "df1_group1['key'] = list(zip(df1_group1['frame_ID'], df1_group1['precondition_id'], df1_group1['response_text']))\n",
    "df10_group1['key'] = list(zip(df10_group1['frame_ID'], df10_group1['precondition_id'], df10_group1['response_text']))\n",
    "df_synthetic1_group1['key'] = list(zip(df_synthetic1_group1['frame_ID'], df_synthetic1_group1['precondition_id'], df_synthetic1_group1['response_text']))\n",
    "df_synthetic2_group1['key'] = list(zip(df_synthetic2_group1['frame_ID'], df_synthetic2_group1['precondition_id'], df_synthetic2_group1['response_text']))\n",
    "\n",
    "\n",
    "# get the order of keys in df1_group1\n",
    "key_order1 = {key: i for i, key in enumerate(df1_group1['key'])}\n",
    "\n",
    "# Map this order to df7\n",
    "df7['sort_order'] = df7['key'].map(key_order1)\n",
    "\n",
    "# Sort df7 — first by sort_order (NaNs last), then by key or index and get its order of keys\n",
    "df7_sorted = df7.sort_values(by=['sort_order', 'key'], na_position='last').reset_index(drop=True)\n",
    "ordered_keys_df7 = df7_sorted['key'].tolist()\n",
    "\n",
    "\n",
    "#sort df1_group1 and df10_group1 according to the initial key order determined for df1_group1 and the order of keys in df7_sorted respectively\n",
    "df1_group1_sorted = df1_group1.set_index('key').reindex(key_order1).dropna(how='all')\n",
    "df1_group1_sorted = df1_group1_sorted.reset_index()\n",
    "df10_group1_sorted = df10_group1.set_index('key').reindex(ordered_keys_df7).dropna(how='all').reset_index()\n",
    "\n",
    "\n",
    "# Sort synthetic dataframes according to the order of keys in df7_sorted\n",
    "df_synthetic1_group1_sorted = df_synthetic1_group1.set_index('key').reindex(ordered_keys_df7).dropna(how='all').reset_index()\n",
    "df_synthetic2_group1_sorted = df_synthetic2_group1.set_index('key').reindex(ordered_keys_df7).dropna(how='all').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a94dcc79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>level_1</th>\n",
       "      <th>level_2</th>\n",
       "      <th>file</th>\n",
       "      <th>frame_ID</th>\n",
       "      <th>frame_type</th>\n",
       "      <th>frame_text</th>\n",
       "      <th>precondition_id</th>\n",
       "      <th>precondition_text</th>\n",
       "      <th>precondition_position</th>\n",
       "      <th>response_text</th>\n",
       "      <th>prompt_config_examples</th>\n",
       "      <th>prompt_config_chain_of_thought</th>\n",
       "      <th>feedback_extraction</th>\n",
       "      <th>feedback_detection</th>\n",
       "      <th>additional_feedback</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7e8d151e-a6ad-4877-85db-5eda2990ac67</td>\n",
       "      <td>341a8e52-ca51-42ec-b84e-f606887369e7</td>\n",
       "      <td>1. Subfact: Onze Minister\\n                2. ...</td>\n",
       "      <td>Interpretatie_Vw_over_besluiten_op_aanvragen_v...</td>\n",
       "      <td>7e8d151e-a6ad-4877-85db-5eda2990ac67</td>\n",
       "      <td>fact</td>\n",
       "      <td>Onze Minister</td>\n",
       "      <td>341a8e52-ca51-42ec-b84e-f606887369e7</td>\n",
       "      <td>Onze Minister in de Vreemdelingenwet en de daa...</td>\n",
       "      <td>Artikel 1 IN Vreemdelingenwet 2024</td>\n",
       "      <td>1. Subfact: Onze Minister\\n                2. ...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7e8d151e-a6ad-4877-85db-5eda2990ac67</td>\n",
       "      <td>7e8d151e-a6ad-4877-85db-5eda2990ac67</td>\n",
       "      <td>1. Subfact: Onze Minister\\n                2. ...</td>\n",
       "      <td>Interpretatie_Vw_over_besluiten_op_aanvragen_v...</td>\n",
       "      <td>7e8d151e-a6ad-4877-85db-5eda2990ac67</td>\n",
       "      <td>fact</td>\n",
       "      <td>Onze Minister</td>\n",
       "      <td>7e8d151e-a6ad-4877-85db-5eda2990ac67</td>\n",
       "      <td>Onze Minister</td>\n",
       "      <td>Artikel 1 IN Vreemdelingenwet 2024</td>\n",
       "      <td>1. Subfact: Onze Minister\\n                2. ...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7e8d151e-a6ad-4877-85db-5eda2990ac67</td>\n",
       "      <td>dd1b844c-4239-4d34-97ef-aa7022f430db</td>\n",
       "      <td>1. Subfact: Onze Minister\\n                2. ...</td>\n",
       "      <td>Interpretatie_Vw_over_besluiten_op_aanvragen_v...</td>\n",
       "      <td>7e8d151e-a6ad-4877-85db-5eda2990ac67</td>\n",
       "      <td>fact</td>\n",
       "      <td>Onze Minister</td>\n",
       "      <td>dd1b844c-4239-4d34-97ef-aa7022f430db</td>\n",
       "      <td>Onze Minister van Veiligheid en Justitie</td>\n",
       "      <td>Artikel 1 IN Vreemdelingenwet 2024</td>\n",
       "      <td>1. Subfact: Onze Minister\\n                2. ...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7e8d151e-a6ad-4877-85db-5eda2990ac67</td>\n",
       "      <td>341a8e52-ca51-42ec-b84e-f606887369e7</td>\n",
       "      <td>1. Subfact: Onze Minister\\n\\n                2...</td>\n",
       "      <td>Interpretatie_Vw_over_besluiten_op_aanvragen_v...</td>\n",
       "      <td>7e8d151e-a6ad-4877-85db-5eda2990ac67</td>\n",
       "      <td>fact</td>\n",
       "      <td>Onze Minister</td>\n",
       "      <td>341a8e52-ca51-42ec-b84e-f606887369e7</td>\n",
       "      <td>Onze Minister in de Vreemdelingenwet en de daa...</td>\n",
       "      <td>Artikel 1 IN Vreemdelingenwet 2024</td>\n",
       "      <td>1. Subfact: Onze Minister\\n\\n                2...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7e8d151e-a6ad-4877-85db-5eda2990ac67</td>\n",
       "      <td>7e8d151e-a6ad-4877-85db-5eda2990ac67</td>\n",
       "      <td>1. Subfact: Onze Minister\\n\\n                2...</td>\n",
       "      <td>Interpretatie_Vw_over_besluiten_op_aanvragen_v...</td>\n",
       "      <td>7e8d151e-a6ad-4877-85db-5eda2990ac67</td>\n",
       "      <td>fact</td>\n",
       "      <td>Onze Minister</td>\n",
       "      <td>7e8d151e-a6ad-4877-85db-5eda2990ac67</td>\n",
       "      <td>Onze Minister</td>\n",
       "      <td>Artikel 1 IN Vreemdelingenwet 2024</td>\n",
       "      <td>1. Subfact: Onze Minister\\n\\n                2...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                level_0                               level_1  \\\n",
       "0  7e8d151e-a6ad-4877-85db-5eda2990ac67  341a8e52-ca51-42ec-b84e-f606887369e7   \n",
       "1  7e8d151e-a6ad-4877-85db-5eda2990ac67  7e8d151e-a6ad-4877-85db-5eda2990ac67   \n",
       "2  7e8d151e-a6ad-4877-85db-5eda2990ac67  dd1b844c-4239-4d34-97ef-aa7022f430db   \n",
       "3  7e8d151e-a6ad-4877-85db-5eda2990ac67  341a8e52-ca51-42ec-b84e-f606887369e7   \n",
       "4  7e8d151e-a6ad-4877-85db-5eda2990ac67  7e8d151e-a6ad-4877-85db-5eda2990ac67   \n",
       "\n",
       "                                             level_2  \\\n",
       "0  1. Subfact: Onze Minister\\n                2. ...   \n",
       "1  1. Subfact: Onze Minister\\n                2. ...   \n",
       "2  1. Subfact: Onze Minister\\n                2. ...   \n",
       "3  1. Subfact: Onze Minister\\n\\n                2...   \n",
       "4  1. Subfact: Onze Minister\\n\\n                2...   \n",
       "\n",
       "                                                file  \\\n",
       "0  Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
       "1  Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
       "2  Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
       "3  Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
       "4  Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
       "\n",
       "                               frame_ID frame_type     frame_text  \\\n",
       "0  7e8d151e-a6ad-4877-85db-5eda2990ac67       fact  Onze Minister   \n",
       "1  7e8d151e-a6ad-4877-85db-5eda2990ac67       fact  Onze Minister   \n",
       "2  7e8d151e-a6ad-4877-85db-5eda2990ac67       fact  Onze Minister   \n",
       "3  7e8d151e-a6ad-4877-85db-5eda2990ac67       fact  Onze Minister   \n",
       "4  7e8d151e-a6ad-4877-85db-5eda2990ac67       fact  Onze Minister   \n",
       "\n",
       "                        precondition_id  \\\n",
       "0  341a8e52-ca51-42ec-b84e-f606887369e7   \n",
       "1  7e8d151e-a6ad-4877-85db-5eda2990ac67   \n",
       "2  dd1b844c-4239-4d34-97ef-aa7022f430db   \n",
       "3  341a8e52-ca51-42ec-b84e-f606887369e7   \n",
       "4  7e8d151e-a6ad-4877-85db-5eda2990ac67   \n",
       "\n",
       "                                   precondition_text  \\\n",
       "0  Onze Minister in de Vreemdelingenwet en de daa...   \n",
       "1                                      Onze Minister   \n",
       "2           Onze Minister van Veiligheid en Justitie   \n",
       "3  Onze Minister in de Vreemdelingenwet en de daa...   \n",
       "4                                      Onze Minister   \n",
       "\n",
       "                precondition_position  \\\n",
       "0  Artikel 1 IN Vreemdelingenwet 2024   \n",
       "1  Artikel 1 IN Vreemdelingenwet 2024   \n",
       "2  Artikel 1 IN Vreemdelingenwet 2024   \n",
       "3  Artikel 1 IN Vreemdelingenwet 2024   \n",
       "4  Artikel 1 IN Vreemdelingenwet 2024   \n",
       "\n",
       "                                       response_text  prompt_config_examples  \\\n",
       "0  1. Subfact: Onze Minister\\n                2. ...                   False   \n",
       "1  1. Subfact: Onze Minister\\n                2. ...                   False   \n",
       "2  1. Subfact: Onze Minister\\n                2. ...                   False   \n",
       "3  1. Subfact: Onze Minister\\n\\n                2...                   False   \n",
       "4  1. Subfact: Onze Minister\\n\\n                2...                   False   \n",
       "\n",
       "   prompt_config_chain_of_thought  feedback_extraction  feedback_detection  \\\n",
       "0                            True                    2                   4   \n",
       "1                            True                    2                   4   \n",
       "2                            True                    2                   4   \n",
       "3                            True                    2                   4   \n",
       "4                            True                    3                   4   \n",
       "\n",
       "   additional_feedback  \n",
       "0                  NaN  \n",
       "1                  NaN  \n",
       "2                  NaN  \n",
       "3                  NaN  \n",
       "4                  NaN  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_group1_sorted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e58944",
   "metadata": {},
   "source": [
    "### For dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "753e9f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a composite key\n",
    "df5['key'] = list(zip(df5['frame_ID'], df5['precondition_id'], df5['response_text']))\n",
    "df1_group2['key'] = list(zip(df1_group2['frame_ID'], df1_group2['precondition_id'], df1_group2['response_text']))\n",
    "df10_group2['key'] = list(zip(df10_group2['frame_ID'], df10_group2['precondition_id'], df10_group2['response_text']))\n",
    "df9['key'] = list(zip(df9['frame_ID'], df9['precondition_id'], df9['response_text']))\n",
    "df_synthetic1_group2['key'] = list(zip(df_synthetic1_group2['frame_ID'], df_synthetic1_group2['precondition_id'], df_synthetic1_group2['response_text']))\n",
    "df_synthetic2_group2['key'] = list(zip(df_synthetic2_group2['frame_ID'], df_synthetic2_group2['precondition_id'], df_synthetic2_group2['response_text']))\n",
    "\n",
    "# get the order of keys in df1_group1\n",
    "key_order2 = {key: i for i, key in enumerate(df1_group2['key'])}\n",
    "\n",
    "# Map this order to df5\n",
    "df5['sort_order'] = df5['key'].map(key_order2)\n",
    "\n",
    "# Sort df5 — first by sort_order (NaNs last), then by key or index and get its order of keys\n",
    "df5_sorted = df5.sort_values(by=['sort_order', 'key'], na_position='last').reset_index(drop=True)\n",
    "ordered_keys_df5 = df5_sorted['key'].tolist()\n",
    "\n",
    "\n",
    "#sort df1_group1 and df10_group1 according to the initial key order determined for df1_group1 and the order of keys in df7_sorted respectively\n",
    "df1_group2_sorted = df1_group2.set_index('key').reindex(key_order2).dropna(how='all').reset_index()\n",
    "df10_group2_sorted = df10_group2.set_index('key').reindex(ordered_keys_df5).dropna(how='all').reset_index()\n",
    "df9_sorted = df9.set_index('key').reindex(ordered_keys_df5).dropna(how='all').reset_index()\n",
    "\n",
    "# Sort synthetic dataframes according to the order of keys in df5_sorted\n",
    "df_synthetic1_group2_sorted = df_synthetic1_group2.set_index('key').reindex(ordered_keys_df5).dropna(how='all').reset_index()\n",
    "df_synthetic2_group2_sorted = df_synthetic2_group2.set_index('key').reindex(ordered_keys_df5).dropna(how='all').reset_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e6981d",
   "metadata": {},
   "source": [
    "## Compute fleiss kappa for proper Dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b81934b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all acts and facts for the different participants\n",
    "df1_group1_acts = df1_group1_sorted[df1_group1_sorted['frame_type'] != 'fact']\n",
    "df1_group2_acts = df1_group2_sorted[df1_group2_sorted['frame_type'] != 'fact']\n",
    "df5_acts = df5_sorted[df5_sorted['frame_type'] != 'fact']\n",
    "df7_acts = df7_sorted[df7_sorted['frame_type'] != 'fact']\n",
    "df9_acts = df9_sorted[df9_sorted['frame_type'] != 'fact']\n",
    "df10_group1_acts = df10_group1_sorted[df10_group1_sorted['frame_type'] != 'fact']\n",
    "df10_group2_acts = df10_group2_sorted[df10_group2_sorted['frame_type'] != 'fact']\n",
    "\n",
    "# Synthetic acts and facts\n",
    "df_synthetic1_group1_acts = df_synthetic1_group1_sorted[df_synthetic1_group1_sorted['frame_type'] != 'fact']\n",
    "df_synthetic2_group1_acts = df_synthetic2_group1_sorted[df_synthetic2_group1_sorted['frame_type'] != 'fact']\n",
    "df_synthetic1_group2_acts = df_synthetic1_group2_sorted[df_synthetic1_group2_sorted['frame_type'] != 'fact']\n",
    "df_synthetic2_group2_acts = df_synthetic2_group2_sorted[df_synthetic2_group2_sorted['frame_type'] != 'fact']\n",
    "\n",
    "df1_group1_facts = df1_group1_sorted[df1_group1_sorted['frame_type'] != 'act']\n",
    "df1_group2_facts = df1_group2_sorted[df1_group2_sorted['frame_type'] != 'act']\n",
    "df5_facts = df5_sorted[df5_sorted['frame_type'] != 'act']\n",
    "df7_facts = df7_sorted[df7_sorted['frame_type'] != 'act']\n",
    "df9_facts = df9_sorted[df9_sorted['frame_type'] != 'act']\n",
    "df10_group1_facts = df10_group1_sorted[df10_group1_sorted['frame_type'] != 'act']\n",
    "df10_group2_facts = df10_group2_sorted[df10_group2_sorted['frame_type'] != 'act']\n",
    "\n",
    "#Synthetic acts and facts\n",
    "df_synthetic1_group1_facts = df_synthetic1_group1_sorted[df_synthetic1_group1_sorted['frame_type'] != 'act']\n",
    "df_synthetic2_group1_facts = df_synthetic2_group1_sorted[df_synthetic2_group1_sorted['frame_type'] != 'act']\n",
    "df_synthetic1_group2_facts = df_synthetic1_group2_sorted[df_synthetic1_group2_sorted['frame_type'] != 'act']\n",
    "df_synthetic2_group2_facts = df_synthetic2_group2_sorted[df_synthetic2_group2_sorted['frame_type'] != 'act']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76883c6b",
   "metadata": {},
   "source": [
    "### Human data Fleiss Kappa computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f1428c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fleiss' Kappa for feedback_extraction (acts) - group 1: tensor(0.5197)\n",
      "Fleiss' Kappa for feedback_detection (acts) - group 1: tensor(0.7484)\n",
      "Fleiss' Kappa for feedback_extraction (acts) - group 2: tensor(0.5068)\n",
      "Fleiss' Kappa for feedback_detection (acts) - group 2: tensor(0.4484)\n",
      "Fleiss' Kappa for feedback_extraction (facts) - group 1: tensor(0.4867)\n",
      "Fleiss' Kappa for feedback_detection (facts) - group 1: tensor(0.4757)\n",
      "Fleiss' Kappa for feedback_extraction (facts) - group 2: tensor(0.4993)\n",
      "Fleiss' Kappa for feedback_detection (facts) - group 2: tensor(0.6800)\n"
     ]
    }
   ],
   "source": [
    "# Prepare dataframes for comparison\n",
    "\n",
    "dfs_acts_human_comp1 = [df1_group1_acts, df7_acts, df10_group1_acts]\n",
    "dfs_acts_human_comp2 = [df1_group2_acts, df5_acts, df9_acts, df10_group2_acts]\n",
    "\n",
    "dfs_facts_human_comp1 = [df1_group1_facts, df7_facts, df10_group1_facts]\n",
    "dfs_facts_human_comp2 = [df1_group2_facts, df5_facts, df9_facts, df10_group2_facts]\n",
    "\n",
    "\n",
    "# Prepare data for acts\n",
    "extraction_tensor_acts_human_comp1 = prepare_data(dfs_acts_human_comp1, 'feedback_extraction')\n",
    "detection_tensor_acts_human_comp1 = prepare_data(dfs_acts_human_comp1, 'feedback_detection')\n",
    "\n",
    "extraction_tensor_acts_human_comp2 = prepare_data(dfs_acts_human_comp2, 'feedback_extraction')\n",
    "detection_tensor_acts_human_comp2 = prepare_data(dfs_acts_human_comp2, 'feedback_detection')\n",
    "\n",
    "# Prepare data for facts\n",
    "\n",
    "extraction_tensor_facts_human_comp1 = prepare_data(dfs_facts_human_comp1, 'feedback_extraction')\n",
    "detection_tensor_facts_human_comp1 = prepare_data(dfs_facts_human_comp1, 'feedback_detection')\n",
    "\n",
    "extraction_tensor_facts_human_comp2 = prepare_data(dfs_facts_human_comp2, 'feedback_extraction')\n",
    "detection_tensor_facts_human_comp2 = prepare_data(dfs_facts_human_comp2, 'feedback_detection')\n",
    "\n",
    "\n",
    "# Get categories counts to pass into Fleiss Kappa\n",
    "\n",
    "categories_count_extraction_acts_human_comp1 = count_categories(extraction_tensor_acts_human_comp1, extraction_categories)\n",
    "categories_count_detection_acts_human_comp1 = count_categories(detection_tensor_acts_human_comp1, detection_categories)\n",
    "\n",
    "categories_count_extraction_acts_human_comp2 = count_categories(extraction_tensor_acts_human_comp2, extraction_categories)\n",
    "categories_count_detection_acts_human_comp2 = count_categories(detection_tensor_acts_human_comp2, detection_categories)\n",
    "\n",
    "categories_count_extraction_facts_human_comp1 = count_categories(extraction_tensor_facts_human_comp1, extraction_categories)\n",
    "categories_count_detection_facts_human_comp1 = count_categories(detection_tensor_facts_human_comp1, detection_categories)\n",
    "\n",
    "categories_count_extraction_facts_human_comp2 = count_categories(extraction_tensor_facts_human_comp2, extraction_categories)\n",
    "categories_count_detection_facts_human_comp2 = count_categories(detection_tensor_facts_human_comp2, detection_categories)\n",
    "\n",
    "# Compute Fleiss' Kappa for acts\n",
    "\n",
    "kappa = FleissKappa(mode='counts')\n",
    "\n",
    "\n",
    "print(\"Fleiss' Kappa for feedback_extraction (acts) - group 1:\", kappa(categories_count_extraction_acts_human_comp1))\n",
    "print(\"Fleiss' Kappa for feedback_detection (acts) - group 1:\", kappa(categories_count_detection_acts_human_comp1))\n",
    "print(\"Fleiss' Kappa for feedback_extraction (acts) - group 2:\", kappa(categories_count_extraction_acts_human_comp2))\n",
    "print(\"Fleiss' Kappa for feedback_detection (acts) - group 2:\", kappa(categories_count_detection_acts_human_comp2))\n",
    "\n",
    "# Compute Fleiss' Kappa for facts\n",
    "print(\"Fleiss' Kappa for feedback_extraction (facts) - group 1:\", kappa(categories_count_extraction_facts_human_comp1))\n",
    "print(\"Fleiss' Kappa for feedback_detection (facts) - group 1:\", kappa(categories_count_detection_facts_human_comp1))\n",
    "print(\"Fleiss' Kappa for feedback_extraction (facts) - group 2:\", kappa(categories_count_extraction_facts_human_comp2))\n",
    "print(\"Fleiss' Kappa for feedback_detection (facts) - group 2:\", kappa(categories_count_detection_facts_human_comp2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aba70e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "19e0540b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Fleiss' Kappa for feedback_extraction (acts): tensor(0.5133)\n",
      "Average Fleiss' Kappa for feedback_detection (acts): tensor(0.5984)\n",
      "Average Fleiss' Kappa for feedback_extraction (facts): tensor(0.4930)\n",
      "Average Fleiss' Kappa for feedback_detection (facts): tensor(0.5778)\n"
     ]
    }
   ],
   "source": [
    "# Calculate average Fleiss' Kappa for acts and facts\n",
    "average_kappa_extraction_acts_human = (kappa(categories_count_extraction_acts_human_comp1) + kappa(categories_count_extraction_acts_human_comp2)) / 2\n",
    "average_kappa_detection_acts_human = (kappa(categories_count_detection_acts_human_comp1) + kappa(categories_count_detection_acts_human_comp2)) / 2\n",
    "average_kappa_extraction_facts_human = (kappa(categories_count_extraction_facts_human_comp1) + kappa(categories_count_extraction_facts_human_comp2)) / 2\n",
    "average_kappa_detection_facts_human = (kappa(categories_count_detection_facts_human_comp1) + kappa(categories_count_detection_facts_human_comp2)) / 2\n",
    "print(\"Average Fleiss' Kappa for feedback_extraction (acts):\", average_kappa_extraction_acts_human)\n",
    "print(\"Average Fleiss' Kappa for feedback_detection (acts):\", average_kappa_detection_acts_human)\n",
    "print(\"Average Fleiss' Kappa for feedback_extraction (facts):\", average_kappa_extraction_facts_human)\n",
    "print(\"Average Fleiss' Kappa for feedback_detection (facts):\", average_kappa_detection_facts_human)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "392f4b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Fleiss' Kappa for feedback_extraction: tensor(0.5031)\n",
      "Average Fleiss' Kappa for feedback_detection: tensor(0.5881)\n"
     ]
    }
   ],
   "source": [
    "print(\"Average Fleiss' Kappa for feedback_extraction:\", (average_kappa_extraction_acts_human + average_kappa_extraction_facts_human) / 2)\n",
    "print(\"Average Fleiss' Kappa for feedback_detection:\", (average_kappa_detection_acts_human + average_kappa_detection_facts_human) / 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697268d7",
   "metadata": {},
   "source": [
    "### Synthetic data Fleiss Kappa computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "22e82c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fleiss' Kappa for feedback_extraction (acts) - group 1: tensor(1.0000)\n",
      "Fleiss' Kappa for feedback_detection (acts) - group 1: tensor(1.0000)\n",
      "Fleiss' Kappa for feedback_extraction (acts) - group 2: tensor(0.6461)\n",
      "Fleiss' Kappa for feedback_detection (acts) - group 2: tensor(0.6381)\n",
      "Fleiss' Kappa for feedback_extraction (facts) - group 1: tensor(0.7219)\n",
      "Fleiss' Kappa for feedback_detection (facts) - group 1: tensor(0.9350)\n",
      "Fleiss' Kappa for feedback_extraction (facts) - group 2: tensor(0.7219)\n",
      "Fleiss' Kappa for feedback_detection (facts) - group 2: tensor(0.9350)\n"
     ]
    }
   ],
   "source": [
    "# Prepare dataframes for comparison\n",
    "\n",
    "dfs_acts_synth_comp1 = [df_synthetic1_group1_acts, df_synthetic2_group1_acts]\n",
    "dfs_acts_synth_comp2 = [df_synthetic1_group2_acts, df_synthetic2_group2_acts]\n",
    "\n",
    "dfs_facts_synth_comp1 = [df_synthetic1_group1_facts, df_synthetic2_group1_facts]\n",
    "dfs_facts_synth_comp2 = [df_synthetic1_group2_facts, df_synthetic2_group2_facts]\n",
    "\n",
    "\n",
    "# Prepare data for acts\n",
    "extraction_tensor_acts_synth_comp1 = prepare_data(dfs_acts_synth_comp1, 'feedback_extraction')\n",
    "detection_tensor_acts_synth_comp1 = prepare_data(dfs_acts_synth_comp1, 'feedback_detection')\n",
    "\n",
    "extraction_tensor_acts_synth_comp2 = prepare_data(dfs_acts_synth_comp2, 'feedback_extraction')\n",
    "detection_tensor_acts_synth_comp2 = prepare_data(dfs_acts_synth_comp2, 'feedback_detection')\n",
    "\n",
    "# Prepare data for facts\n",
    "\n",
    "extraction_tensor_facts_synth_comp1 = prepare_data(dfs_facts_synth_comp1, 'feedback_extraction')\n",
    "detection_tensor_facts_synth_comp1 = prepare_data(dfs_facts_synth_comp1, 'feedback_detection')\n",
    "\n",
    "extraction_tensor_facts_synth_comp2 = prepare_data(dfs_facts_synth_comp2, 'feedback_extraction')\n",
    "detection_tensor_facts_synth_comp2 = prepare_data(dfs_facts_synth_comp2, 'feedback_detection')\n",
    "\n",
    "\n",
    "# Get categories counts to pass into Fleiss Kappa\n",
    "\n",
    "categories_count_extraction_acts_synth_comp1 = count_categories(extraction_tensor_acts_synth_comp1, extraction_categories)\n",
    "categories_count_detection_acts_synth_comp1 = count_categories(detection_tensor_acts_synth_comp1, detection_categories)\n",
    "\n",
    "categories_count_extraction_acts_synth_comp2 = count_categories(extraction_tensor_acts_synth_comp2, extraction_categories)\n",
    "categories_count_detection_acts_synth_comp2 = count_categories(detection_tensor_acts_synth_comp2, detection_categories)\n",
    "\n",
    "categories_count_extraction_facts_synth_comp1 = count_categories(extraction_tensor_facts_synth_comp1, extraction_categories)\n",
    "categories_count_detection_facts_synth_comp1 = count_categories(detection_tensor_facts_synth_comp1, detection_categories)\n",
    "\n",
    "categories_count_extraction_facts_synth_comp2 = count_categories(extraction_tensor_facts_synth_comp2, extraction_categories)\n",
    "categories_count_detection_facts_synth_comp2 = count_categories(detection_tensor_facts_synth_comp2, detection_categories)\n",
    "\n",
    "# Compute Fleiss' Kappa for acts\n",
    "\n",
    "print(\"Fleiss' Kappa for feedback_extraction (acts) - group 1:\", kappa(categories_count_extraction_acts_synth_comp1))\n",
    "print(\"Fleiss' Kappa for feedback_detection (acts) - group 1:\", kappa(categories_count_detection_acts_synth_comp1))\n",
    "print(\"Fleiss' Kappa for feedback_extraction (acts) - group 2:\", kappa(categories_count_extraction_acts_synth_comp2))\n",
    "print(\"Fleiss' Kappa for feedback_detection (acts) - group 2:\", kappa(categories_count_detection_acts_synth_comp2))\n",
    "\n",
    "# Compute Fleiss' Kappa for facts\n",
    "\n",
    "print(\"Fleiss' Kappa for feedback_extraction (facts) - group 1:\", kappa(categories_count_extraction_facts_synth_comp1))\n",
    "print(\"Fleiss' Kappa for feedback_detection (facts) - group 1:\", kappa(categories_count_detection_facts_synth_comp1))\n",
    "print(\"Fleiss' Kappa for feedback_extraction (facts) - group 2:\", kappa(categories_count_extraction_facts_synth_comp2))\n",
    "print(\"Fleiss' Kappa for feedback_detection (facts) - group 2:\", kappa(categories_count_detection_facts_synth_comp2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "226fdb0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Fleiss' Kappa for feedback_extraction (acts): tensor(0.8230)\n",
      "Average Fleiss' Kappa for feedback_detection (acts): tensor(0.8190)\n",
      "Average Fleiss' Kappa for feedback_extraction (facts): tensor(0.7219)\n",
      "Average Fleiss' Kappa for feedback_detection (facts): tensor(0.9350)\n"
     ]
    }
   ],
   "source": [
    "# Calculate average Fleiss' Kappa for acts and facts\n",
    "average_kappa_extraction_acts_synth = (kappa(categories_count_extraction_acts_synth_comp1) + kappa(categories_count_extraction_acts_synth_comp2)) / 2\n",
    "average_kappa_detection_acts_synth = (kappa(categories_count_detection_acts_synth_comp1) + kappa(categories_count_detection_acts_synth_comp2)) / 2\n",
    "average_kappa_extraction_facts_synth = (kappa(categories_count_extraction_facts_synth_comp1) + kappa(categories_count_extraction_facts_synth_comp2)) / 2\n",
    "average_kappa_detection_facts_synth = (kappa(categories_count_detection_facts_synth_comp1) + kappa(categories_count_detection_facts_synth_comp2)) / 2\n",
    "print(\"Average Fleiss' Kappa for feedback_extraction (acts):\", average_kappa_extraction_acts_synth)\n",
    "print(\"Average Fleiss' Kappa for feedback_detection (acts):\", average_kappa_detection_acts_synth)\n",
    "print(\"Average Fleiss' Kappa for feedback_extraction (facts):\", average_kappa_extraction_facts_synth)\n",
    "print(\"Average Fleiss' Kappa for feedback_detection (facts):\", average_kappa_detection_facts_synth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3591db50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Fleiss' Kappa for feedback_extraction: tensor(0.7725)\n",
      "Average Fleiss' Kappa for feedback_detection: tensor(0.8770)\n"
     ]
    }
   ],
   "source": [
    "print(\"Average Fleiss' Kappa for feedback_extraction:\", (average_kappa_extraction_acts_synth + average_kappa_extraction_facts_synth) / 2)\n",
    "print(\"Average Fleiss' Kappa for feedback_detection:\", (average_kappa_detection_acts_synth + average_kappa_detection_facts_synth) / 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e8a5f3",
   "metadata": {},
   "source": [
    "### Fleiss Kappa for human-computer agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1decbbc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fleiss' Kappa for feedback_extraction (acts) - group 1: tensor(0.1320)\n",
      "Fleiss' Kappa for feedback_detection (acts) - group 1: tensor(0.4746)\n",
      "Fleiss' Kappa for feedback_extraction (acts) - group 2: tensor(0.2019)\n",
      "Fleiss' Kappa for feedback_detection (acts) - group 2: tensor(0.1887)\n",
      "Fleiss' Kappa for feedback_extraction (facts) - group 1: tensor(0.4097)\n",
      "Fleiss' Kappa for feedback_detection (facts) - group 1: tensor(0.5771)\n",
      "Fleiss' Kappa for feedback_extraction (facts) - group 2: tensor(0.4250)\n",
      "Fleiss' Kappa for feedback_detection (facts) - group 2: tensor(0.7327)\n"
     ]
    }
   ],
   "source": [
    "# Prepare dataframes for comparison\n",
    "\n",
    "dfs_acts_mix_comp1 = [df1_group1_acts, df7_acts, df10_group1_acts, df_synthetic1_group1_acts, df_synthetic2_group1_acts]\n",
    "dfs_acts_mix_comp2 = [df1_group2_acts, df5_acts, df9_acts, df10_group2_acts, df_synthetic1_group2_acts, df_synthetic2_group2_acts]\n",
    "\n",
    "dfs_facts_mix_comp1 = [df1_group1_facts, df7_facts, df10_group1_facts, df_synthetic1_group1_facts, df_synthetic2_group1_facts]\n",
    "dfs_facts_mix_comp2 = [df1_group2_facts, df5_facts, df9_facts, df10_group2_facts, df_synthetic1_group2_facts, df_synthetic2_group2_facts]\n",
    "\n",
    "\n",
    "# Prepare data for acts\n",
    "extraction_tensor_acts_mix_comp1 = prepare_data(dfs_acts_mix_comp1, 'feedback_extraction')\n",
    "detection_tensor_acts_mix_comp1 = prepare_data(dfs_acts_mix_comp1, 'feedback_detection')\n",
    "\n",
    "extraction_tensor_acts_mix_comp2 = prepare_data(dfs_acts_mix_comp2, 'feedback_extraction')\n",
    "detection_tensor_acts_mix_comp2 = prepare_data(dfs_acts_mix_comp2, 'feedback_detection')\n",
    "\n",
    "# Prepare data for facts\n",
    "\n",
    "extraction_tensor_facts_mix_comp1 = prepare_data(dfs_facts_mix_comp1, 'feedback_extraction')\n",
    "detection_tensor_facts_mix_comp1 = prepare_data(dfs_facts_mix_comp1, 'feedback_detection')\n",
    "\n",
    "extraction_tensor_facts_mix_comp2 = prepare_data(dfs_facts_mix_comp2, 'feedback_extraction')\n",
    "detection_tensor_facts_mix_comp2 = prepare_data(dfs_facts_mix_comp2, 'feedback_detection')\n",
    "\n",
    "\n",
    "# Get categories counts to pass into Fleiss Kappa\n",
    "\n",
    "categories_count_extraction_acts_mix_comp1 = count_categories(extraction_tensor_acts_mix_comp1, extraction_categories)\n",
    "categories_count_detection_acts_mix_comp1 = count_categories(detection_tensor_acts_mix_comp1, detection_categories)\n",
    "\n",
    "categories_count_extraction_acts_mix_comp2 = count_categories(extraction_tensor_acts_mix_comp2, extraction_categories)\n",
    "categories_count_detection_acts_mix_comp2 = count_categories(detection_tensor_acts_mix_comp2, detection_categories)\n",
    "\n",
    "categories_count_extraction_facts_mix_comp1 = count_categories(extraction_tensor_facts_mix_comp1, extraction_categories)\n",
    "categories_count_detection_facts_mix_comp1 = count_categories(detection_tensor_facts_mix_comp1, detection_categories)\n",
    "\n",
    "categories_count_extraction_facts_mix_comp2 = count_categories(extraction_tensor_facts_mix_comp2, extraction_categories)\n",
    "categories_count_detection_facts_mix_comp2 = count_categories(detection_tensor_facts_mix_comp2, detection_categories)\n",
    "\n",
    "# Compute Fleiss' Kappa for acts\n",
    "\n",
    "print(\"Fleiss' Kappa for feedback_extraction (acts) - group 1:\", kappa(categories_count_extraction_acts_mix_comp1))\n",
    "print(\"Fleiss' Kappa for feedback_detection (acts) - group 1:\", kappa(categories_count_detection_acts_mix_comp1))\n",
    "print(\"Fleiss' Kappa for feedback_extraction (acts) - group 2:\", kappa(categories_count_extraction_acts_mix_comp2))\n",
    "print(\"Fleiss' Kappa for feedback_detection (acts) - group 2:\", kappa(categories_count_detection_acts_mix_comp2))\n",
    "\n",
    "# Compute Fleiss' Kappa for facts\n",
    "\n",
    "print(\"Fleiss' Kappa for feedback_extraction (facts) - group 1:\", kappa(categories_count_extraction_facts_mix_comp1))\n",
    "print(\"Fleiss' Kappa for feedback_detection (facts) - group 1:\", kappa(categories_count_detection_facts_mix_comp1))\n",
    "print(\"Fleiss' Kappa for feedback_extraction (facts) - group 2:\", kappa(categories_count_extraction_facts_mix_comp2))\n",
    "print(\"Fleiss' Kappa for feedback_detection (facts) - group 2:\", kappa(categories_count_detection_facts_mix_comp2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fb13997c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Fleiss' Kappa for feedback_extraction (acts): tensor(0.1669)\n",
      "Average Fleiss' Kappa for feedback_detection (acts): tensor(0.3317)\n",
      "Average Fleiss' Kappa for feedback_extraction (facts): tensor(0.4174)\n",
      "Average Fleiss' Kappa for feedback_detection (facts): tensor(0.6549)\n"
     ]
    }
   ],
   "source": [
    "# Calculate average Fleiss' Kappa for acts and facts\n",
    "average_kappa_extraction_acts_mix = (kappa(categories_count_extraction_acts_mix_comp1) + kappa(categories_count_extraction_acts_mix_comp2)) / 2\n",
    "average_kappa_detection_acts_mix = (kappa(categories_count_detection_acts_mix_comp1) + kappa(categories_count_detection_acts_mix_comp2)) / 2\n",
    "average_kappa_extraction_facts_mix = (kappa(categories_count_extraction_facts_mix_comp1) + kappa(categories_count_extraction_facts_mix_comp2)) / 2\n",
    "average_kappa_detection_facts_mix = (kappa(categories_count_detection_facts_mix_comp1) + kappa(categories_count_detection_facts_mix_comp2)) / 2\n",
    "print(\"Average Fleiss' Kappa for feedback_extraction (acts):\", average_kappa_extraction_acts_mix)\n",
    "print(\"Average Fleiss' Kappa for feedback_detection (acts):\", average_kappa_detection_acts_mix)\n",
    "print(\"Average Fleiss' Kappa for feedback_extraction (facts):\", average_kappa_extraction_facts_mix)\n",
    "print(\"Average Fleiss' Kappa for feedback_detection (facts):\", average_kappa_detection_facts_mix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cd5cc58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Fleiss' Kappa for feedback_extraction: tensor(0.2922)\n",
      "Average Fleiss' Kappa for feedback_detection: tensor(0.4933)\n"
     ]
    }
   ],
   "source": [
    "print(\"Average Fleiss' Kappa for feedback_extraction:\", (average_kappa_extraction_acts_mix + average_kappa_extraction_facts_mix) / 2)\n",
    "print(\"Average Fleiss' Kappa for feedback_detection:\", (average_kappa_detection_acts_mix + average_kappa_detection_facts_mix) / 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad9f492",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "\n",
    "It seems that the language model evaluates the extraction task very differently than the huan experts, whereas it agrees a bit more on the detection side but still does pull the score down. We can hence conclude that the computer views this task differently OR may even just have answered all wrong or all right on the data input."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Evaluation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
