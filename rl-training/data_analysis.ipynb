{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd01ea27",
   "metadata": {},
   "source": [
    "# Data cleanup notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae5f442",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab85d869",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchmetrics.nominal import FleissKappa\n",
    "import pandas as pd\n",
    "from utils import parse_ratings, count_categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4514bf",
   "metadata": {},
   "source": [
    "## 2. Clean up messed up files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bac294e",
   "metadata": {},
   "source": [
    "### Load files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc34f4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Participant 2\n",
    "\n",
    "first_file_2 = \"/home/jacques.furst/development/RAG/flintfiller-precondition-rl/data/human_feedback/human_feedback_7a185ca4-3d37-4487-8aa7-ad9e8f6fe884.csv\" # 13:10\n",
    "second_file_2 = \"/home/jacques.furst/development/RAG/flintfiller-precondition-rl/data/human_feedback/human_feedback_861cdaee-9f2e-4454-8252-d8ff397eb14e.csv\" # 15:48\n",
    "third_file_2 = \"/home/jacques.furst/development/RAG/flintfiller-precondition-rl/data/human_feedback/human_feedback_f60e0e84-2638-44da-871b-4847b751fabb.csv\" # 16:23\n",
    "\n",
    "\n",
    "# Participant 6\n",
    "\n",
    "first_file_6 = \"/home/jacques.furst/development/RAG/flintfiller-precondition-rl/data/human_feedback/human_feedback_48d1eb99-5d33-476a-a1a4-75917aa92e92.csv\" # 12:21\n",
    "second_file_6 = \"/home/jacques.furst/development/RAG/flintfiller-precondition-rl/data/human_feedback/human_feedback_b3d2cab5-ffca-467d-bddb-b9e188e5a85a.csv\" # 11:09\n",
    "third_file_6 = \"/home/jacques.furst/development/RAG/flintfiller-precondition-rl/data/human_feedback/human_feedback_c2e282a4-f8e7-4542-95ab-a9a74b6f57e0.csv\" # 13:39\n",
    "\n",
    "\n",
    "# Participant 10\n",
    "\n",
    "first_file_10 =  \"/home/jacques.furst/development/RAG/flintfiller-precondition-rl/data/human_feedback/human_feedback_e274815b-f334-4f2c-8cda-3788070d4bee.csv\" # 13:20\n",
    "second_file_10 = \"/home/jacques.furst/development/RAG/flintfiller-precondition-rl/data/human_feedback/human_feedback_5a066984-b053-4ae4-97ad-675900d79540.csv\" # 14:39\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da94d9db",
   "metadata": {},
   "source": [
    "### Sort out files participant 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c67f99ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281\n"
     ]
    }
   ],
   "source": [
    "df_2_1 = pd.read_csv(first_file_2, sep=\";\")\n",
    "df_2_2 = pd.read_csv(second_file_2, sep=\";\")\n",
    "df_2_3 = pd.read_csv(third_file_2, sep=\";\")\n",
    "\n",
    "df_2_1 = df_2_1[:186]\n",
    "df_2_2 = df_2_2[186:]\n",
    "df_2_3 = df_2_3[30:]\n",
    "\n",
    "df_2 = pd.concat([df_2_1, df_2_2, df_2_3], ignore_index=True)\n",
    "print(len(df_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e13ec52",
   "metadata": {},
   "source": [
    "### Sort out files participant 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b247c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\n",
      "168\n",
      "114\n",
      "282\n"
     ]
    }
   ],
   "source": [
    "df_6_1 = pd.read_csv(second_file_6, sep=\";\")\n",
    "df_6_2 = pd.read_csv(first_file_6, sep=\";\")\n",
    "df_6_3 = pd.read_csv(third_file_6, sep=\";\")\n",
    "\n",
    "print(len(df_6_1))\n",
    "print(len(df_6_2))\n",
    "print(len(df_6_3))\n",
    "\n",
    "df_6_1 = df_6_1[:]\n",
    "df_6_2 = df_6_2[84:]\n",
    "df_6_3 = df_6_3[:]\n",
    "\n",
    "df_6 = pd.concat([df_6_1, df_6_2, df_6_3], ignore_index=True)\n",
    "print(len(df_6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3c11af",
   "metadata": {},
   "source": [
    "### Sort out files participant 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8103e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282\n"
     ]
    }
   ],
   "source": [
    "df_10_1 = pd.read_csv(first_file_10, sep=\";\")\n",
    "df_10_2 = pd.read_csv(second_file_10, sep=\";\")\n",
    "\n",
    "df_10 = pd.concat([df_10_1, df_10_2], ignore_index=True)\n",
    "print(len(df_10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e037d8",
   "metadata": {},
   "source": [
    "### Check if there are duplicate rows in the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4f67265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "duplicates_6 = df_6.iloc[:, :-2].duplicated()\n",
    "duplicates_2 = df_2.iloc[:, :-2].duplicated()\n",
    "print(duplicates_6.sum())\n",
    "print(duplicates_2.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18eba8f6",
   "metadata": {},
   "source": [
    "## 3. Load all proper files (except for the ones that were already created)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5517e4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_1 = \"/home/jacques.furst/development/RAG/flintfiller-precondition-rl/data/human_feedback/human_feedback_b2339fe6-2896-43ab-a9c8-24c8aacfbbd1.csv\"\n",
    "FILE_2 = None\n",
    "FILE_3 = \"/home/jacques.furst/development/RAG/flintfiller-precondition-rl/data/human_feedback/human_feedback_6430b6fd-0ddd-4cc6-a4a0-216d5603143e.csv\"\n",
    "FILE_4 = \"/home/jacques.furst/development/RAG/flintfiller-precondition-rl/data/human_feedback/human_feedback_5fa87112-3702-4263-ba81-1779b3b24d16.csv\"\n",
    "FILE_5 = \"/home/jacques.furst/development/RAG/flintfiller-precondition-rl/data/human_feedback/human_feedback_7b177fba-3ddb-465b-9a25-6f4481eeb492.csv\"\n",
    "FILE_6 = None\n",
    "FILE_7 = \"/home/jacques.furst/development/RAG/flintfiller-precondition-rl/data/human_feedback/human_feedback_ab53866b-7831-4f33-a628-3b6dbf01ead1.csv\"\n",
    "FILE_8 = \"/home/jacques.furst/development/RAG/flintfiller-precondition-rl/data/human_feedback/human_feedback_b1ed9f35-7d6a-439c-8a46-089311e8e340.csv\"\n",
    "FILE_9 = \"/home/jacques.furst/development/RAG/flintfiller-precondition-rl/data/human_feedback/human_feedback_a8ec999a-935f-476d-ac5c-f328a1288c7c.csv\"\n",
    "FILE_10 = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b127917",
   "metadata": {},
   "source": [
    "### Load all dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1da622b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                               Duidelijk\n",
      "1                               Duidelijk\n",
      "2                               Duidelijk\n",
      "3                               Duidelijk\n",
      "4                               Duidelijk\n",
      "                      ...                \n",
      "136    Onbestemde positie in ground truth\n",
      "137    Onbestemde positie in ground truth\n",
      "138               Helemaal niet duidelijk\n",
      "139               Helemaal niet duidelijk\n",
      "140               Helemaal niet duidelijk\n",
      "Name: feedback_detection, Length: 141, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df_1 = pd.read_csv(FILE_1, sep=\";\")\n",
    "df_3 = pd.read_csv(FILE_3, sep=\";\")\n",
    "df_4 = pd.read_csv(FILE_4, sep=\";\")\n",
    "df_5 = pd.read_csv(FILE_5, sep=\";\")\n",
    "df_7 = pd.read_csv(FILE_7, sep=\";\")\n",
    "df_8 = pd.read_csv(FILE_8, sep=\";\")\n",
    "df_9 = pd.read_csv(FILE_9, sep=\";\")\n",
    "\n",
    "print(df_1['feedback_detection'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b785cc",
   "metadata": {},
   "source": [
    "### Check number of common rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c77d888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of common rows in df1 and df5: 94\n",
      "                                                 file  \\\n",
      "0   Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
      "1   Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
      "2   Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
      "3   Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
      "4   Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
      "..                                                ...   \n",
      "89  Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
      "90  Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
      "91  Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
      "92  Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
      "93  Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
      "\n",
      "                                frame_ID frame_type  \\\n",
      "0   7e8d151e-a6ad-4877-85db-5eda2990ac67       fact   \n",
      "1   7e8d151e-a6ad-4877-85db-5eda2990ac67       fact   \n",
      "2   7e8d151e-a6ad-4877-85db-5eda2990ac67       fact   \n",
      "3   7e8d151e-a6ad-4877-85db-5eda2990ac67       fact   \n",
      "4   7e8d151e-a6ad-4877-85db-5eda2990ac67       fact   \n",
      "..                                   ...        ...   \n",
      "89  0ee352d3-e7de-4df0-9f77-bc6062122dfc        act   \n",
      "90  0ee352d3-e7de-4df0-9f77-bc6062122dfc        act   \n",
      "91  0ee352d3-e7de-4df0-9f77-bc6062122dfc        act   \n",
      "92  0ee352d3-e7de-4df0-9f77-bc6062122dfc        act   \n",
      "93  0ee352d3-e7de-4df0-9f77-bc6062122dfc        act   \n",
      "\n",
      "                                           frame_text  \\\n",
      "0                                       Onze Minister   \n",
      "1                                       Onze Minister   \n",
      "2                                       Onze Minister   \n",
      "3                                       Onze Minister   \n",
      "4                                       Onze Minister   \n",
      "..                                                ...   \n",
      "89  niet in behandeling nemen aanvraag van vreemde...   \n",
      "90  niet in behandeling nemen aanvraag van vreemde...   \n",
      "91  niet in behandeling nemen aanvraag van vreemde...   \n",
      "92  niet in behandeling nemen aanvraag van vreemde...   \n",
      "93  niet in behandeling nemen aanvraag van vreemde...   \n",
      "\n",
      "                         precondition_id  \\\n",
      "0   341a8e52-ca51-42ec-b84e-f606887369e7   \n",
      "1   7e8d151e-a6ad-4877-85db-5eda2990ac67   \n",
      "2   dd1b844c-4239-4d34-97ef-aa7022f430db   \n",
      "3   341a8e52-ca51-42ec-b84e-f606887369e7   \n",
      "4   7e8d151e-a6ad-4877-85db-5eda2990ac67   \n",
      "..                                   ...   \n",
      "89  aa969044-267c-4b75-913a-46743f44eea3   \n",
      "90  15c10d53-5667-4a17-a002-8f5bba5bd128   \n",
      "91  86c44e22-2649-4978-b9d1-c7fa6b73945d   \n",
      "92  e7f9471d-17f1-4c54-ae91-77cb1ae554f6   \n",
      "93  5cb67198-8adf-4dcf-ac16-d6772400abc2   \n",
      "\n",
      "                                    precondition_text  \\\n",
      "0   Onze Minister in de Vreemdelingenwet en de daa...   \n",
      "1                                       Onze Minister   \n",
      "2            Onze Minister van Veiligheid en Justitie   \n",
      "3   Onze Minister in de Vreemdelingenwet en de daa...   \n",
      "4                                       Onze Minister   \n",
      "..                                                ...   \n",
      "89  NOT de aanvrager heeft voldaan aan alle wettel...   \n",
      "90  de aanvraag geheel of gedeeltelijk is geweiger...   \n",
      "91  de verstrekte gegevens en bescheiden onvoldoen...   \n",
      "92  een besluit om de aanvraag niet te behandelen ...   \n",
      "93  als betaling leges achterwege blijft, wordt de...   \n",
      "\n",
      "                                precondition_position  \\\n",
      "0                  Artikel 1 IN Vreemdelingenwet 2024   \n",
      "1                  Artikel 1 IN Vreemdelingenwet 2024   \n",
      "2                  Artikel 1 IN Vreemdelingenwet 2024   \n",
      "3                  Artikel 1 IN Vreemdelingenwet 2024   \n",
      "4                  Artikel 1 IN Vreemdelingenwet 2024   \n",
      "..                                                ...   \n",
      "89  Artikel 4:5, sectie 1 a IN Algemene wet bestuu...   \n",
      "90  Artikel 4:5, sectie 1 b IN Algemene wet bestuu...   \n",
      "91  Artikel 4:5, sectie 1 c IN Algemene wet bestuu...   \n",
      "92  Artikel 4:5, sectie 4 IN Algemene wet bestuurs...   \n",
      "93      Artikel 17a sectie 2 IN Vreemdelingenwet 2024   \n",
      "\n",
      "                                        response_text  prompt_config_examples  \\\n",
      "0   1. Subfact: Onze Minister\\n                2. ...                   False   \n",
      "1   1. Subfact: Onze Minister\\n                2. ...                   False   \n",
      "2   1. Subfact: Onze Minister\\n                2. ...                   False   \n",
      "3   1. Subfact: Onze Minister\\n\\n                2...                   False   \n",
      "4   1. Subfact: Onze Minister\\n\\n                2...                   False   \n",
      "..                                                ...                     ...   \n",
      "89  1. De vreemdeling beschikt niet over een geldi...                   False   \n",
      "90  1. De vreemdeling beschikt niet over een geldi...                   False   \n",
      "91  1. De vreemdeling beschikt niet over een geldi...                   False   \n",
      "92  1. De vreemdeling beschikt niet over een geldi...                   False   \n",
      "93  1. De vreemdeling beschikt niet over een geldi...                   False   \n",
      "\n",
      "    prompt_config_chain_of_thought  \n",
      "0                             True  \n",
      "1                             True  \n",
      "2                             True  \n",
      "3                             True  \n",
      "4                             True  \n",
      "..                             ...  \n",
      "89                            True  \n",
      "90                            True  \n",
      "91                            True  \n",
      "92                            True  \n",
      "93                            True  \n",
      "\n",
      "[94 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "df_test_1 = df_1.iloc[:, :-3]\n",
    "df_test_2 = df_8.iloc[:, :-3]\n",
    "\n",
    "\n",
    "common = pd.merge(df_test_1, df_test_2, how='inner')\n",
    "print(\"Number of common rows in df1 and df5:\", len(common))\n",
    "print(common)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4e952f",
   "metadata": {},
   "source": [
    "### Cast ratings to numeric values to use fleiss kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c2a0026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array(['Niet goed'], dtype=object)\n"
     ]
    }
   ],
   "source": [
    "print(repr(df_2.loc[df_2['feedback_detection'].str.contains(\"Niet goed\", na=False), 'feedback_detection'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05ecf0ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# parse ratings in all dataframes to be able to calculate Fleiss kappa\n",
    "def apply_parse_ratings(df, number):\n",
    "    df['feedback_extraction'] = [parse_ratings(feedback) for feedback in df['feedback_extraction']]\n",
    "    # print(number)\n",
    "    # print(df['feedback_detection'])\n",
    "    df['feedback_detection'] = [parse_ratings(feedback_detec) for feedback_detec in df['feedback_detection']]\n",
    "    # print(df['feedback_detection'])\n",
    "    return df\n",
    "\n",
    "# Apply to each DataFrame\n",
    "df1 = apply_parse_ratings(df_1, 1)\n",
    "df2 = apply_parse_ratings(df_2, 2)\n",
    "df3 = apply_parse_ratings(df_3, 3)\n",
    "df4 = apply_parse_ratings(df_4, 4)\n",
    "df5 = apply_parse_ratings(df_5, 5)\n",
    "df6 = apply_parse_ratings(df_6, 6)\n",
    "df7 = apply_parse_ratings(df_7, 7)\n",
    "df8 = apply_parse_ratings(df_8, 8)\n",
    "df9 = apply_parse_ratings(df_9, 9)\n",
    "df10 = apply_parse_ratings(df_10, 10)\n",
    "\n",
    "# Check if any feedback column contains Nan values\n",
    "\n",
    "\n",
    "print(df1['feedback_detection'].isna().any())\n",
    "print(df2['feedback_detection'].isna().any())\n",
    "print(df3['feedback_detection'].isna().any())\n",
    "print(df4['feedback_detection'].isna().any())\n",
    "print(df5['feedback_detection'].isna().any())\n",
    "print(df6['feedback_detection'].isna().any())\n",
    "print(df7['feedback_detection'].isna().any())\n",
    "print(df8['feedback_detection'].isna().any())\n",
    "print(df9['feedback_detection'].isna().any())\n",
    "print(df10['feedback_detection'].isna().any())\n",
    "\n",
    "print(df1['feedback_extraction'].isna().any())\n",
    "print(df2['feedback_extraction'].isna().any())\n",
    "print(df3['feedback_extraction'].isna().any())\n",
    "print(df4['feedback_extraction'].isna().any())\n",
    "print(df5['feedback_extraction'].isna().any())\n",
    "print(df6['feedback_extraction'].isna().any())\n",
    "print(df7['feedback_extraction'].isna().any())\n",
    "print(df8['feedback_extraction'].isna().any())\n",
    "print(df9['feedback_extraction'].isna().any())\n",
    "print(df10['feedback_extraction'].isna().any())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d031f767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are the first 50 rows of df1 and df2 equal (excluding last 3 columns)? True\n",
      "Are the first 50 rows of df1 and df3 equal (excluding last 3 columns)? True\n",
      "Are the first 50 rows of df1 and df4 equal (excluding last 3 columns)? True\n",
      "Are the first 50 rows of df1 and df5 equal (excluding last 3 columns)? True\n",
      "Are the first 50 rows of df1 and df6 equal (excluding last 3 columns)? True\n",
      "Are the first 50 rows of df1 and df7 equal (excluding last 3 columns)? True\n",
      "Are the first 50 rows of df1 and df8 equal (excluding last 3 columns)? True\n",
      "Are the first 50 rows of df1 and df9 equal (excluding last 3 columns)? True\n",
      "Are the first 50 rows of df1 and df10 equal (excluding last 3 columns)? True\n"
     ]
    }
   ],
   "source": [
    "# Collect the first 50 entries from each DataFrame for each column\n",
    "dfs = [df1, df5, df7, df9, df10]\n",
    "# dfs = [df5, df8]\n",
    "\n",
    "\n",
    "# Compare first 50 rows, excluding the last 3 columns\n",
    "subset1 = df1.iloc[:50, :-3]\n",
    "subset2 = df2.iloc[:50, :-3]\n",
    "subset3 = df3.iloc[:50, :-3]\n",
    "subset4 = df4.iloc[:50, :-3]\n",
    "subset5 = df5.iloc[:50, :-3]\n",
    "subset6 = df6.iloc[:50, :-3]\n",
    "subset7 = df7.iloc[:50, :-3]\n",
    "subset8 = df8.iloc[:50, :-3]\n",
    "subset9 = df9.iloc[:50, :-3]\n",
    "subset10 = df10.iloc[:50, :-3]\n",
    "\n",
    "# Check if they are equal\n",
    "are_equal_1_2 = subset1.equals(subset2)\n",
    "are_equal_1_3 = subset1.equals(subset3)\n",
    "are_equal_1_4 = subset1.equals(subset4)\n",
    "are_equal_1_5 = subset1.equals(subset5)\n",
    "are_equal_1_6 = subset1.equals(subset6)\n",
    "are_equal_1_7 = subset1.equals(subset7)\n",
    "are_equal_1_8 = subset1.equals(subset8)\n",
    "are_equal_1_9 = subset1.equals(subset9)\n",
    "are_equal_1_10 = subset1.equals(subset10)\n",
    "\n",
    "# Print results of how equal stuff is\n",
    "print(\"Are the first 50 rows of df1 and df2 equal (excluding last 3 columns)?\", are_equal_1_2)\n",
    "print(\"Are the first 50 rows of df1 and df3 equal (excluding last 3 columns)?\", are_equal_1_3)\n",
    "print(\"Are the first 50 rows of df1 and df4 equal (excluding last 3 columns)?\", are_equal_1_4)\n",
    "print(\"Are the first 50 rows of df1 and df5 equal (excluding last 3 columns)?\", are_equal_1_5)\n",
    "print(\"Are the first 50 rows of df1 and df6 equal (excluding last 3 columns)?\", are_equal_1_6)\n",
    "print(\"Are the first 50 rows of df1 and df7 equal (excluding last 3 columns)?\", are_equal_1_7)\n",
    "print(\"Are the first 50 rows of df1 and df8 equal (excluding last 3 columns)?\", are_equal_1_8)\n",
    "print(\"Are the first 50 rows of df1 and df9 equal (excluding last 3 columns)?\", are_equal_1_9)\n",
    "print(\"Are the first 50 rows of df1 and df10 equal (excluding last 3 columns)?\", are_equal_1_10)\n",
    "\n",
    "# Helper function to extract and stack ratings\n",
    "def prepare_data(dfs, column):\n",
    "    # print(column)\n",
    "    data = [df[column].iloc[:50].tolist() for df in dfs]\n",
    "\n",
    "    # print(data)\n",
    "    return torch.tensor(list(zip(*data))) # shape: (50 items, 8 raters)\n",
    "\n",
    "# Prepare data\n",
    "extraction_tensor = prepare_data(dfs, 'feedback_extraction')\n",
    "detection_tensor = prepare_data(dfs, 'feedback_detection')\n",
    "\n",
    "# couont categories to pass into fleiss kappa\n",
    "extraction_categories = [0,1,2,3]\n",
    "detection_categories = [4,5,6]\n",
    "\n",
    "categories_count_extraction = count_categories(extraction_tensor, extraction_categories)\n",
    "categories_count_detection = count_categories(detection_tensor, detection_categories)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29a107a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fleiss' Kappa for feedback_extraction: tensor(0.4705)\n",
      "Fleiss' Kappa for feedback_detection: tensor(0.4808)\n"
     ]
    }
   ],
   "source": [
    "# # Determine number of classes (assuming all ratings are integers starting from 0 or 1)\n",
    "# num_classes_extraction = len(set(extraction_tensor.flatten().tolist()))\n",
    "# num_classes_detection = len(set(detection_tensor.flatten().tolist()))\n",
    "\n",
    "# Compute Fleiss' Kappa\n",
    "# TODO: data structure seems fine, but check that you have taken the ame data for every person\n",
    "\n",
    "\n",
    "kappa_extraction = FleissKappa(mode='counts')\n",
    "kappa_detection = FleissKappa(mode='counts')\n",
    "\n",
    "print(\"Fleiss' Kappa for feedback_extraction:\", kappa_extraction(categories_count_extraction))\n",
    "print(\"Fleiss' Kappa for feedback_detection:\", kappa_detection(categories_count_detection))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d5c986",
   "metadata": {},
   "source": [
    "# Check distribution of acts/facts in different groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b391bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of entries in the combined DataFrame: 929\n",
      "Number of fact entries in the combined DataFrame: 502\n",
      "Number of act entries in the combined DataFrame: 427\n"
     ]
    }
   ],
   "source": [
    "big_df = pd.concat(dfs, ignore_index=True)\n",
    "print(\"Total number of entries in the combined DataFrame:\", len(big_df))\n",
    "print(\"Number of fact entries in the combined DataFrame:\", (big_df['frame_type']=='fact').sum())\n",
    "print(\"Number of act entries in the combined DataFrame:\", (big_df['frame_type']=='act').sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827da58c",
   "metadata": {},
   "source": [
    "## Check act and fact inter-annotator agreement (maybe beyond first 50?) for rest of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b19b6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. get all act entries for each participant, know which worked on the same data\n",
    "# participant 1: dataset 1\n",
    "# participant 5: dataset 2\n",
    "# participant 7: dataset 1\n",
    "# participant 9: dataset 2\n",
    "# participant 10: dataset 1 + 2\n",
    "# group 1: 1,7,10\n",
    "# group 2: 5, 9, 10  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b81934b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all acts and facts for the different participants\n",
    "df1_acts = df1[df1['frame_type'] != 'fact']\n",
    "df5_acts = df5[df5['frame_type'] != 'fact']\n",
    "df7_acts = df7[df7['frame_type'] != 'fact']\n",
    "df9_acts = df9[df9['frame_type'] != 'fact']\n",
    "df10_acts = df10[df10['frame_type'] != 'fact']\n",
    "\n",
    "df1_facts = df1[df1['frame_type'] != 'act']\n",
    "df5_facts = df5[df5['frame_type'] != 'act']\n",
    "df7_facts = df7[df7['frame_type'] != 'act']\n",
    "df9_facts = df9[df9['frame_type'] != 'act']\n",
    "df10_facts = df10[df10['frame_type'] != 'act']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10240ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of common rows in df1 and df5: 94\n",
      "                                                 file  \\\n",
      "0   Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
      "1   Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
      "2   Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
      "3   Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
      "4   Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
      "..                                                ...   \n",
      "89  Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
      "90  Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
      "91  Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
      "92  Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
      "93  Interpretatie_Vw_over_besluiten_op_aanvragen_v...   \n",
      "\n",
      "                                frame_ID frame_type  \\\n",
      "0   7e8d151e-a6ad-4877-85db-5eda2990ac67       fact   \n",
      "1   7e8d151e-a6ad-4877-85db-5eda2990ac67       fact   \n",
      "2   7e8d151e-a6ad-4877-85db-5eda2990ac67       fact   \n",
      "3   7e8d151e-a6ad-4877-85db-5eda2990ac67       fact   \n",
      "4   7e8d151e-a6ad-4877-85db-5eda2990ac67       fact   \n",
      "..                                   ...        ...   \n",
      "89  0ee352d3-e7de-4df0-9f77-bc6062122dfc        act   \n",
      "90  0ee352d3-e7de-4df0-9f77-bc6062122dfc        act   \n",
      "91  0ee352d3-e7de-4df0-9f77-bc6062122dfc        act   \n",
      "92  0ee352d3-e7de-4df0-9f77-bc6062122dfc        act   \n",
      "93  0ee352d3-e7de-4df0-9f77-bc6062122dfc        act   \n",
      "\n",
      "                                           frame_text  \\\n",
      "0                                       Onze Minister   \n",
      "1                                       Onze Minister   \n",
      "2                                       Onze Minister   \n",
      "3                                       Onze Minister   \n",
      "4                                       Onze Minister   \n",
      "..                                                ...   \n",
      "89  niet in behandeling nemen aanvraag van vreemde...   \n",
      "90  niet in behandeling nemen aanvraag van vreemde...   \n",
      "91  niet in behandeling nemen aanvraag van vreemde...   \n",
      "92  niet in behandeling nemen aanvraag van vreemde...   \n",
      "93  niet in behandeling nemen aanvraag van vreemde...   \n",
      "\n",
      "                         precondition_id  \\\n",
      "0   341a8e52-ca51-42ec-b84e-f606887369e7   \n",
      "1   7e8d151e-a6ad-4877-85db-5eda2990ac67   \n",
      "2   dd1b844c-4239-4d34-97ef-aa7022f430db   \n",
      "3   341a8e52-ca51-42ec-b84e-f606887369e7   \n",
      "4   7e8d151e-a6ad-4877-85db-5eda2990ac67   \n",
      "..                                   ...   \n",
      "89  aa969044-267c-4b75-913a-46743f44eea3   \n",
      "90  15c10d53-5667-4a17-a002-8f5bba5bd128   \n",
      "91  86c44e22-2649-4978-b9d1-c7fa6b73945d   \n",
      "92  e7f9471d-17f1-4c54-ae91-77cb1ae554f6   \n",
      "93  5cb67198-8adf-4dcf-ac16-d6772400abc2   \n",
      "\n",
      "                                    precondition_text  \\\n",
      "0   Onze Minister in de Vreemdelingenwet en de daa...   \n",
      "1                                       Onze Minister   \n",
      "2            Onze Minister van Veiligheid en Justitie   \n",
      "3   Onze Minister in de Vreemdelingenwet en de daa...   \n",
      "4                                       Onze Minister   \n",
      "..                                                ...   \n",
      "89  NOT de aanvrager heeft voldaan aan alle wettel...   \n",
      "90  de aanvraag geheel of gedeeltelijk is geweiger...   \n",
      "91  de verstrekte gegevens en bescheiden onvoldoen...   \n",
      "92  een besluit om de aanvraag niet te behandelen ...   \n",
      "93  als betaling leges achterwege blijft, wordt de...   \n",
      "\n",
      "                                precondition_position  \\\n",
      "0                  Artikel 1 IN Vreemdelingenwet 2024   \n",
      "1                  Artikel 1 IN Vreemdelingenwet 2024   \n",
      "2                  Artikel 1 IN Vreemdelingenwet 2024   \n",
      "3                  Artikel 1 IN Vreemdelingenwet 2024   \n",
      "4                  Artikel 1 IN Vreemdelingenwet 2024   \n",
      "..                                                ...   \n",
      "89  Artikel 4:5, sectie 1 a IN Algemene wet bestuu...   \n",
      "90  Artikel 4:5, sectie 1 b IN Algemene wet bestuu...   \n",
      "91  Artikel 4:5, sectie 1 c IN Algemene wet bestuu...   \n",
      "92  Artikel 4:5, sectie 4 IN Algemene wet bestuurs...   \n",
      "93      Artikel 17a sectie 2 IN Vreemdelingenwet 2024   \n",
      "\n",
      "                                        response_text  prompt_config_examples  \\\n",
      "0   1. Subfact: Onze Minister\\n                2. ...                   False   \n",
      "1   1. Subfact: Onze Minister\\n                2. ...                   False   \n",
      "2   1. Subfact: Onze Minister\\n                2. ...                   False   \n",
      "3   1. Subfact: Onze Minister\\n\\n                2...                   False   \n",
      "4   1. Subfact: Onze Minister\\n\\n                2...                   False   \n",
      "..                                                ...                     ...   \n",
      "89  1. De vreemdeling beschikt niet over een geldi...                   False   \n",
      "90  1. De vreemdeling beschikt niet over een geldi...                   False   \n",
      "91  1. De vreemdeling beschikt niet over een geldi...                   False   \n",
      "92  1. De vreemdeling beschikt niet over een geldi...                   False   \n",
      "93  1. De vreemdeling beschikt niet over een geldi...                   False   \n",
      "\n",
      "    prompt_config_chain_of_thought  \n",
      "0                             True  \n",
      "1                             True  \n",
      "2                             True  \n",
      "3                             True  \n",
      "4                             True  \n",
      "..                             ...  \n",
      "89                            True  \n",
      "90                            True  \n",
      "91                            True  \n",
      "92                            True  \n",
      "93                            True  \n",
      "\n",
      "[94 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# check the number of first rows that are equal in all dataframes\n",
    "df_test_1 = df1.iloc[:, :-3]\n",
    "df_test_2 = df8.iloc[:, :-3]\n",
    "\n",
    "\n",
    "common = pd.merge(df_test_1, df_test_2, how='inner')\n",
    "print(\"Number of common rows in df1 and df5:\", len(common))\n",
    "print(common)\n",
    "\n",
    "#TODO: 94 rows in common is very odd, should only be around 50, check if the data is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1428c8b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "apply_parse_ratings() missing 1 required positional argument: 'number'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# sets for acts and facts\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#TODO: find out until which point the dataframes are equal\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m df10_part1 \u001b[38;5;241m=\u001b[39m \u001b[43mapply_parse_ratings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_10_1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m df10_part2 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df_10[:], df_10_2], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     11\u001b[0m dfs_acts_comp1 \u001b[38;5;241m=\u001b[39m [df1_acts, df7_acts, df10_acts]\n",
      "\u001b[0;31mTypeError\u001b[0m: apply_parse_ratings() missing 1 required positional argument: 'number'"
     ]
    }
   ],
   "source": [
    "# sets for acts and facts\n",
    "\n",
    "#TODO: find out until which point the dataframes are equal\n",
    "\n",
    "\n",
    "\n",
    "df10_part1 = apply_parse_ratings(df_10_1)\n",
    "\n",
    "df10_part2 = pd.concat([df_10[:], df_10_2], ignore_index=True)\n",
    "\n",
    "dfs_acts_comp1 = [df1_acts, df7_acts, df10_acts]\n",
    "dfs_acts_comp2 = [df5_acts, df9_acts, df10_acts]\n",
    "\n",
    "dfs_facts_comp1 = [df1_facts, df7_facts, df10_facts]\n",
    "dfs_facts_comp2 = [df5_facts, df9_facts, df10_facts]\n",
    "\n",
    "\n",
    "# Prepare data for acts\n",
    "extraction_tensor_acts_comp1 = prepare_data(dfs_acts_comp1, 'feedback_extraction')\n",
    "detection_tensor_acts_comp1 = prepare_data(dfs_acts_comp1, 'feedback_detection')\n",
    "\n",
    "extraction_tensor_acts_comp2 = prepare_data(dfs_acts_comp2, 'feedback_extraction')\n",
    "detection_tensor_acts_comp2 = prepare_data(dfs_acts_comp2, 'feedback_detection')\n",
    "\n",
    "# Prepare data for facts\n",
    "\n",
    "extraction_tensor_facts_comp1 = prepare_data(dfs_facts_comp1, 'feedback_extraction')\n",
    "detection_tensor_facts_comp1 = prepare_data(dfs_facts_comp1, 'feedback_detection')\n",
    "\n",
    "extraction_tensor_facts_comp2 = prepare_data(dfs_facts_comp2, 'feedback_extraction')\n",
    "detection_tensor_facts_comp2 = prepare_data(dfs_facts_comp2, 'feedback_detection')\n",
    "\n",
    "\n",
    "# Get categories counts to pass into Fleiss Kappa\n",
    "\n",
    "categories_count_extraction_acts_comp1 = count_categories(extraction_tensor_acts_comp1, extraction_categories)\n",
    "categories_count_detection_acts_comp1 = count_categories(detection_tensor_acts_comp1, detection_categories)\n",
    "\n",
    "categories_count_extraction_acts_comp2 = count_categories(extraction_tensor_acts_comp2, extraction_categories)\n",
    "categories_count_detection_acts_comp2 = count_categories(detection_tensor_acts_comp2, detection_categories)\n",
    "\n",
    "categories_count_extraction_facts_comp1 = count_categories(extraction_tensor_facts_comp1, extraction_categories)\n",
    "categories_count_detection_facts_comp1 = count_categories(detection_tensor_facts_comp1, detection_categories)\n",
    "\n",
    "categories_count_extraction_facts_comp2 = count_categories(extraction_tensor_facts_comp2, extraction_categories)\n",
    "categories_count_detection_facts_comp2 = count_categories(detection_tensor_facts_comp2, detection_categories)\n",
    "\n",
    "# Compute Fleiss' Kappa for acts\n",
    "\n",
    "kappa_extraction_acts_comp1 = FleissKappa(mode='counts')\n",
    "kappa_detection_acts_comp1 = FleissKappa(mode='counts')\n",
    "kappa_extraction_acts_comp2 = FleissKappa(mode='counts')\n",
    "kappa_detection_acts_comp2 = FleissKappa(mode='counts')\n",
    "\n",
    "print(\"Fleiss' Kappa for feedback_extraction (acts) - group 1:\", kappa_extraction_acts_comp1(categories_count_extraction_acts_comp1))\n",
    "print(\"Fleiss' Kappa for feedback_detection (acts) - group 1:\", kappa_detection_acts_comp1(categories_count_detection_acts_comp1))\n",
    "print(\"Fleiss' Kappa for feedback_extraction (acts) - group 2:\", kappa_extraction_acts_comp2(categories_count_extraction_acts_comp2))\n",
    "print(\"Fleiss' Kappa for feedback_detection (acts) - group 2:\", kappa_detection_acts_comp2(categories_count_detection_acts_comp2))\n",
    "\n",
    "# Compute Fleiss' Kappa for facts\n",
    "kappa_extraction_facts_comp1 = FleissKappa(mode='counts')\n",
    "kappa_detection_facts_comp1 = FleissKappa(mode='counts')\n",
    "kappa_extraction_facts_comp2 = FleissKappa(mode='counts')\n",
    "kappa_detection_facts_comp2 = FleissKappa(mode='counts')\n",
    "\n",
    "print(\"Fleiss' Kappa for feedback_extraction (facts) - group 1:\", kappa_extraction_facts_comp1(categories_count_extraction_facts_comp1))\n",
    "print(\"Fleiss' Kappa for feedback_detection (facts) - group 1:\", kappa_detection_facts_comp1(categories_count_detection_facts_comp1))\n",
    "print(\"Fleiss' Kappa for feedback_extraction (facts) - group 2:\", kappa_extraction_facts_comp2(categories_count_extraction_facts_comp2))\n",
    "print(\"Fleiss' Kappa for feedback_detection (facts) - group 2:\", kappa_detection_facts_comp2(categories_count_detection_facts_comp2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_cleanup",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
